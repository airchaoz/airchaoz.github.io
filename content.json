{"posts":[{"title":"C++并发编程之线程管理","text":"C++11 引入的一个标准库类std::thread，用于创建和管理线程。它提供了一种方便的方式来执行并发任务，使得多线程编程变得更加简单和安全。 线程管理的基础每个程序运行时都会有一个线程，即执行main函数的线程。 启动线程通过std::thread对象来创建线程，线程在创建时启动，可以选择阻塞join或者分离detach执行。 这是一段启动线程的代码： 123456789101112131415#include &quot;bits/stdc++.h&quot;#include &lt;thread&gt; // 引入线程头文件using namespace std;void hello() { cout &lt;&lt; &quot;Hello Concurrent World&quot; &lt;&lt; endl;}int main (int argc, char *argv[]) { thread t{hello}; // 开启线程 t.join(); // 等待线程结束 // t.detach() // 分离线程 return 0;} 如果线程对象t在析构时还未选择阻塞join或者分离detach，std::thread的析构函数会调用std::terminate()，会报以下错误： 12terminate called without an active exceptionAborted 如果主线程结束时子线程还未结束，那么子线程也会被迫结束，例如以下例子是没有输出的。 123456789101112131415#include &quot;bits/stdc++.h&quot;#include &lt;thread&gt;using namespace std;void hello() { this_thread::sleep_for(chrono::seconds(1)); cout &lt;&lt; &quot;Hello Concurrent World&quot; &lt;&lt; endl;}int main (int argc, char *argv[]) { thread t{hello}; t.detach(); return 0;} 线程的分离使用detach会让线程在后台运行，这就意味着主线程不能与之产生直接交互。也就是说，不会等待这个线程结束；如果线程分离，那么就不可能有std::thread对象能引用它，分离线程的确在后台运行，所以分离线程不能被加入。不过C++运行库保证，当线程退出时，相关资源的能够正确回收，后台线程的归属和控制C++运行库都会处理。 线程分离detach之后，只要主线程还在运行，线程就不会终止，而是会继续执行直到正常退出。 1234567891011121314151617181920#include &quot;bits/stdc++.h&quot;#include &lt;thread&gt;using namespace std;void hello() { this_thread::sleep_for(chrono::seconds(1)); cout &lt;&lt; &quot;Hello Concurrent World&quot; &lt;&lt; endl;}void test_detach() { thread t{hello}; t.detach();}int main (int argc, char *argv[]) { test_detach(); this_thread::sleep_for(chrono::seconds(2)); return 0;} 线程的分离需要特别注意变量的生命周期，避免线程依旧访问已经析构的变量 1234567891011121314151617181920212223242526272829303132#include &quot;bits/stdc++.h&quot;#include &lt;thread&gt;using namespace std;struct func{ int&amp; i; func(int&amp; i_) : i(i_) {} void operator() () { for (unsigned j=0 ; j&lt;1000000 ; ++j) { i++; // 1. 潜在访问隐患：悬空引用 cout &lt;&lt; &quot;i = &quot; &lt;&lt; i &lt;&lt; endl; } }};void oops(){ int some_local_state=0; func my_func(some_local_state); std::thread my_thread(my_func); my_thread.detach(); // 2. 不等待线程结束} // 3. 新线程可能还在运行int main (int argc, char *argv[]) { oops(); this_thread::sleep_for(10ms); return 0;} 上面这个例子可以看出，多线程对内存管理有着更高的要求，在使用引用传递和指针传递时需要格外谨慎。处理这种情况的常规方法：使线程函数的功能齐全，将数据复制到线程中，而非复制到共享数据中。 线程的等待一般来说，线程的等待要比线程的分离更加难以处理，因为线程的分离可以在线程创建时就执行，而线程的等待需要精心挑选一个位置。因为调用join会让当前线程进入阻塞，无法执行其他任务，导致多线程的收益减弱。 除此之外，还可以使用std::thread::joinable来判断线程是否可以调用join，如果线程已经被join、detach或者已经结束了，则返回False 线程管理实践一种方式是使用“资源获取即初始化方式”(RAII，Resource Acquisition Is Initialization)，并且提供一个类，在析构函数中使用join()，如同下面清单中的代码。看它如何简化f()函数。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#include &quot;bits/stdc++.h&quot;#include &lt;thread&gt;using namespace std;struct func{ int&amp; i; func(int&amp; i_) : i(i_) {} void operator() () { for (unsigned j=0 ; j&lt;1000000 ; ++j) { i++; // 1. 潜在访问隐患：悬空引用 cout &lt;&lt; &quot;i = &quot; &lt;&lt; i &lt;&lt; endl; } }};class thread_guard{ std::thread&amp; t;public: explicit thread_guard(std::thread&amp; t_): t(t_) {} ~thread_guard() { if(t.joinable()) // 1 { t.join(); // 2 } } thread_guard(thread_guard const&amp;)=delete; // 3 thread_guard&amp; operator=(thread_guard const&amp;)=delete;};void oops(){ int some_local_state=0; func my_func(some_local_state); std::thread my_thread(my_func); thread_guard my_guard(my_thread);}int main (int argc, char *argv[]) { oops(); this_thread::sleep_for(10ms); return 0;} 当执行完oops函数时，会对my_guard对象进行析构，调用my_guard的析构函数。析构函数判断线程是否可join，并等待线程结束。 拷贝构造函数和拷贝赋值操作被标记为=delete，是为了不让编译器自动生成它们。直接对一个对象进行拷贝或赋值是危险的，因为这可能会弄丢已经加入的线程。通过删除声明，任何尝试给thread_guard对象赋值的操作都会引发一个编译错误。","link":"/2024/06/27/C-%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E7%BA%BF%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"title":"C++跨平台开发总结","text":"C++编写的程序是可以跨平台的，这是因为C++语言本身是一种独立于平台的编程语言。但是不同的操作系统和不同的编译器使用起来会有一些差异，这里记录了C++跨Win/Linux平台开发时需要注意的一些要点。 宏隔离系统宏Windows系统宏 _WIN32：在所有 Windows 平台上定义，包括 32 位和 64 位 Windows 系统。只要是 Windows 平台，都会定义这个宏。 _WIN64：仅在 64 位 Windows 平台上定义。如果程序在 64 位 Windows 上编译，这个宏会被定义。 WIN32：这个宏与 _WIN32 类似，用于兼容性目的，通常不推荐直接使用 Linux系统宏 linux：在所有 Linux 平台上定义。表示程序是在 Linux 系统上编译的。 unix：在所有类 Unix 平台上定义，包括 Linux、BSD、Mac OS X 等。表示程序是在 Unix 或类 Unix 系统上编译的。 gnu_linux：特指 GNU/Linux 系统。大部分情况下与 linux 一起定义。 MAC系统宏 APPLE：在 macOS 和 iOS 平台上定义。表示程序是在 Apple 操作系统上编译的。 MACH：在基于 Mach 内核的操作系统上定义，包括 macOS。通常与 APPLE 一起定义，用于进一步识别 macOS。 编译器宏GCC编译器 GNUC：定义 GCC 编译器的主版本号。例如，GCC 9.x 会定义 GNUC 为 9。 GNUC_MINOR：定义 GCC 编译器的次版本号。例如，GCC 9.3 会定义 GNUC_MINOR 为 3。 GNUC_PATCHLEVEL：定义 GCC 编译器的修订版本号。例如，GCC 9.3.0 会定义 GNUC_PATCHLEVEL 为 0。 VERSION：定义 GCC 的完整版本字符串。 Clang/LLVM编译器 clang：在使用 Clang 编译器时定义。 clang_major：定义 Clang 编译器的主版本号。 clang_minor：定义 Clang 编译器的次版本号。 clang_patchlevel：定义 Clang 编译器的修订版本号。 MSVC (Microsoft Visual C++)编译器MSVC 是 Microsoft 的 C++ 编译器，主要用于 Windows 平台的开发。 _MSC_VER：定义 MSVC 编译器的版本号。例如，Visual Studio 2019 的 _MSC_VER 是 1920。 _MSC_FULL_VER：定义 MSVC 编译器的完整版本号，包含修订号。 _MSC_BUILD：定义 MSVC 编译器的内部版本号。 架构宏~i386：在 32 位 x86 架构上定义。 x86_64：在 64 位 x86 架构上定义 arm：在 32 位 ARM 架构上定义 aarch64 或 arm64：在 64 位 ARM 架构上定义。 C++版本宏__cplusplus：定义 C++ 标准的版本。不同版本的 C++ 标准有不同的值。例如，C++98 为 199711L，C++11 为 201103L，C++14 为 201402L，C++17 为 201703L，C++20 为 202002L。 文件系统本节内容不过多展开文件系统本身，而是总结不同系统文件系统在程序开发时需要注意的事项。 大小写由于历史原因，Win中的文件默认情况下不区分文件名的大小写，而Linux是区分大小写的。为了程序的可移植性，建议在Win系统中编程也注意区分大小写。 文件分隔符Win平台的分隔符为双反斜杠\\\\而Linux的文件分隔符为单斜杠/。大多数API两者路径分隔符都支持，但是为了考虑兼容性，可以使用系统宏对文件分隔符做处理 12345#ifdef _WIN32 #define sep '\\\\'#else #define sep '/'#endif 专属头文件Linux头文件在Linux系统上，C++编程中可以用到一些特定的头文件，这些头文件通常与Linux系统特有的功能和API有关。以下是一些在Linux上才有的常见头文件： &lt;unistd.h&gt;：包含了大量POSIX标准的函数声明，如 fork、exec、pipe、sleep、getpid、getppid 等等。 &lt;sys/types.h&gt;：定义了一些数据类型，如 pid_t、uid_t、gid_t 等，用于系统调用和库函数。 &lt;sys/stat.h&gt;：提供了获取文件状态信息的函数，如 stat、fstat、lstat 等。 &lt;fcntl.h&gt;：定义了文件控制的函数和宏，如 open、fcntl 等。 &lt;sys/socket.h&gt;：提供了套接字编程所需的结构体和函数声明，如 socket、bind、listen、accept、connect 等。 &lt;netinet/in.h&gt;：定义了Internet地址族的常量和结构体，如 sockaddr_in、INADDR_ANY、INADDR_LOOPBACK 等。 &lt;arpa/inet.h&gt;：提供了Internet操作的函数，如 inet_pton、inet_ntop 等。 &lt;sys/wait.h&gt;：定义了等待进程变更状态的函数和宏，如 wait、waitpid 等。 &lt;pthread.h&gt;：用于POSIX线程（pthreads）编程，包含线程创建、同步等相关函数。 &lt;sys/mman.h&gt;：提供了内存映射相关的函数，如 mmap、munmap、mprotect 等。 &lt;sys/resource.h&gt;：包含资源操作的函数和宏，如 getrlimit、setrlimit 等。 &lt;sys/time.h&gt;：提供了时间获取和操作的函数，如 gettimeofday、settimeofday、timersub 等。 &lt;sys/ioctl.h&gt;：定义了设备控制接口函数，如 ioctl。 &lt;sys/ipc.h&gt;：用于进程间通信（IPC）的头文件，包含共享内存、消息队列和信号灯的功能。 &lt;sys/shm.h&gt;：提供了共享内存的函数，如 shmget、shmat、shmdt、shmctl 等。 &lt;sys/sem.h&gt;：提供了信号量的函数，如 semget、semop、semctl 等。 &lt;sys/msg.h&gt;：提供了消息队列的函数，如 msgget、msgsnd、msgrcv、msgctl 等。 这些头文件和它们所提供的功能在编写与操作系统交互、网络编程、多线程编程、进程间通信等方面的应用程序时非常有用。 Windows头文件Windows上也有一些专有的头文件，主要与系统API函数有关 &lt;windows.h&gt;：这是一个包含了大量Windows API函数、常量、宏和数据类型的头文件，是使用Windows API进行系统编程的基础。 &lt;winsock2.h&gt;：用于Windows Sockets 2 API的头文件，提供了网络编程的功能，如创建和操作套接字。 &lt;ws2tcpip.h&gt;：包含了一些Windows Sockets 2扩展功能的头文件，如IPv6支持和高级TCP/IP操作。 &lt;winuser.h&gt;：包含了用户界面相关的Windows API，如窗口管理、消息处理、输入处理等。 &lt;winbase.h&gt;：包含了基础系统服务的Windows API，如进程、线程、文件操作、内存管理等。 &lt;winnt.h&gt;：包含了Windows NT特定的数据类型和常量，通常与系统级编程有关。 &lt;winsvc.h&gt;：用于Windows服务控制的头文件，包含了创建、管理和控制Windows服务的API。 &lt;processthreadsapi.h&gt;：包含了与进程和线程管理相关的API，如创建进程和线程、同步等。 &lt;tlhelp32.h&gt;：提供了进程快照功能的API，可以用于列举系统中的进程和线程。 &lt;shlobj.h&gt;：包含了与Shell编程相关的API，如文件操作对话框、特殊文件夹路径等。 &lt;commctrl.h&gt;：包含了常见控件库的API，如树视图、列表视图、工具栏等。 &lt;dbghelp.h&gt;：提供了调试帮助功能的API，如符号处理、堆栈跟踪等。 &lt;aclapi.h&gt;：包含了访问控制列表（ACL）和安全描述符相关的API。 &lt;sddl.h&gt;：用于安全描述符定义语言（SDDL）字符串操作的API。 &lt;lm.h&gt;：包含了网络管理功能的API，如用户、组、共享资源管理等。 &lt;rpc.h&gt;：用于远程过程调用（RPC）的API。 &lt;wincrypt.h&gt;：包含了加密API，用于数据加密、解密、证书管理等。 &lt;setupapi.h&gt;：用于安装程序和设备管理的API。 &lt;tchar.h&gt;：用于处理可移植字符集的API，支持Unicode和ANSI。 其他注意事项未定义行为的实现是由C++编译器决定的，因此要在代码中避免未定义行为。 参考文章 C++跨平台开发注意事项(Win/Linux) 【一】-CSDN博客","link":"/2024/06/24/C-%E8%B7%A8%E5%B9%B3%E5%8F%B0%E5%BC%80%E5%8F%91%E6%80%BB%E7%BB%93/"},{"title":"CMake快速上手","text":"由于项目需要使用CMake，对CMake一窍不通的我开始一边查资料一边写CMake。不得不说，CMake的中文资料真的不多，CMake有大量的变量和函数，很容易看的一头雾水。在看了很多的资料后，建议有时间直接看官方的文档进行学习。这里记录一些我写的CMake脚本和注解，提供给入门新手学习。 脚本说明&amp;项目信息CMake文件开头都会设置支持的CMake最小版本号、项目名称和项目使用的语言。不同的cmake版本，使用起来也会略有差异。 1234# 设置cmake最小版本号cmake_minimum_required(VERSION 3.13)# 设置项目名称和项目使用的语言project(sysumoc-test LANGUAGES CXX) 设置变量CMake设置变量使用关键字set设置，比如我们可以设置项目使用的c++标准。项目使用的是c++11，所以我们设置CMAKE_CXX_STANDARD变量为11。 1234# set the C++ standardset(CMAKE_CXX_STANDARD 11)set(CMAKE_CXX_STANDARD_REQUIRED ON)set(CMAKE_CXX_EXTENSIONS OFF) CMake有大量的变量，这些变量与编译密切相关。但是直接从文档中学习这些变量并不是聪明的事，建议阅读其他人写的CMake文件，掌握一些常见的变量，下面是我整理的常见的变量。 常见变量 CMAKE_CXX_STANDARD 显式声明程序使用c++11进行编译，也可以设置compiler flag来指定c++版本； CMAKE_CXX_STANDARD_REQUIRED 设置指定的C++编译器版本是必须的，如果不设置，或者为OFF，则指定版本不可用时，会使用上一版本。如果设置为ON，不满足条件时会停止构建项目； CMAKE_CXX_EXTENSIONS 如果值为ON，则会使用更加通用的参数，比如使用std=c++14 而不是-std=gnu++14； CMAKE_ARCHIVE_OUTPUT_DIRECTORY 静态库的存放目录； CMAKE_LIBRARY_OUTPUT_DIRECTORY 动态库的存放目录； CMAKE_RUNTIME_OUTPUT_DIRECTORY 可执行文件的存放目录； CMAKE_BINARY_DIR 一般情况下可以认为就是工程的顶层目录； CMAKE_SOURCE_DIR 一般情况下可以认为就是工程的顶层目录； CMAKE_CURRENT_SOURCE_DIR CMakeLists.txt文件所在的路径； 打印信息打印信息是一个调试CMake脚本的好方法，尤其是我们对一些路径或文件的变量不确定时。可以使用以下语句来打印变量和信息 1message([&lt;mode&gt;] &quot;message text&quot; ...) 信息的类型有：STATUS、DEPRECATION、AUTHOR_WARNING、WARNING等可选，具体可以查阅文档 使用三方库第三方库有很多种，一种是被广泛使用的官方库，例如MPI。对于这种库，我们可以使用find_package命令来进行查找，例如下面代码: 12345678910111213141516# CMake 最低版本号要求cmake_minimum_required(VERSION 3.11)# 项目信息project(Demo1)# 输出MPI路径message(STATUS &quot;MPI_INCLUDE_PATH = ${MPI_INCLUDE_PATH}&quot;)# 查找MPI库路径find_package(MPI REQUIRED)# 输出MPI路径message(STATUS &quot;MPI_FOUND = ${MPI_FOUND}&quot;)message(STATUS &quot;MPI_INCLUDE_PATH = ${MPI_INCLUDE_PATH}&quot;)message(STATUS &quot;MPI_LIBRARIES = ${MPI_LIBRARIES}&quot;) 输出结果为: 1234567-- MPI_INCLUDE_PATH =-- MPI_FOUND = TRUE-- MPI_INCLUDE_PATH = /usr/include/mpich-- MPI_LIBRARIES = /usr/lib/x86_64-linux-gnu/libmpichcxx.so;/usr/lib/x86_64-linux-gnu/libmpich.so-- Configuring done-- Generating done-- Build files have been written to: ... find_package命令可以从系统中查找指定第三方库，指定REQUIRED后，如果没有找到库则会报错。查找的结果会保存在变量中。 &lt;package&gt;_FOUND保存是否找到库 &lt;package&gt;_INCLUDE_PATH头文件所在的路径 &lt;package&gt;_LIBRARIES库文件所在的路径 找到库后便可以进行链接操作 12345678# 设置头文件路径，相当与gcc中的-Iinclude_directories(${MPI_INCLUDE_PATH})# 设置库文件路径，相当与gcc中的-Llink_directories(${MPI_LIBRARIES})# 设置链接的库，相当于gcc中的-ltarget_link_libraries(${MPI_LIBRARIES}) 注意：链接库需要在生成可执行文件后。 设置编译选项在cmake脚本中，设置编译选项（配置编译器）有如下三种方法： 1、add_compile_options命令 1add_compile_options(-Wall -Werror -Wstrict-prototypes -Wmissing-prototypes) 2、add_definitions命令 1ADD_DEFINITIONS(&quot;-Wall -Werror -Wstrict-prototypes -Wmissing-prototypes) 3、set命令修改CMAKE_CXX_FLAGS或CMAKE_C_FLAGS 1set(CMAKE_C_FLAGS &quot;-Wall -Werror -Wstrict-prototypes -Wmissing-prototypes) 使用这三种方式在有的情况下效果是一样的，但请注意它们还是有区别的：add_compile_options命令和add_definitions添加的编译选项是针对所有编译器的(包括c和c++编译器)，而set命令设置CMAKE_C_FLAGS或CMAKE_CXX_FLAGS变量则是分别只针对c和c++编译器的。 生成可执行文件使用add_executable命令可以生成可执行文件。 1add_executable(main src/main.cpp) CMake编译MPI程序main.cpp文件如下 12345678910111213#include &quot;bits/stdc++.h&quot;#include &quot;mpi.h&quot;int main(int argc, char **argv) { MPI_Init(&amp;argc, &amp;argv); int rank; int size; MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank); MPI_Comm_size(MPI_COMM_WORLD, &amp;size); printf(&quot;hello world from rank %d of %d\\n&quot;, rank, size); MPI_Finalize(); return 0;} CMakeLists.txt文件如下 1234567891011121314151617181920# CMake 最低版本号要求cmake_minimum_required (VERSION 3.17)# 项目名和信息project (mpi_hello LANGUAGES CXX)# 查找MPI库路径find_package(MPI REQUIRED)# 设置编译参数add_compile_options(-Wall -O3)# 设置头文件路径，相当与gcc中的-Iinclude_directories(SYSTEM ${MPI_INCLUDE_PATH})# 生成可执行文件add_executable(main main.cpp)# 设置链接的库，相当于gcc中的-ltarget_link_libraries(main ${MPI_LIBRARIES}) 输入cmake .命令生成makefile文件，make命令编程程序。 123456mpiexec -n 4 ./main # 运行程序# 运行结果如下hello world from rank 0 of 4hello world from rank 3 of 4hello world from rank 1 of 4hello world from rank 2 of 4 参考资料CMake官方文档博客：cmake 常用变量和常用环境变量查表手册","link":"/2023/01/18/CMake%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/"},{"title":"CMake进阶","text":"补充上篇博客没有提到的内容，方便更完善的构建C++程序。 链接库以下是一段链接库的代码： 1234target_link_libraries(hello_binary PRIVATE hello_library) 在CMake中，PRIVATE、PUBLIC 和 INTERFACE 是用来指定依赖库属性的关键词。它们用于控制库与目标（例如可执行文件或其他库）之间的链接方式和信息传递。 PRIVATE： 当你将一个库标记为 PRIVATE 时，这意味着依赖库仅在当前目标中使用，并且不会传递给由当前目标链接的其他目标。 在本例中，target_link_libraries(hello_binary PRIVATE hello_library) 表示只有 hello_binary 可以访问 hello_library 提供的功能，其他与 hello_binary 无关的目标不会受到 hello_library 的影响。 PUBLIC： 将库标记为 PUBLIC 时，这表示依赖库在当前目标中使用的同时，也会传递给由当前目标链接的其他目标。 在本例中，target_include_directories(hello_library PUBLIC ${PROJECT_SOURCE_DIR}/include) 会将 hello_library 的头文件包含路径公开给所有链接到它的目标，这样其他目标也能使用 hello_library 提供的头文件。 INTERFACE： INTERFACE 类似于 PUBLIC，但不会影响当前目标本身。它仅将依赖项传递给其他目标。 如果你有一个中间库，它不会被链接到任何可执行文件，但你希望它的依赖项传递给其他库，那么可以使用 INTERFACE。 总结： 使用 PRIVATE 来限制库的使用范围为当前目标。 使用 PUBLIC 来将库的依赖传递给链接到当前目标的其他目标。 使用 INTERFACE 将依赖项传递给其他目标，而不影响当前目标。 在你的示例代码中，target_include_directories(hello_library PUBLIC ${PROJECT_SOURCE_DIR}/include) 允许其他目标访问 hello_library 的头文件路径，而 target_link_libraries(hello_binary PRIVATE hello_library) 使 hello_binary 能够链接到 hello_library 的功能，但这些功能不会传递给其他目标。 设置宏定义target_compile_definitions 是CMake中用于在目标（例如可执行文件、库等）编译过程中添加预处理宏定义的函数。预处理宏定义是在编译阶段进行文本替换的标识符，它可以影响代码的编译过程。 函数的基本语法如下： 12345target_compile_definitions(target_name PRIVATE definition1 definition2 ... INTERFACE definition3 definition4 ... PUBLIC definition5 definition6 ...) target_name：目标的名称，可以是可执行文件、库等的名称。 PRIVATE、INTERFACE 和 PUBLIC：这些关键词用于指定定义的可见性。PRIVATE 表示仅在当前目标内部可见，INTERFACE 表示仅在与当前目标链接的目标中可见，PUBLIC 表示在当前目标和链接到它的目标中都可见。 definition1, definition2, …：要添加的预处理宏定义。 设置编译类型1234567891011121314151617181920212223// Set a default build type if none was specifiedif(NOT CMAKE_BUILD_TYPE AND NOT CMAKE_CONFIGURATION_TYPES) message(&quot;Setting build type to 'RelWithDebInfo' as none was specified.&quot;) // 如果用户没有明确指定构建类型，该代码将默认构建类型设置为&quot;RelWithDebInfo&quot; set(CMAKE_BUILD_TYPE RelWithDebInfo CACHE STRING &quot;Choose the type of build.&quot; FORCE) // Set the possible values of build type for cmake-gui set_property(CACHE CMAKE_BUILD_TYPE PROPERTY STRINGS &quot;Debug&quot; &quot;Release&quot; &quot;MinSizeRel&quot; &quot;RelWithDebInfo&quot;)endif()if(CMAKE_BUILD_TYPE MATCHES &quot;Debug&quot;) message(&quot;Debug build&quot;) // 执行与Debug构建相关的代码elseif(CMAKE_BUILD_TYPE MATCHES &quot;Release&quot;) message(&quot;Release build&quot;) // 执行与Release构建相关的代码elseif(CMAKE_BUILD_TYPE MATCHES &quot;RelWithDebInfo&quot;) message(&quot;Release with Debug Info build&quot;) // 执行与RelWithDebInfo构建相关的代码else() message(&quot;Unknown build type&quot;) // 执行在未知构建类型时的操作endif() 编译命令检查方法一12include(CheckCXXCompilerFlag)CHECK_CXX_COMPILER_FLAG(&quot;-std=c++11&quot; COMPILER_SUPPORTS_CXX11) 方法二12// set the C++ standard to C++ 11set(CMAKE_CXX_STANDARD 11) 方法三12// set the C++ standard to the appropriate standard for using autotarget_compile_features(hello_cpp11 PUBLIC cxx_auto_type) CMake配置文件configure_file 函数是CMake中的一个非常有用的工具，用于将源文件的内容复制到目标文件中，并在复制过程中进行文本替换。这对于生成配置文件、资源文件等非常有用。以下是**configure_file** 函数的基本用法： 1configure_file(input_file output_file [@ONLY] [COPYONLY] input_file：要作为源的输入文件路径。 output_file：要生成的目标文件路径。 @ONLY：一个可选参数，当设置为这个值时，只有以**@**开头的变量会被替换。如果不设置这个参数，所有变量都会被替换。 COPYONLY：一个可选参数，当设置为这个值时，只复制输入文件到输出文件，不进行变量替换。这在复制二进制文件等时很有用。 通常，您将在CMake中使用**configure_file**来生成配置文件，其中一些变量的值在构建过程中被设置。 下面是一个示例，演示如何使用**configure_file**生成一个配置文件： 假设你有一个名为 config.h.in 的输入文件，内容如下： 123#define PROJECT_NAME &quot;@PROJECT_NAME@&quot;#define VERSION_MAJOR @PROJECT_VERSION_MAJOR@#define VERSION_MINOR @PROJECT_VERSION_MINOR@ 然后，在CMakeLists.txt中，您可以使用**configure_file**来生成 config.h 配置文件： 1configure_file(config.h.in config.h) 在上述示例中，CMake将 config.h.in 中的**@PROJECT_NAME@、@PROJECT_VERSION_MAJOR@和@PROJECT_VERSION_MINOR@**等变量替换为实际的值，并生成了一个名为 config.h 的输出文件。您可以在代码中包含 config.h，以使用正确的配置信息。 这是一个简单的示例，但是**configure_file**函数非常有用，可以用于生成各种配置文件，包括用于在构建过程中动态生成项目信息的头文件、脚本文件等。 宏和函数的区别在CMake中，宏（macros）和函数（functions）都是用于封装一系列操作的工具，但它们在使用和行为方面存在一些区别。以下是它们之间的主要区别： 参数传递方式： 宏（macros）： 在调用宏时，参数会在调用点被展开，并将参数的值替换到宏的定义中。这意味着宏在展开时会完整地嵌入其调用点，包括所有参数的值和宏的代码。 函数（functions）： 函数的参数是按值传递的，这意味着在函数内部使用参数时，您在函数定义中定义的参数名将作为变量使用，保存传递给函数的实际值。 变量作用域： 宏（macros）： 宏的变量在调用宏时被展开到调用点，并且宏的定义中的所有变量都处于全局作用域。这意味着宏内部定义的变量可以影响宏调用点之外的代码。 函数（functions）： 函数内部定义的变量在函数内部有效，不会影响函数调用点之外的代码。函数的参数和局部变量仅在函数内部可见。 返回值： 宏（macros）： 宏没有返回值的概念。它们实际上是一组命令和逻辑的组合，宏的效果直接体现在宏的调用点。 函数（functions）： 函数可以有返回值。您可以在函数内部使用 return() 命令来返回一个值，并在函数调用点使用该值。 定义方式： 宏（macros）： 定义宏使用 macro 关键字。 函数（functions）： 定义函数使用 function 关键字。 调用方式： 宏（macros）： 调用宏使用宏的名称，后面跟上参数列表，参数之间使用空格分隔。 函数（functions）： 调用函数使用函数的名称，后面跟上参数列表，参数之间使用分号 ; 分隔。 综合起来，宏和函数在CMake中都用于封装代码块，但它们在参数传递、变量作用域、返回值等方面存在差异。您可以根据需要选择使用宏或函数来实现不同的封装和逻辑。 find_package、find_library和find_program的区别find_package、find_library 和 find_program 都是 CMake 中用于查找不同类型资源的命令，它们有不同的用途和区别： find_package：find_package 用于查找已安装的软件包或库，并导入其配置信息。它通常用于查找外部的第三方库或工具，并在项目中使用它们。find_package 将检查指定的包是否安装在系统上，并在找到包时配置项目以使用该包。通过 CONFIG 模式，它还可以导入该软件包的配置文件，设置编译选项、链接库等。 find_library：find_library 用于查找特定的库文件，并返回库文件的绝对路径。它主要用于查找并指定要链接到项目中的库，以便在编译和链接时使用。您可以指定库的名称以及查找路径，find_library 将返回库文件的完整路径，供您在项目中使用。 find_program：find_program 用于查找可执行文件或命令。它允许您在CMake中查找特定的可执行文件，然后可以将找到的可执行文件与目标一起使用，或者执行自定义操作。例如，您可以使用 find_program 来查找编译器、工具或其他外部命令。 综合起来，这些命令在CMake中都具有不同的用途，用于查找不同类型的资源。find_package 用于查找库和工具，并导入其配置，find_library 用于查找库文件的路径，而 find_program 则用于查找可执行文件的路径。根据您的需求，您可以选择适当的命令来在CMake项目中查找所需的资源。 option的使用option 函数用于在CMake项目中创建用户可配置的选项。这些选项通常用于允许用户自定义项目的行为或功能开关。option 函数接受三个参数：选项名称、选项描述和默认值。 其基本语法如下： 1option(&lt;option_name&gt; &lt;option_description&gt; &lt;initial_value&gt;) &lt;option_name&gt;：选项的名称，这是用户在CMake配置中使用的标识符。 &lt;option_description&gt;：选项的描述，通常是一段文本，用于说明选项的作用。 &lt;initial_value&gt;：选项的默认值，可以是 ON 或 OFF，表示选项的初始状态。 例如，以下是一个使用 option 函数的示例： 1option(ENABLE_FEATURE_X &quot;Enable feature X&quot; ON) 在这个示例中，我们定义了一个名为 ENABLE_FEATURE_X 的选项，它用于启用或禁用某个功能（feature X）。默认情况下，该选项的值为 ON，表示功能是启用的。 要在项目中使用这个选项，您可以使用 if 语句来检查选项的值，例如： 1234if (ENABLE_FEATURE_X) # 启用了功能 X，执行相关操作 # ...endif() 用户在CMake配置中可以使用 -D 选项来设置选项的值。例如，要禁用功能 X，可以执行以下命令： 1cmake -DENABLE_FEATURE_X:BOOL=OFF .. 这将覆盖默认值，并在CMake配置中禁用功能 X。 总之，option 函数允许您在CMake项目中创建用户可配置的选项，以便根据用户的需求来配置项目的行为。 使用FetchContent引入第三方库FetchContent 是一个CMake模块，用于在CMake项目中下载和管理外部依赖项。它的目标是简化项目依赖项的管理，使得在项目中集成和使用第三方库更加方便。FetchContent 模块提供了一组函数，其中最重要的函数是 FetchContent_Declare 和 FetchContent_MakeAvailable。 以下是 FetchContent 相关函数的基本使用示例： 1234567891011121314151617181920cmakeCopy codeinclude(FetchContent)# 声明要下载的外部依赖项FetchContent_Declare( my_dependency GIT_REPOSITORY https://github.com/example/my_dependency.git GIT_TAG v1.0.0 # 可选：指定要下载的特定标签或分支)# 配置并下载外部依赖项FetchContent_GetProperties(my_dependency)if(NOT my_dependency_POPULATED) FetchContent_Populate(my_dependency) add_subdirectory(${my_dependency_SOURCE_DIR} ${my_dependency_BINARY_DIR})endif()# 使用已下载的外部依赖项target_link_libraries(my_project PRIVATE my_dependency) 上述示例中的关键步骤包括： 包含 FetchContent 模块：首先，使用 include(FetchContent) 命令包含 FetchContent 模块。 声明要下载的外部依赖项：使用 FetchContent_Declare 函数声明要下载的外部依赖项。您需要提供依赖项的名称以及其来源（通常是一个Git仓库的URL）。您还可以选择性地指定特定的标签或分支。 配置并下载外部依赖项：使用 FetchContent_GetProperties 函数检查依赖项是否已经被下载和配置。如果尚未下载，使用 FetchContent_Populate 函数来下载和配置依赖项。这些函数会将依赖项的源代码下载到项目的构建目录中。 使用已下载的外部依赖项：在项目中使用已下载的依赖项，例如，通过链接到它们的库文件。 FetchContent 还提供了其他函数和选项，用于自定义依赖项的下载和配置过程。这使得您可以更灵活地管理和集成外部依赖项，而无需手动下载和管理它们。注意，FetchContent 在CMake版本3.11及更高版本中可用。","link":"/2023/08/27/CMake%E8%BF%9B%E9%98%B6/"},{"title":"GDB-Dashboard的使用","text":"GDB-Dashboard是一个使用Python API编写的独立的.gdbinit文件，能提供一个模块化的界面，方便我们控制GDB显示的信息。 安装只需要在$HOME目录下放置.gdbinit文件即可 1wget -P ~ https://github.com/cyrus-and/gdb-dashboard/raw/master/.gdbinit 配置配置文件gdb-dashboard 会从下面几个目录查找配置文件并执行相关配置完成一些初始化的工作： /etc/gdb-dashboard/; $XDG_CONFIG_HOME/gdb-dashboard/ (defaulting to ~/.config/gdb-dashboard/); ~/Library/Preferences/gdb-dashboard/; ~/.gdbinit.d/. 在dashboard启动时会去加载和执行上面目录存放的一些初始化配置文件，一般建议在~/.gdbinit.d/目录下添加我们自己的配置 定义显示的模块或者组件比如默认显示的模块太多、屏幕放不下了，有个别模块我们目前用不到，可以通过修改配置关闭一些模块的显示 dashboard 目前支持的全部组件如下： assembly breakpoints expressions history memory registers source stack threads variables 我们可以在配置文件中定义启动后显示的组件 使用-layout指令来定义需要显示的内容和隐藏的内容 比如我们只显示 register , assembly, stack dashboard -layout registers assembly source !variables stack 这个定义顺序也表示模组的展示顺序，从上到下 使用多个终端显示除了设置某些组件不显示之外，我们还可以设置让某个组件在其他终端显示输出 整个gdb-dashboard的显示内容或者是单个模块组件的显示内容都可可以单独独立的在不同的终端输出显示 比如我们打开了2个终端 可以将源码组件在A终端输出显示，其他的组件在B终端显示 使用-output 命令用来将输出内容重定向到其他的界面或设备，可以实现上面的目标 重定向全部输出到 /dev/pts/1 dashboard -output /dev/pts/1 重定向 assembly 组件到 /det/pts/3 dashboard assembly -output /dev/pts/1 重定向 source组件输出到 /dev/pts/3 dashboard source -output /dev/pts/2 /dev/pts/x 表示一个终端界面，如何获取我们的某个终端的序号是什么呢？ 在终端输入tty命令就可以查看当前终端的序号 jhb@jhb-pc:~/rtos/armv8_os$ tty /dev/pts/2 其他设置显示高度设置将组件重定向到其他窗口以后，可以使用下面的命令使得组件全屏显示 dashboard assembly -style height 0dashboard source -style height 0 保存默认配置有时候想要保存一些默认的布局，例如只看源码，看源码和汇编等等，可以为每一种使用情况保存一种布局，方便我们快速切换布局。 在home目录下创建.gdbinit.d和文件.gdbinit/init文件，在init文件中保存如下格式的命令定义 1234define soul dashboard -layout source expressions stack variables dashboard source -style height 20end 在gdb调试时，输入soul命令就可以切换到源码阅读布局了","link":"/2024/02/14/GDB-Dashboard%E7%9A%84%E4%BD%BF%E7%94%A8/"},{"title":"MPI与mpi4py的编译安装","text":"mpi4py是sysumoc程序使用的必备模块，它的编译安装有着严格的要求。默认情况下，编译sysumoc所链接的MPI库和编译mpi4py所链接的MPI库需要是同一个MPI库，否则程序就会无法运行。在超算上普通用户没有root权限，甚至会无法连接网络，所以会从源码编译安装mpi4py就非常重要。 一、有网络下pip编译安装mpi4py方法注意，无论是否使用 conda 虚拟环境，都不建议用 conda install 的方式安装，因为 conda 安装的模块是事先编译好的，只有通过pip安装的包才会重新编译。 pip安装的mpi4py是默认使用当前环境下的mpicc命令编译的，pip安装命令: 12345pip3 uninstall mpi4py # 安装前先删除旧的包pip3 install mpi4py --no-cache-dir --user--no-cache-dir # 防止直接从缓存安装mpi4py，因为缓存里的mpi4py也是编译好的。--user # 没有root权限，mpi4py只能安装在用户目录 二、本地编译mpi4py先将mpi4py的源码下载到本地，mpi4py 仓库地址:https://github.com/mpi4py/mpi4py 进入mpi4py源码文件夹，编译安装命令: 123rm -rf build # 删除编译好的文件，这一步非常重要，要不然切换MPI链接库后重新编译会没有作用python3 setup.py build --mpicc=[需要链接的mpicc的路径]python3 setup.py install --user 运行以下命令查看mpi4py链接的mpicc: python3 -c “import mpi4py; print(mpi4py.get_config())”输入下面命令可以查看mpicc路径 1which mpicc 为什么说”链接的MPI库“而不是说“mpicc的版本”呢？因为mpicc本身不是一个编译器，如果我们用vim打开mpicc文件，会发现其实它是一个脚本文件 1234567891011121314151617181920212223242526! /bin/bash# (C) 2006 by Argonne National Laboratory. See COPYRIGHT in top-level directory.# mpiccSimple script to compile and/or link MPI programs.This script knows the default flags and libraries, and can handlealternative C compilers and the associated flags and libraries.The important terms are: includedir, libdir - Directories containing an *installed* mpich prefix, execprefix - Often used to define includedir and libdir CC - C compiler WRAPPER_CFLAGS - Any special flags needed to compile WRAPPER_LDFLAGS - Any special flags needed to link WRAPPER_LIBS - Any special libraries needed in order to link# We assume that (a) the C compiler can both compile and link programs# Handling of command-line options: This is a little tricky because some options may contain blanks.# Special issues with shared libraries - todo# --------------------------------------------------------------------------Set the default values of all variables. 输入mpicc -show ，可以发现其实mpicc命令等同于显示出来的命令，如下图显示，他是由gcc为编译器，链接了一些MPI库，添加了一些编译选项。因此可以认为，MPICC并不是一个编译器，而一个链接了MPI库和添加了一些编译选项的alias。最终决定编译后的程序的是编译时链接的MPI库，而不是使用了哪个alias mpicc和mpiicc有什么区别？严格的说，其实就只有mpicc这一种，mpiicc只是intel为了方便区分，使用gcc编译器链接MPI库还是自家的icc编译器链接MPI库。编译器与MPI库是可以任意组合的，比如icc可以和mpich组合，gcc也可以和intel mpi组合。在mpicc文件中我们可以找到这样一行 1CC=&quot;gcc&quot; 如果 CC=gcc 那么 mpicc 就是与 gcc 绑定的，如果将CC改为 CC=icc 那么mpicc就与icc绑定的。 icc与mpich绑定的mpicc命令： 超算中尽量使用绝对路径超算平台有各种版本的python和mpicc，通过conda和module切换虽然方便，但是可能会有冲突，导致不知道当前环境加载的是哪个版本的程序。这里强烈建议使用绝对路径， 比如conda中的python3，就直接使用/public1/home/sc81558/.conda/envs/icc/bin/python3 比如oneapi中的mpicc就直接使用/public1/soft/oneAPI/2021.2/mpi/2021.2.0/bin/mpicc 绝对路径可以防止出现意外，同时也少加载了其他不必要的环境（比如使用oneapi，source加载就会加载其他很多不必要的环境）。","link":"/2022/12/01/MPI%E4%B8%8Empi4py%E7%9A%84%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85/"},{"title":"MSBuild生成compile_command.json文件","text":"在windows平台上，CMake生成compile_command.json不是一件容易的事情，CMAKE_EXPORT_COMPILE_COMMANDS可能不会生效，同时也没有bear一样的生成工具。 最近发现谷歌程序员开发的工具 https://github.com/0xabu/MsBuildCompileCommandsJson 可以很方便的为CMake和MSBuild编译的项目生成compile_command.json。 该项目没有提供Release，需要自己手动编译一下。首先安装dotnet环境：https://dotnet.microsoft.com/en-us/download/dotnet 再将项目克隆到本地进行编译 1234git clone https://github.com/0xabu/MsBuildCompileCommandsJson.gitcd MsBuildCompileCommandsJsondotnet build 在\\bin\\Debug\\netstandard2.0目录内可以看到CompileCommandsJson.dll这个动态库，编译时只需要链接这个动态库，就可以生成compile_command.json文件。 以spdlog日志库为例，先创建build目录，并调用cmake .. 生成MSBuild编译脚本 123mkdir buildcd build cmake .. 再编译并链接之前编译好的动态库 1msbuild -logger:&quot;D:\\repository\\MsBuildCompileCommandsJson\\bin\\Debug\\netstandard2.0\\CompileCommandsJson.dll&quot; .\\ALL_BUILD.vcxproj 此时就能发现当前目录生成了compile_command.json 网上查了一下原理，了解到-logger 参数允许指定一个自定义的日志记录器（logger），它可以在构建过程中记录和处理构建事件，利用这个编译日志记录器可以很好的生成所需要的compile_command.json文件，这个设计确实很巧妙。","link":"/2024/11/20/MSBuild%E7%94%9F%E6%88%90compile-command-json%E6%96%87%E4%BB%B6/"},{"title":"OpenMP和MPI混合并行的环境配置","text":"MPI一般用于不同的计算节点之间的并行，而OpenMP常用于在一台多核心服务器上的并行，两者都能够实现并行的功能，OpenMP和MPI混合编程是常见的使用方式。而我们在本地开发调试时，往往使用一台多核的服务器对MPI和OpenMP进行调试，在调试过程中会遇到这么一个问题：如何为程序分配MPI线程和OpenMP线程？ 编译参数bind-toMPI分配的线程可以认为是一个计算节点所具有的线程，默认下是一个MPI线程一个物理线程。但可以通过-bind-to命令可以为一个MPI线程分配不同的核心。命令如下： 1mpiexec -n 4 bind-to core:4 codename // 一个MPI进程分配四个核心，一个有四个MPI进程 下面是bind-to的帮助信息: 12345678910111213141516171819-bind-to: Process-core binding type to use Binding type options: Default: none -- no binding (default) Architecture unaware options: rr -- round-robin as OS assigned processor IDs user:0+2,1+4,3,2 -- user specified binding Architecture aware options (part within the {} braces are optional): board{:&lt;n&gt;} -- bind to 'n' motherboards numa{:&lt;n&gt;} -- bind to 'n' numa domains socket{:&lt;n&gt;} -- bind to 'n' sockets core{:&lt;n&gt;} -- bind to 'n' cores hwthread{:&lt;n&gt;} -- bind to 'n' hardware threads l1cache{:&lt;n&gt;} -- bind to processes on 'n' L1 cache domains l2cache{:&lt;n&gt;} -- bind to processes on 'n' L2 cache domains l3cache{:&lt;n&gt;} -- bind to processes on 'n' L3 cache domains OMP_PROC_BIND绝大数HPC应用程序属于CPU计算密集型，对CPU的资源占用会长期处于100%状态，计算程序的进程或线程在不同核上的调度会导致性能下降。因此建议将线程与核绑定，并且计算线程总数不要超过节点的CPU核总数。 执行以下命令将OpenMP线程绑定到核： 123456789101112131415export OMP_PROC_BIND=close有以下三种模式可以选择spread这是一种比较稀疏、均匀的绑定方式。如果有M个线程，N个处理器，那么在并行线程开始时首先会从串行线程运行的那个核开始分布，每个核上运行M/N个线程。如果串行线程在p1上运行，而并行线程有4个线程，则分别分布在p1、p3、p5、p7。如果如果串行线程在p0上运行，而并行线程有16个线程，则会分别分布在p0上有线程0和线程1，p1上运行线程2和线程3，p3上运行线程4和线程5，p4上运行线程6和线程7，…，p7上运行线程14和线程15。close这是一种紧密的绑定方式。这种方式优先分配与串行线程相临近的核。当并行线程数超过核数时，分配方式与spread相近。如果串行线程在p1上运行，进入并行线程时有4个线程，则分别分布在p1，p2，p3，p4。mastermaster的意思是继承串行线程部分的核绑定，即全部由运行串行线程的那个核来运行所有的线程。 OMP_PLACES像OMP_PROC_BIND一样，OMP_PLACES也是OpenMP的一个环境变量，可以用来指定线程的位置。OMP_PLACES有两种使用方式，一个是关键字的形式： 关键字 意义 threads 每个位置对应于目标机器上的单个硬件线程 cores 每个位置对应于目标机器上的单个核心(具有一个或多个硬件线程)。 sockets 每个位置对应于目标机器上的单个套接字(由一个或多个核心组成)。 另一种是指定某个具体的核，通过逗号分隔的位置列表或间隔来指定多个位置 123456export OMP_PLACES threadsexport OMP_PLACES &quot;threads(4)&quot;// 下面三个命令等价export OMP_PLACES &quot;{0,1,2,3},{4,5,6,7},{8,9,10,11},{12,13,14,15}&quot;export OMP_PLACES &quot;{0:4},{4:4},{8:4},{12:4}&quot;export OMP_PLACES &quot;{0:4}:4:4&quot; 具体问题1个MPI进程占据一个CPU, CPU中的多核分配为OpenMP线程1OMP_PROC_BIND=true OMP_PLACES=sockets mpiexec -n 1 -bind-to socket:2 ./mpi.o 多个进程, 每个进程多个线程.1OMP_PROC_BIND=true OMP_PLACES=cores mpiexec -n 8 -bind-to core:7 ./mpi.o","link":"/2022/12/22/OpenMP%E5%92%8CMPI%E6%B7%B7%E5%90%88%E5%B9%B6%E8%A1%8C%E7%9A%84%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"},{"title":"Qt程序上手构建","text":"一个QT程序可以分为前端和后端，前端就是程序的界面。界面一般由Qt Design程序以可视化的形式生成，通过拖拽布置组件、并为组件设置属性和设置信号和函数槽。 界面头文件的生成 Qt Design生成的界面文件后缀为ui，是一种xml文件，我们可以使用uic程序转换为c++编程语言所需要的.h头文件。 1uic hello.ui -o ui_hello.h 界面头文件的使用查看生成的UI文件 12345678910111213141516171819202122232425262728293031323334353637383940414243/********************************************************************************** Form generated from reading UI file 'hello.ui'**** Created by: Qt User Interface Compiler version 5.9.0**** WARNING! All changes made in this file will be lost when recompiling UI file!********************************************************************************/#ifndef UI_HELLO_H#define UI_HELLO_H#include &lt;QtCore/QVariant&gt;#include &lt;QtWidgets/QAction&gt;#include &lt;QtWidgets/QApplication&gt;#include &lt;QtWidgets/QButtonGroup&gt;#include &lt;QtWidgets/QHeaderView&gt;#include &lt;QtWidgets/QLabel&gt;#include &lt;QtWidgets/QWidget&gt;QT_BEGIN_NAMESPACEclass Ui_Form{public: QLabel *label; void setupUi(QWidget *Form) { if (Form-&gt;objectName().isEmpty()) Form-&gt;setObjectName(QStringLiteral(&quot;Form&quot;)); Form-&gt;resize(427, 244); label = new QLabel(Form); label-&gt;setObjectName(QStringLiteral(&quot;label&quot;)); label-&gt;setGeometry(QRect(10, 10, 200, 40)); retranslateUi(Form); QMetaObject::connectSlotsByName(Form); } // setupUi void retranslateUi(QWidget *Form) { Form-&gt;setWindowTitle(QApplication::translate(&quot;Form&quot;, &quot;Form&quot;, Q_NULLPTR)); label-&gt;setText(QApplication::translate(&quot;Form&quot;, &quot;C\\350\\257\\255\\350\\250\\200\\344\\270\\255\\346\\226\\207\\347\\275\\221&quot;, Q_NULLPTR)); } // retranslateUi};namespace Ui { class Form: public Ui_Form {};} // namespace UiQT_END_NAMESPACE#endif // UI_HELLO_H 代码开头的注释提醒开发者不要手动修改该头文件，因为uic工具下次自动生成.h 文件时，会把旧的代码全清掉，然后生成新的代码内容。 QT_BEGIN_NAMESPACE和 QT_END_NAMESPACE这两个宏标示中间的代码是包含在名字空间里的，就是一个提示作用，没有实际意义。 第一个类是全局范围定义的Ui_Form类，里面首先定义了一个label指针，注意这个指针名称就是之前设计师里显示的objectName。 接着定义了一个 setupUi 函数，这个是最关键的生成图形界面的函数，它接收一个 QWidget 对象的指针，然后为这个 QWidget 对象设置窗口界面和控件。 还有一个 retranslateUi 函数，是专门用于支持多国语言翻译的，主窗口和标签控件的字符串都在这重新翻译一下，如果有多国语言支持的翻译文件，界面的多国语言显示就通过该函数实现。 接下来定义了一个叫 Ui 的名字空间，空间里定义了一个类 Form ，简单地从 Ui_Form 类继承一下，并没有添加额外的代码。使用 Ui 名字空间的好处就是避免名称冲突，所以正常都不会直接使用 Ui_Form 类，而是用名字空间里的 Ui::Form 类。 准确地说，它们通过 setupUi 函数，辅助该函数参数里的窗口对象（QWidget *Form）构建图形界面，它们帮助别的窗口类对象构建图形界面，仅此而已。当然，在 setupUi 函数里新建的控件指针，如 label，是 Ui_Form 或Ui::Form 类里的成员变量，代码里需要通过这个类的成员变量来操控相应的控件。 如果要在项目里面使用 ui 文件（其实是 ui_*.h），通常有三种方式：直接使用方式、多重继承使用方式和成员变量使用方式。本节讲述前两种使用方式，而以后 Qt Creator 自动生成的代码就是成员变量使用方式，本节就不重复了。 直接使用 .ui 文件直接使用 .ui 文件的原理非常简单，创建一个 QWidget 类对象和 Ui::Form 类对象，调用 Ui::Form 对象的 setupUi 函数设置一下主窗体，然后显示就行了。我们在 D:\\QtDemo\\ 文件夹里新建一个 main.cpp，然后编辑代码如下： 123456789101112#include &lt;QtWidgets/QApplication&gt;#include &lt;QtWidgets/QWidget&gt;#include &quot;ui_hello.h&quot;int main(int argc, char *argv[]){ QApplication a(argc, argv); QWidget *w = new QWidget(); //主窗口 Ui::Form createUi; //createUi并不是一个真正的窗口 createUi.setupUi(w); //createUi是创建GUI的工具 w-&gt;show(); //w是真正的窗口 return a.exec();} main.cpp 包含了三个头文件 QApplication、QWidget 和 前面用 uic 生成的 ui_hello.h，由于 ui_hello.h 不包含 Q_OBJECT 宏，是不需要用元对象编译器 moc 处理的。 main 函数里第一行是图形界面程序入口对象，第二行创建了一个 QWidget 类对象 w（w 其实是一个指向对象的指针）作为程序的主窗口，w 自己并没有创建控件或设置窗口属性。 第三行语句： Ui::Form createUi; 创建了 Ui::Form 类的对象 createUi ，这个对象自己不是一个窗口，它可以为别的窗口对象设置图形界面。 第四行语句： createUi.setupUi(w); 调用了 createUi 对象的 setupUi 函数，该函数接收一个窗体对象指针，这里是 w。setupUi 函数里面的代码会为 w 创建内部的控件，设置窗体大小等等。 剩下的两行代码是显示主界面，并进入事件处理循环，直到退出。 多重继承法使用 .ui 文件上面的代码非常简单，除了 uic 生成的 ui_hello.h 和手动编写的 main.cpp，就没其他的代码文件了。主界面是 QWidget 类的对象，然后该对象比较简单，没有自己的代码。 如果要丰富一下主界面的窗口类，那就需要使用从 QWidget 类继承的方式并加上 Ui::Form 类的代码。C++ 如果要同时使用两个类的代码，有两种方式： 一种是多重继承的方式，同时用 QWidget 和 Ui::Form 类作为基类； 还有一种是使用成员变量，将 Ui::Form 类的对象作为 QWidget 派生类的成员变量，这种也叫单一继承方式，它的基类只有 QWidget。 本小节介绍多重继承方式，而以后的代码都用 QtCreator 自动生成的单一继承方式（Ui::Form 的对象作为成员变量）。 将前面做好的 hello.ui 和 ui_hello.h 复制到 D:\\QtDemo 文件夹，然后再新建三个代码文件，分别是 hellouiwidget.h、hellouiwidget.cpp 和 main.cpp ，每个文件的内容如下。 hellouiwidget.h 代码内容 123456789101112#include &lt;QtWidgets/QWidget&gt;#include &lt;QtWidgets/QLabel&gt;#include &quot;ui_hello.h&quot;class HelloUIWidget : public QWidget, public Ui::Form{ Q_OBJECTpublic: explicit HelloUIWidget(QWidget *parent = 0); ~HelloUIWidget();protected: void AdjustLabel();}; hellouiwidget.h 包含了三个头文件 QWidget、QLabel 和 使用 uic 生成的 ui_hello.h ，里面定义了一个类 HelloUIWidget 。HelloUIWidget 从 QWidget、Ui::Form 两个基类继承而来，都是 public 继承方式。由于基类有一个是 Qt 窗口类 QWidget，所以在类定义开始处必须加入 Q_OBJECT 宏，用于声明元对象系统。 该类定义了两个公开类型（public）的函数，即构造函数和析构函数。 最后一个是我们自己编写的保护类型（protected）的函数 AdjustLabel，用于调整 label 标签对象的显示效果。使用多重继承或成员变量的方式就容易丰富窗口类的功能，我们在 HelloUIWidget 里添加了 AdjustLabel 函数，当然还可以添加更多的函数。 hellouiwidget.cpp 文件内容： 123456789101112131415#include &quot;hellouiwidget.h&quot;HelloUIWidget::HelloUIWidget(QWidget *parent) : QWidget(parent){ setupUi(this); //必须先调用setupUi 函数 //TODO: AdjustLabel();}HelloUIWidget::~HelloUIWidget(){ //无需手动删除 Label 组件和 widget 组件，它们会被 Qt 自动删除}void HelloUIWidget::AdjustLabel(){ label-&gt;setText(&quot;新宝库&quot;);} 在 HelloUIWidget 构造函数定义处，它使用输入参数 parent 初始化了基类 QWidget，另一个基类 Ui::Form 因为它构造函数不需要参数，就没必要手动编写初始化代码，C++ 编译器自己会先构造好基类。 HelloUIWidget 从基类 Ui::Form 继承了 setupUi 函数，所以可直接调用该函数为自己窗口（this）构建图形界面。在构建好图形界面的控件之后，我们再调用自己编写的 AdjustLabel 函数修改标签控件显示效果。 第二个函数是 HelloUIWidget 类的析构函数，里面没有实际代码。仔细观察 ui_hello.h 代码可以发现 label 指针保存的对象是用 new 创建的，而这里我们没有手动 delete 它，因为在 Qt 主窗口关闭时，这些控件会随着主窗口全会被自动销毁，对于控件对象可以不用手动编写 delete 代码。 第三个函数是 AdjustLabel ，这个函数里对 label 指针保存的对象进行处理，label 指针成员变量也是从基类 Ui::Form 继承而来的。AdjustLabel 里面第一句代码： 1label-&gt;setText(&quot;新宝库&quot;); 是设置标签控件显示的文本。 main.cpp 文件内容： 123456789#include &lt;QtWidgets/QApplication&gt;#include &quot;hellouiwidget.h&quot;int main(int argc, char *argv[]){ QApplication a(argc, argv); HelloUIWidget *w = new HelloUIWidget(); w-&gt;show(); return a.exec();} 代码内容比较简单，main 函数里第一句创建图形程序的入口对象，第二句创建主界面窗口对象，第三句显示主界面窗口，最后一句进入事件循环直到退出为止。窗口对象会在主窗口关闭时自动销毁，所以没有 手动加 delete 代码。 代码分析完了，接下来就是编译生成目标程序了。 参考文献博客:Qt.ui文件的使用","link":"/2023/01/13/Qt%E7%A8%8B%E5%BA%8F%E4%B8%8A%E6%89%8B%E6%9E%84%E5%BB%BA/"},{"title":"TF Lite和Flex 的编译、使用","text":"当谈到深度学习和机器学习框架时，必定绕不开Tensorflow。作为一个备受欢迎的开源工具，它被广泛用于构建、训练和部署机器学习模型。TensorFlow 由 Google 开发，并于2015年首次发布，它的目标是提供一个灵活、可扩展且易于使用的框架，使研究人员和工程师能够快速开发和部署深度学习模型。 对于移动和嵌入式设备，TensorFlow 提供了 TensorFlow Lite。它是 TensorFlow 的一个轻量级版本，专门设计用于在移动设备、物联网设备和嵌入式系统等资源受限的环境中运行机器学习模型。它的目标是在保持模型性能的同时，提供更小的模型尺寸和更快的推理速度，以满足移动和嵌入式应用的需求。以下是 TensorFlow Lite 的一些关键特点和用途： 轻量级：TFLite 通过使用量化技术、模型剪枝和模型蒸馏等方法，将深度学习模型的大小大幅减小，以适应资源有限的设备。这有助于减少模型的存储空间和内存占用。 快速推理：TFLite 针对嵌入式设备进行了优化，以实现快速的推理速度。这对于实时应用和响应时间敏感的任务非常重要，如图像识别、语音识别和姿态估计等。 硬件加速支持：TFLite 支持多种硬件加速器，包括GPU、TPU和边缘设备上的专用加速器。这允许模型在加速硬件上运行，进一步提高了推理速度。 跨平台兼容性：TFLite 可以在多个操作系统上运行，包括Android、iOS、Linux和嵌入式操作系统，使其适用于各种移动和嵌入式平台。 易于集成：TFLite 提供了针对多种编程语言的 API，包括Python、C++和Java，使开发者能够轻松集成模型到他们的应用中。 量化和转换工具：TFLite 提供了用于将训练好的 TensorFlow 模型转换为 TFLite 格式的工具，同时还支持量化，这有助于减小模型的尺寸并提高性能。 模型兼容性：TFLite 支持多种类型的模型，包括图像分类、目标检测、自然语言处理和语音处理等。这使得开发者能够在移动和嵌入式设备上部署各种机器学习任务。 源码下载TFLite是Tensorflow的子模块，源码也放在Tensorflow当中，可以直接从Github上下载。Git使用如下命令克隆到本地： 1git clone https://github.com/tensorflow/tensorflow.git 程序编译Tensorflow的编译不是一件简单的事情，本人踩了很多坑，这里记录一下编译过程，避免后人踩坑。 Tensorflow提供了CMake和Bazel两种编译途径，这里强烈推荐使用Bazel编译，这也是官方推荐。CMake虽然有时也能编译成功，但是维护程度没有Bazel好，更容易编译失败。 💡 Tensorflow的版本跟Bazel是存在版本对应关系的，官方只会测试少部分指定的版本。 这里强烈建议使用Bazelisk，它能够自动识别编译所需要的Bazel并自动下载切换到对应的版本。使用方法也很简单，从Github上下载Release，重命名成bazel(Windows下是bazel.exe)并添加到环境变量当中即可。 Windows平台编译环境依赖： VC2019：在WIN平台编译需要准备VC编译环境，这里本人使用VC2019，因为Tensorflow使用的C++标准库比较新，使用旧版本VC可能会无法编译。 Git Bash：编译时需要Bash来执行某些脚本，因为Win本身不支持bash，所以需要借助Git Bash Python+Numpy模块 Lite编译步骤： 💡 **一定要使用CMD！一定要使用CMD！一定要使用CMD！不要使用PowerShell** 进入到源码目录，先生成编译配置，选项看自己需要来选。 1python .\\configure.py 在编译之前设置好编译变量，建议设置好Git Bash路径和VC路径，避免编译找不到这两个。 12set BAZEL_SH=D:/Program Files/Git/bin/bash.exeset BAZEL_VC=D:\\\\Program Files (x86)\\\\Microsoft Visual Studio\\\\2019\\BuildTools\\\\VC 编译需要能上外网，否则很多源码无法下载。 使用以下命令进行编译，-c opt表示编译Release版本，有需要可以改成DEBUG版本。 1bazel build -c opt --config=mkl //tensorflow/lite:tensorflowlite 编译好之后在\\bazel-out\\x64_windows-opt\\bin\\tensorflow\\lite文件下可以找到tensorflowlite.dll和tensorflowlite.dll.if.lib，这就是我们需要的tensorflow动态库文件。 FLex编译步骤：并不是所有的模型都能转Lite格式，默认的Lite只支持少量的算子，如果想要复杂的算子需要使用Flex委托，官方关于这部分的解释如下 Flex的编译也是只需要一行命令，但是需要注意的是，编译Flex需要编译Tensorflow的核心库，需要非常久的时间，建议有条件放到多核编译机上编译。 1bazel build -c opt --config=monolithic tensorflow/lite/delegates/flex:tensorflowlite_flex 编译完成后可以在\\bazel-out\\x64_windows-opt\\bin\\tensorflow\\lite\\delegates\\flex 目录里找到tensorflowlite_flex.dll和tensorflowlite_flex.dll.if.lib Linux平台编译环境依赖： GCC：建议使用高版本的GCC进行编译，对C++14、17支持的版本最佳 Python+Numpy模块 编译步骤：Linux环境下的编译比较简单，先生成编译配置，再编译 123python .\\configure.pybazel build -c opt --config=mkl //tensorflow/lite:tensorflowlitebazel build -c opt --config=monolithic tensorflow/lite/delegates/flex:tensorflowlite_flex 程序调用调用需要用到Tensorflow Lite C++ API，通过文档可以查询到api接口及其功能。 TensorFlow Lite C++ API Reference 头文件调用需要用到tensorflow和flatbuffers的头文件，tensorflow就使用源码文件夹，flatbuffers的头文件在路径bazel-out\\x64_windows-opt\\bin\\external\\flatbuffers\\_virtual_includes\\flatbuffers中可以找到，Linux在类似的目录。 调用主要使用这3个头文件 123#include &quot;tensorflow/lite/interpreter.h&quot;#include &quot;tensorflow/lite/kernels/register.h&quot;#include &quot;tensorflow/lite/model.h&quot; 加载模型12std::unique_ptr&lt;tflite::FlatBufferModel&gt; model = tflite::FlatBufferModel::BuildFromFile(&quot;../model/lstm_1mon_5s.tflite&quot;); 创建解释器123456789 tflite::ops::builtin::BuiltinOpResolver resolver; std::unique_ptr&lt;tflite::Interpreter&gt; interpreter; tflite::InterpreterBuilder(*model, resolver)(&amp;interpreter);// 分配解释器内存 if (interpreter-&gt;AllocateTensors() != kTfLiteOk) { std::cerr &lt;&lt; &quot;Failed to allocate tensors.&quot; &lt;&lt; std::endl; return 1; } 输出模型信息tflite模型文件包含了推理所需要的尺寸信息，可以将其输出出来便于错误检查。 123456 // 获取输入输出张量 TfLiteTensor* input_tensor = interpreter-&gt;input_tensor(0); TfLiteTensor* output_tensor = interpreter-&gt;output_tensor(0);// 输入数据尺寸const int input_tensor_size = input_tensor-&gt;bytes / sizeof(float); 填充推理数据1234float* input_data = interpreter-&gt;typed_input_tensor&lt;float&gt;(0);for (int i = 0; i &lt; N; ++i) { input_data[i] = 0.5f;} 运行模型推理12345// 运行模型if (interpreter-&gt;Invoke() != kTfLiteOk) { std::cerr &lt;&lt; &quot;Failed to invoke interpreter.&quot; &lt;&lt; std::endl; return 1;} 获取输出数据12// 获取输出数据float* output_data = interpreter-&gt;typed_output_tensor&lt;float&gt;(0); 完整的Demo如下 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677#include &lt;fstream&gt;#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;unordered_map&gt;#include &lt;vector&gt;#include &quot;tensorflow/lite/interpreter.h&quot;#include &quot;tensorflow/lite/kernels/register.h&quot;#include &quot;tensorflow/lite/model.h&quot;void loadModelAndRunInference(const std::string model_path, const int time_step, std::vector&lt;std::vector&lt;float&gt;&gt; &amp;indata, std::vector&lt;float&gt; &amp;outdata) { if (!indata.size()) { std::cerr &lt;&lt; &quot;输入数据不能为空&quot; &lt;&lt; std::endl; return; } if (indata[0].size() &lt; time_step) { std::cerr &lt;&lt; &quot;输入数据量小于样本时间步长&quot; &lt;&lt; std::endl; return; } // 加载模型 auto model = tflite::FlatBufferModel::BuildFromFile(model_path.c_str()); if (!model) { std::cerr &lt;&lt; &quot;Failed to load model.&quot; &lt;&lt; std::endl; return; } // 创建解释器 tflite::ops::builtin::BuiltinOpResolver resolver; std::unique_ptr&lt;tflite::Interpreter&gt; interpreter; tflite::InterpreterBuilder(*model, resolver)(&amp;interpreter); if (!interpreter) { std::cerr &lt;&lt; &quot;Failed to construct interpreter.&quot; &lt;&lt; std::endl; return; } // 分配张量 if (interpreter-&gt;AllocateTensors() != kTfLiteOk) { std::cerr &lt;&lt; &quot;Failed to allocate tensors.&quot; &lt;&lt; std::endl; return; } // 获取输入输出张量 TfLiteTensor* input_tensor = interpreter-&gt;input_tensor(0); TfLiteTensor* output_tensor = interpreter-&gt;output_tensor(0); // 填充输入数据 int input_tensor_size = input_tensor-&gt;bytes / sizeof(float); std::cout &lt;&lt; &quot;输入数据大小为:&quot; &lt;&lt; input_tensor_size &lt;&lt; std::endl; const int vec_num = indata.size(); for (int n = 0; n &lt; indata[0].size() - time_step; n++) { float* input_data = interpreter-&gt;typed_input_tensor&lt;float&gt;(0); for (int i = 0; i &lt; time_step; ++i) { for (int j = 0; j &lt; vec_num; ++j) { input_data[i*vec_num+j] = indata[j][n+i]; } } // 运行模型 if (interpreter-&gt;Invoke() != kTfLiteOk) { std::cerr &lt;&lt; &quot;Failed to invoke interpreter.&quot; &lt;&lt; std::endl; return; } // 获取输出数据 float* output_data = interpreter-&gt;typed_output_tensor&lt;float&gt;(0); outdata.push_back(*output_data); }} Flex调用官方申明，只要链接了共享库，在运行时创建解释器时，就会自动安装必要的 TfLiteDelegate。不需要像其他委托类型通常要求的那样显式安装委托实例。 在Linux平台中，只需要使用--no-as-needed来强制链接tensorflowlite_flex.so即可，CMake脚本如下 12345678910111213141516171819202122232425cmake_minimum_required(VERSION 3.11)project(predict)set(CMAKE_CXX_STANDARD 11)include_directories( /home/airchaoz/miniconda3/envs/tflite/lib/python3.8/site-packages/tensorflow/include /home/airchaoz/repository/tf_lite/library/lite/include /home/airchaoz/repository/tf_lite/tensorflow)add_compile_options(&quot;-g&quot;)# 添加动态set(LINK_DIR /home/airchaoz/repository/tf_lite/library/lite/lib/)add_executable(predict src/main.cpp )link_libraries(${LINK_DIR}/libflatbuffers.a)target_link_libraries(predict ${LINK_DIR}libtensorflowlite.so)# 强制链接整个库target_link_libraries(predict -Wl,--no-as-needed ${LINK_DIR}libtensorflowlite_flex.so -Wl,--as-needed) 在Win平台中，找不到强制链接的选项，这里使用手动加载的方式实现","link":"/2023/12/13/TF-Lite%E5%92%8CFlex-%E7%9A%84%E7%BC%96%E8%AF%91%E3%80%81%E4%BD%BF%E7%94%A8/"},{"title":"Transformer模型入门","text":"Transformer模型最早是由Google在2017年发布的一篇论文《Attention Is All You Need》中提出。最早该方法用用于翻译任务中，发现性能能够超越之前最优秀的RNN模型。在后一年，Google发表的《BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding》提出了BERT模型，和OpenAI发布《Improving Language Understanding by Generative Pre-Training》提出了GPT模型，这两个著名的模型奠定了大模型的基础。 Transformer 最核心、最具革新性的特点是它完全依赖注意力机制来处理序列数据，彻底放弃了传统的循环神经网络（RNN，如 LSTM）和卷积神经网络（CNN）结构。它通过位置编码来实现对序列顺序的识别，在模型训练时没有前后依赖关系，可以实现高度并行化，显著提高训练效率，正是这一点使得大模型成为可能。 相比卷积神经网络只考虑附近数据的影响，Transformer有更大的感受野，更容易连接序列的任意位置，这也是Transformer的重要优点之一。 模型预览 Transformer 模型遵循标准的**编码器-解码器（Encoder-Decoder）**架构，图例的左边是编码器，右边是解码器，模型由堆叠（stacked）的编码器和解码器组成。 编码器编码器层每层包含2个组件，分别是多头注意力和全连接的前馈神经网络，每一层输出会使用层归一化和残差网络。 输入给编码器的序列需要加入位置编码信息，添加位置信息使模型感知序列的顺序。 解码器解码器使用3个组件，分别是带有掩码的多头注意力层，多头注意力机制和全连接的前馈神经网络。 掩码用于掩盖后面位置的数据，保证数据不会被泄漏，这是自回归模型所需要的；第2个不带掩码的多头注意力机制层用于连接编码器和解码器。 相关阅读Transformer模型详解（图解最完整版） - 知乎 10.7. Transformer — 动手学深度学习 2.0.0 documentation The Illustrated Transformer – Jay Alammar – Visualizing machine learning one concept at a time. How Transformers Work: A Detailed Exploration of Transformer Architecture | DataCamp Attention? Attention! | Lil’Log 模型技术详解Embedding是一种将高维离散数据映射到低维稠密向量空间的技术。在机器学习中有一种one-hot编码方法，即用1表示状态或者属性存在，用0表示状态或者属性不存在。当状态非常多时，输入矩阵会变得非常的稀疏，embedding就是将高维的稀疏矩阵投影到低维中，减少输入矩阵的稀疏程度。 embedding的概念相对简单，实现起来要复杂的多，Embedding 的生成方式已经从Word2Vec等静态生成发展到基于Transform的动态生成，动态生成会根据上下文识别在当前语境中的语义。例如同样是苹果一词，在“苹果是一种好吃的水果”和“苹果是一个伟大的品牌”有着不同的含意，动态Embedding能够捕捉这些语境。随着进一步发展，现在有多模态Embedding，将文本、图像和音频等不同模态的信息映射到统一的向量空间中，使得跨模态检索成为可能(文本检索图像)。 相关阅读embedding概念理解: 一文读懂Embedding的概念，以及它和深度学习的关系 - 知乎 embedding发展趋势综述： from static to dynamic word representations a survey 从静态到动态，词表征近几十年发展回顾-腾讯云开发者社区-腾讯云 位置编码与RNN和LSTM等序列模型不同，Transformer本身不具备处理顺序序列的能力。为了使Transformer能够感知到序列中的位置信息，需要为输入序列中的每个元素附加一个位置信息，形成一个新的输入向量。 位置编码有许多分类，论文中提出的正余弦位置编码属于绝对位置编码，后续也提出了相对位置编码和可学习位置编码，以及现在大模型广泛使用旋转位置编码。但总的来说，位置编码需要尽可能多的满足以下几个特性： 唯一性：每个位置的编码都是唯一的； 能够体现相对位置信息：任意一个词，知道其他的词哪些是离得比较近的； 外推性：当推理输入的长度超过训练的最大长度时，依然能够很好的处理； 有界性：位置编码的置应该有边界。 相关阅读Transformer Architecture: The Positional Encoding - Amirhossein Kazemnejad’s Blog Transformer学习笔记一：Positional Encoding（位置编码） - 知乎 Transformer升级之路：2、博采众长的旋转式位置编码 - 科学空间|Scientific Spaces 十分钟读懂旋转编码（RoPE） - 知乎 多头注意力机制注意力机制是Transformer模型的核心，理解起来有相当大的困难。一个学习建议就是先将公式和实现代码背熟，知道具体是怎么计算的，再回去看有关解释的文章。 推导公式定义一个长度为N的输入序列： $$ \\mathbb{S}_N=\\{w_i\\}^{N}_{i=1} $$ 其实$w_i$表示输入序列中$i$个token，而输入序列$\\mathbb{S}_N$对应的embbedding表示为： $$ \\mathbb{E}_N=\\{x_i\\}^{N}_{i=1} $$ 其中 $x_i$ 表示第 $i$ 个token$w_i$ 对应的$d$维词嵌入向量。 接着在做 self-attention 之前，会用词嵌入向量计算 $q,k,v$ 向量同时加入位置信息，函数公式表达如下： $$\\begin{gathered}\\boldsymbol{q}_m=f_q(\\boldsymbol{x}_m,m) \\\\boldsymbol{k}_n=f_k(\\boldsymbol{x}_n,n) \\\\boldsymbol{v}_n=f_v(\\boldsymbol{x}_n,n)\\end{gathered}$$ 其中 $q_m$ 表示第 $m$ 个 token 对应的词向量 $x_m$ 集成位置信息$m$之后的 query 向量。而$k_n$和$v_n$则表示第n个token对应的词向量 $x_n$ 集成位置信息$n$之后的 key 和 value 向量。 而基于transformer的位置编码方法都是着重于构造一个合适的$f(q,k,v)$函数形式。 而计算第$m$个词嵌入向量 $x_m$ 对应的 self-attention 输出结果，就是$q_m$和其他$k_n$都计算一个 attention score ，然后再将 attention score 乘以对应的 $v_n$ 再求和得到输出向量$o_m$ ： $$ a_{m,n}=\\frac{\\exp(\\frac{q_m^\\mathrm{T}k_n}{\\sqrt{d}})}{\\sum_{j=1}^N\\exp(\\frac{q_m^\\mathrm{T}k_j}{\\sqrt{d}})}\\\\\\boldsymbol{o}_{m}=\\sum_{n=1}^Na_{m,n}\\boldsymbol{v}_n $$ Pytorch代码实现12345678910111213141516171819202122232425262728293031323334353637383940class MultiHeadAttention(nn.Module): def __init__(self, d_model, num_heads, dropout=0.1): super().__init__() assert d_model % num_heads == 0, &quot;d_model must be divisible by num_heads&quot; self.d_model = d_model self.num_heads = num_heads self.d_k = d_model // num_heads self.w_q = nn.Linear(d_model, d_model) self.w_k = nn.Linear(d_model, d_model) self.w_v = nn.Linear(d_model, d_model) self.w_o = nn.Linear(d_model, d_model) self.dropout = dropout self.scale = torch.sqrt(torch.FloatTensor([self.d_k])) def forward(self, q, k, v, mask=None): batch_size = q.size(0) q = self.w_q(q).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2) k = self.w_k(k).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2) v = self.w_v(v).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2) attn_scores = (q @ k.transpose(-2, -1)) / self.scale.to(q.device) if mask is not None: attn_scores = attn_scores.masked_fill(mask == 0, -1e9) attn_weights = F.softmax(attn_scores, dim=-1) attn_weights = self.dropout(attn_weights) output = attn_weights @ v output = output.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model) output = self.w_o(output) return output, attn_weights 相关阅读Q、K、V 与 Multi-Head Attention 多头注意力机制 - 知乎 深度探索：机器学习中的多头注意力机制（Multi-Head Attention）原理及应用-CSDN博客 十分钟读懂旋转编码（RoPE） - 知乎","link":"/2025/06/05/Transformer%E6%A8%A1%E5%9E%8B%E5%85%A5%E9%97%A8/"},{"title":"asio学习记录","text":"asio（Asynchronous Input/Output）是一个用于C++的跨平台库，主要用于网络和底层I/O编程。它提供了一套高效的异步I/O模型，使得开发者可以更轻松地编写高性能的网络应用。 第一部分：基础概念asio简介asion的基本概念和用途asio的主要特点包括： 跨平台支持：支持Windows、Linux和MacOS等多个平台。 异步操作：通过事件驱动的模型支持异步I/O操作。 可扩展性：可以与现有的第三方库（如Boost库）集成，增强功能。 高效性：通过减少阻塞和提高并发性来提高程序的性能。 同步与异步操作 同步操作：在执行I/O操作时，程序会阻塞当前线程，直到操作完成。同步操作简单易用，但在高并发情况下性能较低，因为线程会因等待I/O操作而浪费时间。 异步操作：在执行I/O操作时，程序不会阻塞当前线程，而是通过回调函数在操作完成时通知程序。异步操作可以提高并发性能，因为线程不会被阻塞，可以处理其他任务。 安装和配置在Windows、Linux和MacOS上安装asioasio可以单独安装，也可以作为Boost库的一部分进行安装。以下是安装步骤： Windows： 下载并安装Boost库：https://www.boost.org/users/download/ 在项目中包含asio头文件（通常位于boost/asio.hpp）。 Linux： 1sudo apt-get install libboost-all-dev 或者通过源码安装： 123456wget https://boostorg.jfrog.io/artifactory/main/release/1.75.0/source/boost_1_75_0.tar.gztar -xvzf boost_1_75_0.tar.gzcd boost_1_75_0./bootstrap.sh./b2sudo ./b2 install MacOS： 使用Homebrew安装Boost库： 1brew install boost 配置编译环境（使用CMake）使用CMake来配置asio项目的编译环境。以下是一个简单的CMakeLists.txt文件示例： 1234567891011cmake_minimum_required(VERSION 3.10)project(AsioExample)set(CMAKE_CXX_STANDARD 11)find_package(Boost 1.75 REQUIRED COMPONENTS system)include_directories(${Boost_INCLUDE_DIRS})add_executable(AsioExample main.cpp)target_link_libraries(AsioExample ${Boost_LIBRARIES}) 在CMakeLists.txt文件中，确保指定了Boost库的位置，并链接必要的Boost组件（如system）。 基本操作初始化asio在使用asio之前，需要初始化io_context对象。io_context是asio的核心，它提供了一个执行异步操作的机制。 123456#include &lt;boost/asio.hpp&gt;int main() { boost::asio::io_context io_context; return 0;} 使用io_context对象io_context对象负责管理所有的I/O操作。在执行任何异步操作之前，需要调用io_context的run()方法来启动I/O事件循环。 1234567891011#include &lt;boost/asio.hpp&gt;#include &lt;iostream&gt;int main() { boost::asio::io_context io_context; io_context.run(); std::cout &lt;&lt; &quot;I/O context has stopped.&quot; &lt;&lt; std::endl; return 0;} 在上面的例子中，io_context.run()会阻塞当前线程，直到没有更多的异步操作需要处理。 使用工作线程和执行器为了实现多线程环境中的异步操作，可以使用工作线程和执行器。asio提供了strand类来确保回调函数在同一个线程中顺序执行。 12345678910111213141516171819202122232425#include &lt;boost/asio.hpp&gt;#include &lt;thread&gt;#include &lt;vector&gt;#include &lt;iostream&gt;void worker(boost::asio::io_context&amp; io_context) { io_context.run();}int main() { boost::asio::io_context io_context; std::vector&lt;std::thread&gt; threads; for (int i = 0; i &lt; 4; ++i) { threads.emplace_back(worker, std::ref(io_context)); } for (auto&amp; thread : threads) { thread.join(); } std::cout &lt;&lt; &quot;All threads have stopped.&quot; &lt;&lt; std::endl; return 0;} 在上面的例子中，创建了多个工作线程，每个线程都运行io_context。这种方式可以提高并发性能，适用于高并发的网络应用。 第二部分：同步操作同步TCP编程创建同步TCP客户端和服务器 同步TCP服务器： 一个简单的同步TCP服务器会等待客户端连接，接受连接后进行数据通信。 12345678910111213141516171819202122232425262728293031323334#include &lt;iostream&gt;#include &lt;boost/asio.hpp&gt;using boost::asio::ip::tcp;int main() { try { boost::asio::io_context io_context; tcp::acceptor acceptor(io_context, tcp::endpoint(tcp::v4(), 12345)); std::cout &lt;&lt; &quot;Server is running on port 12345&quot; &lt;&lt; std::endl; while (true) { tcp::socket socket(io_context); acceptor.accept(socket); std::cout &lt;&lt; &quot;Client connected&quot; &lt;&lt; std::endl; boost::system::error_code error; std::string message = &quot;Hello from server!&quot;; boost::asio::write(socket, boost::asio::buffer(message), error); if (error) { std::cerr &lt;&lt; &quot;Error on write: &quot; &lt;&lt; error.message() &lt;&lt; std::endl; } socket.close(); } } catch (std::exception&amp; e) { std::cerr &lt;&lt; &quot;Exception: &quot; &lt;&lt; e.what() &lt;&lt; std::endl; } return 0;} 同步TCP客户端： 一个简单的同步TCP客户端会连接到服务器并接收数据。 123456789101112131415161718192021222324252627282930313233#include &lt;iostream&gt;#include &lt;boost/asio.hpp&gt;using boost::asio::ip::tcp;int main() { try { boost::asio::io_context io_context; tcp::resolver resolver(io_context); tcp::resolver::results_type endpoints = resolver.resolve(&quot;127.0.0.1&quot;, &quot;12345&quot;); tcp::socket socket(io_context); boost::asio::connect(socket, endpoints); boost::system::error_code error; char reply[128]; size_t reply_length = boost::asio::read(socket, boost::asio::buffer(reply), error); if (error) { std::cerr &lt;&lt; &quot;Error on read: &quot; &lt;&lt; error.message() &lt;&lt; std::endl; } else { std::cout &lt;&lt; &quot;Reply from server: &quot; &lt;&lt; std::string(reply, reply_length) &lt;&lt; std::endl; } socket.close(); } catch (std::exception&amp; e) { std::cerr &lt;&lt; &quot;Exception: &quot; &lt;&lt; e.what() &lt;&lt; std::endl; } return 0;} 连接、发送和接收数据 连接： 在客户端中使用boost::asio::connect函数连接到服务器。服务器端使用acceptor.accept(socket)接受客户端连接。 发送数据： 使用boost::asio::write函数将数据发送到已连接的socket。 接收数据： 使用boost::asio::read函数从socket中接收数据。 处理错误在进行I/O操作时，可能会发生各种错误，如连接失败、读写失败等。可以通过boost::system::error_code对象捕获和处理这些错误。 1234567boost::system::error_code error;boost::asio::write(socket, boost::asio::buffer(message), error);if (error) { std::cerr &lt;&lt; &quot;Error on write: &quot; &lt;&lt; error.message() &lt;&lt; std::endl;} 同步UDP编程创建同步UDP客户端和服务器 同步UDP服务器： 一个简单的同步UDP服务器会接收数据报并发送响应。 1234567891011121314151617181920212223242526272829#include &lt;iostream&gt;#include &lt;boost/asio.hpp&gt;using boost::asio::ip::udp;int main() { try { boost::asio::io_context io_context; udp::socket socket(io_context, udp::endpoint(udp::v4(), 12345)); std::cout &lt;&lt; &quot;UDP Server is running on port 12345&quot; &lt;&lt; std::endl; while (true) { char data[1024]; udp::endpoint sender_endpoint; size_t length = socket.receive_from(boost::asio::buffer(data), sender_endpoint); std::cout &lt;&lt; &quot;Received: &quot; &lt;&lt; std::string(data, length) &lt;&lt; std::endl; std::string response = &quot;Hello from UDP server!&quot;; socket.send_to(boost::asio::buffer(response), sender_endpoint); } } catch (std::exception&amp; e) { std::cerr &lt;&lt; &quot;Exception: &quot; &lt;&lt; e.what() &lt;&lt; std::endl; } return 0;} 同步UDP客户端： 一个简单的同步UDP客户端会发送数据报并接收响应。 1234567891011121314151617181920212223242526272829303132#include &lt;iostream&gt;#include &lt;boost/asio.hpp&gt;using boost::asio::ip::udp;int main() { try { boost::asio::io_context io_context; udp::resolver resolver(io_context); udp::resolver::results_type endpoints = resolver.resolve(udp::v4(), &quot;127.0.0.1&quot;, &quot;12345&quot;); udp::socket socket(io_context); socket.open(udp::v4()); std::string request = &quot;Hello from UDP client!&quot;; socket.send_to(boost::asio::buffer(request), *endpoints.begin()); char reply[1024]; udp::endpoint sender_endpoint; size_t reply_length = socket.receive_from(boost::asio::buffer(reply), sender_endpoint); std::cout &lt;&lt; &quot;Reply from server: &quot; &lt;&lt; std::string(reply, reply_length) &lt;&lt; std::endl; socket.close(); } catch (std::exception&amp; e) { std::cerr &lt;&lt; &quot;Exception: &quot; &lt;&lt; e.what() &lt;&lt; std::endl; } return 0;} 发送和接收数据报 发送数据报： 使用socket.send_to函数发送数据报到指定的UDP端点。 接收数据报： 使用socket.receive_from函数接收来自指定端点的数据报。 处理错误与同步TCP编程类似，同步UDP编程也需要处理可能的I/O错误。同样可以使用boost::system::error_code对象捕获和处理这些错误。 1234567boost::system::error_code error;socket.send_to(boost::asio::buffer(request), *endpoints.begin(), 0, error);if (error) { std::cerr &lt;&lt; &quot;Error on send: &quot; &lt;&lt; error.message() &lt;&lt; std::endl;} 其他同步类型1. 定时器Boost.Asio提供了高精度的定时器，可以用于执行定时操作。 123456789101112131415161718#include &lt;iostream&gt;#include &lt;boost/asio.hpp&gt;void print(const boost::system::error_code&amp;/*e*/) { std::cout &lt;&lt; &quot;Hello, world!&quot; &lt;&lt; std::endl;}int main() { boost::asio::io_context io_context; boost::asio::steady_timer timer(io_context, boost::asio::chrono::seconds(5)); timer.async_wait(&amp;print); io_context.run(); return 0;} 2. 信号处理Boost.Asio可以处理操作系统信号，例如SIGINT和SIGTERM。 1234567891011121314151617181920#include &lt;iostream&gt;#include &lt;boost/asio.hpp&gt;void handle_signal(const boost::system::error_code&amp; error, int signal_number) { if (!error) { std::cout &lt;&lt; &quot;Received signal: &quot; &lt;&lt; signal_number &lt;&lt; std::endl; }}int main() { boost::asio::io_context io_context; boost::asio::signal_set signals(io_context, SIGINT, SIGTERM); signals.async_wait(handle_signal); io_context.run(); return 0;} 3. 文件I/O虽然Boost.Asio主要用于网络编程，但也支持异步文件I/O操作。需要注意的是，这部分功能在某些平台上的支持可能有限。 4. 串行通信Boost.Asio支持与串行端口进行通信，这对于与硬件设备的通信非常有用。 1234567891011121314151617181920212223#include &lt;iostream&gt;#include &lt;boost/asio.hpp&gt;void read_handler(const boost::system::error_code&amp; error, std::size_t bytes_transferred) { if (!error) { std::cout &lt;&lt; &quot;Read &quot; &lt;&lt; bytes_transferred &lt;&lt; &quot; bytes&quot; &lt;&lt; std::endl; }}int main() { boost::asio::io_context io_context; boost::asio::serial_port serial(io_context, &quot;/dev/ttyS0&quot;); serial.set_option(boost::asio::serial_port_base::baud_rate(9600)); char data[128]; boost::asio::async_read(serial, boost::asio::buffer(data), read_handler); io_context.run(); return 0;} 5. DNS解析Boost.Asio提供了域名解析功能，可以将域名解析为IP地址。 12345678910111213141516#include &lt;iostream&gt;#include &lt;boost/asio.hpp&gt;int main() { boost::asio::io_context io_context; boost::asio::ip::tcp::resolver resolver(io_context); boost::asio::ip::tcp::resolver::results_type endpoints = resolver.resolve(&quot;www.example.com&quot;, &quot;80&quot;); for (const auto&amp; endpoint : endpoints) { std::cout &lt;&lt; endpoint.endpoint() &lt;&lt; std::endl; } return 0;} 6. 自定义协议除了TCP和UDP，Boost.Asio还支持实现自定义协议。你可以根据需要定义自己的数据传输方式和数据格式。 第三部分：异步操作在异步编程中，程序可以在等待I/O操作完成的同时执行其他任务，这样可以提高程序的效率和响应速度。Boost.Asio通过提供异步操作模型来支持异步编程。以下是详细讲解。 异步操作基础异步操作模型Boost.Asio的异步操作是基于回调函数的。当一个异步操作开始时，程序会立即返回，并在操作完成时调用预先指定的回调函数。 1234567boost::asio::io_context io_context;boost::asio::steady_timer timer(io_context, boost::asio::chrono::seconds(5));timer.async_wait([](const boost::system::error_code&amp;/*e*/) { std::cout &lt;&lt; &quot;Timer expired!&quot; &lt;&lt; std::endl;});io_context.run(); 使用异步回调函数异步回调函数是当异步操作完成时被调用的函数。回调函数通常接受一个boost::system::error_code参数，用于检查操作是否成功。 123456void on_timer_expired(const boost::system::error_code&amp; error) { if (!error) { std::cout &lt;&lt; &quot;Timer expired!&quot; &lt;&lt; std::endl; }} 异步TCP编程创建异步TCP客户端和服务器在Boost.Asio中，可以使用boost::asio::ip::tcp::socket创建TCP客户端和服务器，并使用异步操作函数进行数据传输。 异步TCP服务器123456789101112131415161718192021#include &lt;boost/asio.hpp&gt;#include &lt;iostream&gt;void handle_accept(const boost::system::error_code&amp; error) { if (!error) { std::cout &lt;&lt; &quot;Client connected!&quot; &lt;&lt; std::endl; }}int main() { boost::asio::io_context io_context; boost::asio::ip::tcp::acceptor acceptor(io_context, boost::asio::ip::tcp::endpoint(boost::asio::ip::tcp::v4(), 12345)); boost::asio::ip::tcp::socket socket(io_context); acceptor.async_accept(socket, handle_accept); io_context.run(); return 0;} 异步TCP客户端12345678910111213141516171819202122#include &lt;boost/asio.hpp&gt;#include &lt;iostream&gt;void handle_connect(const boost::system::error_code&amp; error) { if (!error) { std::cout &lt;&lt; &quot;Connected to server!&quot; &lt;&lt; std::endl; }}int main() { boost::asio::io_context io_context; boost::asio::ip::tcp::resolver resolver(io_context); boost::asio::ip::tcp::resolver::results_type endpoints = resolver.resolve(&quot;localhost&quot;, &quot;12345&quot;); boost::asio::ip::tcp::socket socket(io_context); boost::asio::async_connect(socket, endpoints, handle_connect); io_context.run(); return 0;} 异步连接、发送和接收数据异步发送数据12345678void handle_write(const boost::system::error_code&amp; error, std::size_t bytes_transferred) { if (!error) { std::cout &lt;&lt; &quot;Sent &quot; &lt;&lt; bytes_transferred &lt;&lt; &quot; bytes&quot; &lt;&lt; std::endl; }}socket.async_send(boost::asio::buffer(&quot;Hello, server!&quot;), handle_write); 异步接收数据123456789void handle_read(const boost::system::error_code&amp; error, std::size_t bytes_transferred) { if (!error) { std::cout &lt;&lt; &quot;Received &quot; &lt;&lt; bytes_transferred &lt;&lt; &quot; bytes&quot; &lt;&lt; std::endl; }}boost::asio::streambuf buffer;boost::asio::async_read(socket, buffer, handle_read); 使用strand确保线程安全Boost.Asio提供了strand来确保多个异步操作的顺序执行，以避免多线程环境中的数据竞争。 123456789boost::asio::strand&lt;boost::asio::io_context::executor_type&gt; strand(io_context.get_executor());void safe_async_operation() { socket.async_send(boost::asio::buffer(&quot;Hello, server!&quot;), boost::asio::bind_executor(strand, handle_write)); socket.async_receive(boost::asio::buffer(data), boost::asio::bind_executor(strand, handle_read));} 异步UDP编程创建异步UDP客户端和服务器异步UDP编程类似于TCP编程，但数据传输单位是数据报。 异步UDP服务器12345678910111213141516171819202122#include &lt;boost/asio.hpp&gt;#include &lt;iostream&gt;void handle_receive(const boost::system::error_code&amp; error, std::size_t bytes_transferred) { if (!error) { std::cout &lt;&lt; &quot;Received &quot; &lt;&lt; bytes_transferred &lt;&lt; &quot; bytes&quot; &lt;&lt; std::endl; }}int main() { boost::asio::io_context io_context; boost::asio::ip::udp::socket socket(io_context, boost::asio::ip::udp::endpoint(boost::asio::ip::udp::v4(), 12345)); boost::asio::ip::udp::endpoint sender_endpoint; char data[1024]; socket.async_receive_from(boost::asio::buffer(data, 1024), sender_endpoint, handle_receive); io_context.run(); return 0;} 异步UDP客户端1234567891011121314151617181920212223#include &lt;boost/asio.hpp&gt;#include &lt;iostream&gt;void handle_send(const boost::system::error_code&amp; error, std::size_t bytes_transferred) { if (!error) { std::cout &lt;&lt; &quot;Sent &quot; &lt;&lt; bytes_transferred &lt;&lt; &quot; bytes&quot; &lt;&lt; std::endl; }}int main() { boost::asio::io_context io_context; boost::asio::ip::udp::resolver resolver(io_context); boost::asio::ip::udp::resolver::results_type endpoints = resolver.resolve(boost::asio::ip::udp::v4(), &quot;localhost&quot;, &quot;12345&quot;); boost::asio::ip::udp::socket socket(io_context); const std::string message = &quot;Hello, server!&quot;; socket.async_send_to(boost::asio::buffer(message), *endpoints.begin(), handle_send); io_context.run(); return 0;} 异步发送和接收数据报异步发送数据报12345678void handle_send(const boost::system::error_code&amp; error, std::size_t bytes_transferred) { if (!error) { std::cout &lt;&lt; &quot;Sent &quot; &lt;&lt; bytes_transferred &lt;&lt; &quot; bytes&quot; &lt;&lt; std::endl; }}socket.async_send_to(boost::asio::buffer(&quot;Hello, server!&quot;), endpoint, handle_send); 异步接收数据报12345678910void handle_receive(const boost::system::error_code&amp; error, std::size_t bytes_transferred) { if (!error) { std::cout &lt;&lt; &quot;Received &quot; &lt;&lt; bytes_transferred &lt;&lt; &quot; bytes&quot; &lt;&lt; std::endl; }}boost::asio::ip::udp::endpoint sender_endpoint;char data[1024];socket.async_receive_from(boost::asio::buffer(data, 1024), sender_endpoint, handle_receive); 第四部分：高级主题定时器在Boost.Asio中，定时器可以用来实现延迟和周期性任务。主要有两种类型的定时器：steady_timer和deadline_timer。 使用 steady_timer 和 deadline_timer steady_timer 用于相对时间的定时操作，即从当前时间开始计算的一段时间后触发。 deadline_timer 用于绝对时间的定时操作，即在一个指定的时间点触发。 123456789101112131415#include &lt;boost/asio.hpp&gt;#include &lt;iostream&gt;void print(const boost::system::error_code&amp;/*e*/) { std::cout &lt;&lt; &quot;Hello, World!&quot; &lt;&lt; std::endl;}int main() { boost::asio::io_context io_context; boost::asio::steady_timer timer(io_context, boost::asio::chrono::seconds(5)); timer.async_wait(print); io_context.run(); return 0;} 123456789101112131415#include &lt;boost/asio.hpp&gt;#include &lt;iostream&gt;void print(const boost::system::error_code&amp;/*e*/) { std::cout &lt;&lt; &quot;Hello, World!&quot; &lt;&lt; std::endl;}int main() { boost::asio::io_context io_context; boost::asio::deadline_timer timer(io_context, boost::posix_time::seconds(5)); timer.async_wait(print); io_context.run(); return 0;} 实现延迟和周期性任务延迟任务通过设置定时器并等待它过期，可以实现延迟任务。 12345678void delayed_task() { boost::asio::steady_timer timer(io_context, boost::asio::chrono::seconds(5)); timer.async_wait([](const boost::system::error_code&amp;/*e*/) { std::cout &lt;&lt; &quot;Task executed after delay!&quot; &lt;&lt; std::endl; }); io_context.run();} 周期性任务周期性任务可以通过在回调函数内再次启动定时器来实现。 123456789101112131415161718void periodic_task(const boost::system::error_code&amp;/*e*/, boost::asio::steady_timer&amp; timer) { std::cout &lt;&lt; &quot;Periodic task executed!&quot; &lt;&lt; std::endl; timer.expires_after(boost::asio::chrono::seconds(5)); timer.async_wait([&amp;timer](const boost::system::error_code&amp; error) { periodic_task(error, timer); });}int main() { boost::asio::io_context io_context; boost::asio::steady_timer timer(io_context, boost::asio::chrono::seconds(5)); timer.async_wait([&amp;timer](const boost::system::error_code&amp; error) { periodic_task(error, timer); }); io_context.run(); return 0;} 异步信号处理Boost.Asio允许捕捉和处理系统信号，如SIGINT和SIGTERM，这在编写需要平滑退出的应用程序时非常有用。 示例：捕捉和处理系统信号1234567891011121314151617#include &lt;boost/asio.hpp&gt;#include &lt;iostream&gt;void signal_handler(const boost::system::error_code&amp; error, int signal_number) { if (!error) { std::cout &lt;&lt; &quot;Signal received: &quot; &lt;&lt; signal_number &lt;&lt; std::endl; }}int main() { boost::asio::io_context io_context; boost::asio::signal_set signals(io_context, SIGINT, SIGTERM); signals.async_wait(signal_handler); io_context.run(); return 0;} 并发与多线程在多线程环境中使用Boost.Asio时，需要注意线程安全问题。可以通过strand和适当的io_context管理来确保安全。 在多线程环境中使用 asio12345678910111213141516171819202122#include &lt;boost/asio.hpp&gt;#include &lt;thread&gt;#include &lt;vector&gt;void worker_thread(boost::asio::io_context&amp; io_context) { io_context.run();}int main() { boost::asio::io_context io_context; std::vector&lt;std::thread&gt; threads; for (int i = 0; i &lt; 4; ++i) { threads.emplace_back(worker_thread, std::ref(io_context)); } io_context.run(); for (auto&amp; thread : threads) { thread.join(); } return 0;} strand 和 io_context 的线程安全问题strand 用于序列化多个异步操作，确保它们不会同时运行，避免数据竞争问题。 示例：使用 strand 保证线程安全12345678910boost::asio::io_context io_context;boost::asio::strand&lt;boost::asio::io_context::executor_type&gt; strand(io_context.get_executor());void safe_async_operation() { socket.async_send(boost::asio::buffer(&quot;Hello, server!&quot;), boost::asio::bind_executor(strand, handle_write)); socket.async_receive(boost::asio::buffer(data), boost::asio::bind_executor(strand, handle_read));} 通过以上示例，可以看到如何使用Boost.Asio中的高级功能来处理定时任务、异步信号和并发编程。理解和使用这些高级主题，可以编写出更为高效和可靠的异步应用程序。 第五部分：实战项目实现一个简单的聊天室在这个项目中，我们将使用 TCP 协议来创建一个多客户端的聊天室，并实现消息广播功能。 步骤 1：创建服务器类首先，我们需要创建一个 ChatServer 类来管理客户端连接和消息广播。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#include &lt;boost/asio.hpp&gt;#include &lt;iostream&gt;#include &lt;set&gt;#include &lt;memory&gt;using boost::asio::ip::tcp;class ChatServer {public: ChatServer(boost::asio::io_context&amp; io_context, const tcp::endpoint&amp; endpoint) : acceptor_(io_context, endpoint) { start_accept(); }private: void start_accept() { auto new_connection = std::make_shared&lt;tcp::socket&gt;(acceptor_.get_executor().context()); acceptor_.async_accept(*new_connection, [this, new_connection](const boost::system::error_code&amp; error) { if (!error) { connections_.insert(new_connection); start_read(new_connection); } start_accept(); }); } void start_read(std::shared_ptr&lt;tcp::socket&gt; socket) { auto buffer = std::make_shared&lt;boost::asio::streambuf&gt;(); boost::asio::async_read_until(*socket, *buffer, &quot;\\n&quot;, [this, socket, buffer](const boost::system::error_code&amp; error, std::size_t) { if (!error) { std::istream is(buffer.get()); std::string message; std::getline(is, message); broadcast_message(message); start_read(socket); } else { connections_.erase(socket); } }); } void broadcast_message(const std::string&amp; message) { for (auto&amp; connection : connections_) { boost::asio::async_write(*connection, boost::asio::buffer(message + &quot;\\n&quot;), [](const boost::system::error_code&amp;, std::size_t) {}); } } tcp::acceptor acceptor_; std::set&lt;std::shared_ptr&lt;tcp::socket&gt;&gt; connections_;}; 步骤 2：运行服务器123456789101112131415#include &lt;boost/asio.hpp&gt;#include &lt;iostream&gt;int main() { try { boost::asio::io_context io_context; tcp::endpoint endpoint(tcp::v4(), 12345); ChatServer server(io_context, endpoint); io_context.run(); } catch (std::exception&amp; e) { std::cerr &lt;&lt; &quot;Exception: &quot; &lt;&lt; e.what() &lt;&lt; std::endl; } return 0;} 文件传输应用步骤 1：文件上传和下载服务器我们将实现一个简单的服务器，用于接收和发送文件。 12345678910111213141516171819202122232425262728293031#include &lt;boost/asio.hpp&gt;#include &lt;fstream&gt;#include &lt;iostream&gt;using boost::asio::ip::tcp;class FileServer {public: FileServer(boost::asio::io_context&amp; io_context, const tcp::endpoint&amp; endpoint) : acceptor_(io_context, endpoint) { start_accept(); }private: void start_accept() { auto new_connection = std::make_shared&lt;tcp::socket&gt;(acceptor_.get_executor().context()); acceptor_.async_accept(*new_connection, [this, new_connection](const boost::system::error_code&amp; error) { if (!error) { handle_client(new_connection); } start_accept(); }); } void handle_client(std::shared_ptr&lt;tcp::socket&gt; socket) {// Handle file upload or download here } tcp::acceptor acceptor_;}; 步骤 2：处理文件上传和下载1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950void handle_client(std::shared_ptr&lt;tcp::socket&gt; socket) { auto buffer = std::make_shared&lt;boost::asio::streambuf&gt;(); boost::asio::async_read_until(*socket, *buffer, &quot;\\n&quot;, [this, socket, buffer](const boost::system::error_code&amp; error, std::size_t) { if (!error) { std::istream is(buffer.get()); std::string command; std::getline(is, command); if (command == &quot;UPLOAD&quot;) { handle_upload(socket); } else if (command == &quot;DOWNLOAD&quot;) { handle_download(socket); } } });}void handle_upload(std::shared_ptr&lt;tcp::socket&gt; socket) { auto buffer = std::make_shared&lt;boost::asio::streambuf&gt;(); boost::asio::async_read_until(*socket, *buffer, &quot;\\n&quot;, [this, socket, buffer](const boost::system::error_code&amp; error, std::size_t) { if (!error) { std::istream is(buffer.get()); std::string filename; std::getline(is, filename); std::ofstream ofs(filename, std::ios::binary); boost::asio::async_read(*socket, boost::asio::transfer_all(), [this, socket, &amp;ofs](const boost::system::error_code&amp; error, std::size_t bytes_transferred) { if (!error) { ofs.write(boost::asio::buffer_cast&lt;const char*&gt;(buffer-&gt;data()), bytes_transferred); } ofs.close(); }); } });}void handle_download(std::shared_ptr&lt;tcp::socket&gt; socket) { auto buffer = std::make_shared&lt;boost::asio::streambuf&gt;(); boost::asio::async_read_until(*socket, *buffer, &quot;\\n&quot;, [this, socket, buffer](const boost::system::error_code&amp; error, std::size_t) { if (!error) { std::istream is(buffer.get()); std::string filename; std::getline(is, filename); std::ifstream ifs(filename, std::ios::binary); if (ifs) { auto data = std::make_shared&lt;std::vector&lt;char&gt;&gt;(std::istreambuf_iterator&lt;char&gt;(ifs), {}); boost::asio::async_write(*socket, boost::asio::buffer(*data), [](const boost::system::error_code&amp;, std::size_t) {}); } } });} HTTP 服务器步骤 1：创建 HTTP 服务器类我们将实现一个简单的 HTTP 服务器，处理 GET 和 POST 请求。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960#include &lt;boost/asio.hpp&gt;#include &lt;iostream&gt;#include &lt;string&gt;using boost::asio::ip::tcp;class HttpServer {public: HttpServer(boost::asio::io_context&amp; io_context, const tcp::endpoint&amp; endpoint) : acceptor_(io_context, endpoint) { start_accept(); }private: void start_accept() { auto new_connection = std::make_shared&lt;tcp::socket&gt;(acceptor_.get_executor().context()); acceptor_.async_accept(*new_connection, [this, new_connection](const boost::system::error_code&amp; error) { if (!error) { handle_request(new_connection); } start_accept(); }); } void handle_request(std::shared_ptr&lt;tcp::socket&gt; socket) { auto buffer = std::make_shared&lt;boost::asio::streambuf&gt;(); boost::asio::async_read_until(*socket, *buffer, &quot;\\r\\n\\r\\n&quot;, [this, socket, buffer](const boost::system::error_code&amp; error, std::size_t) { if (!error) { std::istream is(buffer.get()); std::string request_line; std::getline(is, request_line); std::string method, uri, version; std::istringstream request_stream(request_line); request_stream &gt;&gt; method &gt;&gt; uri &gt;&gt; version; if (method == &quot;GET&quot;) { handle_get(socket, uri); } else if (method == &quot;POST&quot;) { handle_post(socket, buffer); } } }); } void handle_get(std::shared_ptr&lt;tcp::socket&gt; socket, const std::string&amp; uri) { std::string response = &quot;HTTP/1.1 200 OK\\r\\nContent-Type: text/plain\\r\\n\\r\\nHello, World!&quot;; boost::asio::async_write(*socket, boost::asio::buffer(response), [socket](const boost::system::error_code&amp;, std::size_t) {}); } void handle_post(std::shared_ptr&lt;tcp::socket&gt; socket, std::shared_ptr&lt;boost::asio::streambuf&gt; buffer) { std::istream is(buffer.get()); std::string body((std::istreambuf_iterator&lt;char&gt;(is)), std::istreambuf_iterator&lt;char&gt;()); std::cout &lt;&lt; &quot;Received POST data: &quot; &lt;&lt; body &lt;&lt; std::endl; std::string response = &quot;HTTP/1.1 200 OK\\r\\nContent-Type: text/plain\\r\\n\\r\\nPOST data received&quot;; boost::asio::async_write(*socket, boost::asio::buffer(response), [socket](const boost::system::error_code&amp;, std::size_t) {}); } tcp::acceptor acceptor_;}; 步骤 2：运行 HTTP 服务器123456789101112int main() { try { boost::asio::io_context io_context; tcp::endpoint endpoint(tcp::v4(), 8080); HttpServer server(io_context, endpoint); io_context.run(); } catch (std::exception&amp; e) { std::cerr &lt;&lt; &quot;Exception: &quot; &lt;&lt; e.what() &lt;&lt; std::endl; } return 0;} 以上三个实战项目展示了如何使用 Boost.Asio 实现多客户端聊天室、文件传输应用和 HTTP 服务器。 第六部分：优化与调试性能优化优化Boost.Asio程序的性能对于构建高效、低延迟、高吞吐量的网络应用非常重要。以下是一些关键策略和方法： 分析和优化Asio程序的性能异步操作 确保尽可能使用异步操作（如 async_read 和 async_write），以充分利用I/O操作的非阻塞特性。避免使用同步操作（如 read 和 write），因为它们会阻塞线程，导致性能瓶颈。 减少内存分配 频繁的内存分配和释放会显著影响性能。可以使用内存池或对象池来管理内存，从而减少分配和释放的开销。Boost.Asio提供了 boost::asio::io_context::strand 类，用于确保异步操作在同一线程内顺序执行，减少了竞争和上下文切换的开销。 123boost::asio::io_context io_context;boost::asio::io_context::strand strand(io_context); 调整线程数 合理配置线程池的大小，以充分利用多核处理器的优势。一般来说，线程数应等于或略大于处理器的核心数。 1234567std::vector&lt;std::thread&gt; threads;for (std::size_t i = 0; i &lt; num_threads; ++i) { threads.emplace_back([&amp;io_context]() { io_context.run(); });}for (auto&amp; thread : threads) { thread.join();} 使用高效的I/O模型 对于高并发场景，可以使用 epoll（Linux）、kqueue（FreeBSD、macOS）或 IOCP（Windows）等高效的I/O复用技术。Boost.Asio在后台已经实现了这些技术，但在特定平台上需要确保编译时启用了相应的选项。 减少延迟和提高吞吐量减少上下文切换 尽量减少线程之间的上下文切换。可以通过绑定任务到特定的线程来实现，确保特定任务在同一线程内顺序执行。 1234boost::asio::post(strand, []() {// Task to be executed in the context of strand}); 优化数据传输 对于大文件传输，可以使用分块传输技术，将大文件分成多个小块进行传输，避免一次性传输带来的延迟和内存占用问题。 12345678void send_file_in_chunks(std::shared_ptr&lt;tcp::socket&gt; socket, const std::string&amp; file_path) { std::ifstream file(file_path, std::ios::binary); std::vector&lt;char&gt; buffer(1024); while (file.read(buffer.data(), buffer.size())) { boost::asio::write(*socket, boost::asio::buffer(buffer.data(), file.gcount())); }} 优化消息处理 对于消息广播，可以使用批处理或压缩技术，减少网络传输的次数和数据量，从而提高吞吐量。 12345678void broadcast_messages(const std::vector&lt;std::string&gt;&amp; messages) { std::string batch; for (const auto&amp; msg : messages) { batch += msg + &quot;\\n&quot;; } boost::asio::async_write(*socket, boost::asio::buffer(batch), [](const boost::system::error_code&amp;, std::size_t) {});} 2. 调试技巧调试Boost.Asio程序需要了解常见问题及其解决方案，并使用调试工具分析网络流量。以下是一些常用的调试技巧： 常见问题和解决方案1. 数据丢失或顺序错误在异步操作中，数据丢失或顺序错误通常是由于没有正确管理缓冲区或异步操作之间的依赖关系。确保每个异步操作完成后再启动下一个操作，并使用 strand 来保证操作顺序。 1234boost::asio::post(strand, [this]() { start_read();}); 2. 连接超时或失败连接超时或失败可能是由于网络问题或资源耗尽。可以设置超时时间并实现重试机制。 12345678boost::asio::steady_timer timer(io_context);timer.expires_after(std::chrono::seconds(5));timer.async_wait([socket](const boost::system::error_code&amp; error) { if (!error) { socket-&gt;close(); }}); 3. 内存泄漏内存泄漏通常是由于未正确释放资源。使用智能指针（如 std::shared_ptr 和 std::unique_ptr）来管理动态分配的内存，确保资源在超出作用域时自动释放。 使用调试工具分析网络流量1. WiresharkWireshark是一个强大的网络协议分析工具，可以捕获和分析网络流量。通过Wireshark，可以实时查看网络包，分析协议层次，找出潜在问题。 2. Boost.Asio的调试输出Boost.Asio支持调试输出，可以在编译时启用 BOOST_ASIO_ENABLE_HANDLER_TRACKING 宏，以便输出详细的操作日志，帮助分析异步操作的执行顺序和状态。 123#define BOOST_ASIO_ENABLE_HANDLER_TRACKING#include &lt;boost/asio.hpp&gt; 3. GDB和LLDB使用GDB（Linux）或LLDB（macOS）调试Boost.Asio程序，可以设置断点、查看变量、分析栈帧等，帮助排查问题。 1gdb ./your_program 通过以上性能优化和调试技巧，可以有效提高Boost.Asio程序的性能和稳定性，构建高效、可靠的网络应用。","link":"/2024/07/09/asio%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"title":"c++时间类型","text":"时间类型可以说是非常常用的类型，在使用的过程中经常感觉掌握的不够全面，这里梳理一下，作为记录。 C风格时间tm结构体在C++11之前，标准库中并没有提供专门的时间和日期类型。为了处理时间和日期，开发者通常会C语言提供的时间和类型。现在C++项目基本上都使用了C++11及更高的版本，但是一些古早的代码或者库接口还是能看到C风格的时间。 为了使用C语言踢狗的日期和时间相关的函数和结构，需要在 C++ 程序中引用 &lt;ctime&gt; 头文件。 有四个与时间相关的类型：clock_t、time_t、size_t 和 tm。类型 clock_t、size_t 和 time_t 能够把系统时间和日期表示为某种整数。 结构类型 tm 把日期和时间以 C 结构的形式保存，tm 结构的定义如下： 1234567891011struct tm { int tm_sec; // 秒，正常范围从 0 到 59，但允许至 61 int tm_min; // 分，范围从 0 到 59 int tm_hour; // 小时，范围从 0 到 23 int tm_mday; // 一月中的第几天，范围从 1 到 31 int tm_mon; // 月，范围从 0 到 11 int tm_year; // 自 1900 年起的年数 int tm_wday; // 一周中的第几天，范围从 0 到 6，从星期日算起 int tm_yday; // 一年中的第几天，范围从 0 到 365，从 1 月 1 日算起 int tm_isdst; // 夏令时}; 相关函数一些跟C风格时间有关的函数如下： 序号 函数 &amp; 描述 time_t time(time_t *time); 该函数返回系统的当前日历时间，自 1970 年 1 月 1 日以来经过的秒数。如果系统没有时间，则返回 -1。 char *ctime(const time_t *time); 该返回一个表示当地时间的字符串指针，字符串形式 day month year hours:minutes:seconds year\\n\\0。 struct tm *localtime(const time_t *time); 该函数返回一个指向表示本地时间的 tm 结构的指针。 clock_t clock(void); 该函数返回程序执行起（一般为程序的开头），处理器时钟所使用的时间。如果时间不可用，则返回 -1。 char * asctime ( const struct tm * time ); 该函数返回一个指向字符串的指针，字符串包含了 time 所指向结构中存储的信息，返回形式为：day month date hours:minutes:seconds year\\n\\0。 struct tm *gmtime(const time_t *time); 该函数返回一个指向 time 的指针，time 为 tm 结构，用协调世界时（UTC）也被称为格林尼治标准时间（GMT）表示。 time_t mktime(struct tm *time); 该函数返回日历时间，相当于 time 所指向结构中存储的时间。 double difftime ( time_t time2, time_t time1 ); 该函数返回 time1 和 time2 之间相差的秒数。 size_t strftime(); 该函数可用于格式化日期和时间为指定的格式。 格式化成字符串： 123456time_t now = time(NULL);struct tm *tm_now = localtime(&amp;now);char buffer[80];strftime(buffer, sizeof(buffer), &quot;%Y-%m-%d %H:%M:%S&quot;, tm_now);printf(&quot;Formatted time: %s\\n&quot;, buffer); C++11之后提供了string格式化函数put_time用法如下 1234567891011121314151617181920#include &lt;iostream&gt;#include &lt;iomanip&gt; // 包含 put_time 的头文件#include &lt;ctime&gt;#include &lt;sstream&gt; // 包含 ostringstream 的头文件int main() { // 获取当前时间 std::time_t now = std::time(nullptr); std::tm tm_now = *std::localtime(&amp;now); // 使用 ostringstream 和 put_time 格式化时间 std::ostringstream oss; oss &lt;&lt; std::put_time(&amp;tm_now, &quot;%Y-%m-%d %H:%M:%S&quot;); std::string formatted_time = oss.str(); // 输出格式化的时间 std::cout &lt;&lt; &quot;Formatted time: &quot; &lt;&lt; formatted_time &lt;&lt; std::endl; return 0;} 字符串格式化成时间： 123456const char *time_string = &quot;2023-10-07 14:30:00&quot;;struct tm tm_time;char *result;// 使用 strptime 将字符串解析为 tm 结构体result = strptime(time_string, &quot;%Y-%m-%d %H:%M:%S&quot;, &amp;tm_time); 用例用时间类函数给代码片段计时： 123456789101112131415161718192021#include &lt;stdio.h&gt;#include &lt;time.h&gt;int main() { time_t start, end; double elapsed; time(&amp;start); // 获取开始时间 // 这里放置需要计时的代码 for (int i = 0; i &lt; 100000000; i++) { // 一些耗时操作 } time(&amp;end); // 获取结束时间 elapsed = difftime(end, start); // 计算时间差 printf(&quot;Elapsed time: %.2f seconds\\n&quot;, elapsed); return 0;} 这种方法虽然简单易用，但是实际上这种计时方法只能精确到秒级，如果想要精确到毫秒级需要使用POSIX提供的gettimeofday函数和timeval结构体 timeval结构体timeval结构体非常简单，只由两个成员变量组成 1234struct timeval { time_t tv_sec; // 秒 suseconds_t tv_usec; // 微秒}; 相关函数gettimeofday() 函数是POSIX标准的一部分，用于获取当前时间，精度可以达到微秒级别。以下是 gettimeofday() 函数的详细文档： 12#include &lt;sys/time.h&gt;int gettimeofday(struct timeval *tv, struct timezone *tz); tv：指向 struct timeval 类型的指针，用于存储当前时间。 tz：指向 struct timezone 类型的指针，用于存储时区信息。不过，这个参数在现代系统中通常被忽略，应该设置为 NULL。 成功时返回0，失败时返回-1，并设置 errno 以指示错误类型。 用例使用下面这段代码可以统计高精度的计时 12345678910111213141516171819#include &lt;stdio.h&gt;#include &lt;sys/time.h&gt;int main() { struct timeval start, end; double elapsed; gettimeofday(&amp;start, NULL); // 获取开始时间 // 这里放置需要计时的代码 for (int i = 0; i &lt; 100000000; i++) { // 一些耗时操作 } gettimeofday(&amp;end, NULL); // 获取结束时间 elapsed = (end.tv_sec - start.tv_sec) + (end.tv_usec - start.tv_usec) / 1000000.0; // 计算时间差 printf(&quot;Elapsed time: %.6f seconds\\n&quot;, elapsed); return 0;} C++风格时间C++11标准引入了&lt;chrono&gt; 库是。它提供了C++版的时间和日期处理函数和数据类型，并且它是跨平台的，在开始时不用考虑平台上的差异，他包含以下内容： 时钟（Clocks）： system_clock：表示系统的实时时钟，通常与当前日期和时间相关联。 steady_clock：一个稳定的时钟，不会因为系统时间的调整而改变，适用于测量时间间隔。 high_resolution_clock：系统中具有最高分辨率的时钟，通常是 system_clock 或 steady_clock 的别名。 一般来说steady_clock有比system_clock更高的时间精度，具有纳秒级别的时间精度。 时间点（Time Points）： time_point：表示一个特定的时间点，通常与某个时钟相关联，可以选择上面介绍的三种时钟之一。例如： 1std::chrono::time_point&lt;std::chrono::system_clock&gt; now = std::chrono::system_clock::now(); 时间间隔（Durations）：std::chrono::duration 是 C++ 标准库中的一个类模板，用于表示时间间隔。 1234namespace std::chrono { template &lt;class Rep, class Period = std::ratio&lt;1&gt;&gt; class duration;} Rep：表示存储时间值的类型（如 int、long long、double 等）。 Period：表示时间单位，相对于秒的比例（如 std::ratio&lt;1&gt; 表示秒，std::milli 表示毫秒）。 时间转换和格式化： duration_cast：用于在不同的时间单位之间进行转换。例如： 1auto milliseconds = std::chrono::duration_cast&lt;std::chrono::milliseconds&gt;(elapsed_seconds); time_point_cast：用于在不同的时间点类型之间进行转换。例如： 1auto tp_ms = std::chrono::time_point_cast&lt;std::chrono::milliseconds&gt;(now); to_time_t：可以将 system_clock 的时间点转换为 time_t 类型，以便与C风格的日期时间函数交互。例如： 1std::time_t now_c = std::chrono::system_clock::to_time_t(now); 用例一段使用chrono统计代码耗时的代码如下 12345678910111213141516171819202122232425#include &lt;iostream&gt;#include &lt;chrono&gt;#include &lt;thread&gt;int main() { // 记录开始时间 auto start = std::chrono::high_resolution_clock::now(); // 需要测量的代码块 for (int i = 0; i &lt; 1000000; ++i) { // 模拟一些耗时操作 std::this_thread::sleep_for(std::chrono::microseconds(1)); } // 记录结束时间 auto end = std::chrono::high_resolution_clock::now(); // 计算耗时 std::chrono::duration&lt;double&gt; elapsed = end - start; // 输出耗时 std::cout &lt;&lt; &quot;Elapsed time: &quot; &lt;&lt; elapsed.count() &lt;&lt; &quot; seconds&quot; &lt;&lt; std::endl; return 0;} 参考文章 Chrono in C++ - GeeksforGeeks C++ 日期 &amp; 时间 | 菜鸟教程","link":"/2024/06/30/c-%E6%97%B6%E9%97%B4%E7%B1%BB%E5%9E%8B/"},{"title":"docker核心知识概括","text":"Docker架构 Docker的核心组件包括： Docker客户端：Client Docker服务端：Docker Daemon Docker镜像：Image Registry：镜像远端 Docker容器：Container Docker 采用的是 Client/Server 架构。客户端向服务器发送请求，服务器负责构建、运行和分发容器。客户端和服务器可以运行在同一个 Host 上，客户端也可以通过 socket 或 REST API 与远程的服务器通信。 Docker客户端最常用的 Docker 客户端是 docker 命令，在安装docker时一并装好。 命令 解释 docker run 运行一个容器 docker ps 列出运行中的容器 docker ps -a 列出所有容器，包括停止的容器 docker images 列出本地镜像 docker pull 从远端仓库拉取镜像 docker build 基于Dockerfile构建镜像 docker exec 在运行中的容器中执行命令 docker stop 停止一个或多个运行中的容器 docker rm 删除一个或多个容器 docker rmi 删除一个或多个本地镜像 docker network ls 列出所有网络 docker volume ls 列出所有卷 docker inspect 提供关于指定Docker对象的详细信息 docker logs 查看容器的日志 docker cp 从容器复制文件到主机 docker commit 创建一个新的镜像 除了docker命令工具之外，也可以通过REST API与Docker服务端通信，一些GUI客户端就是基于此实现的。例如Portainer，它提供了直观的用户界面，使用户能够轻松地管理容器、镜像、卷、网络等Docker组件，而无需使用命令行界面。 Docker 服务端Docker Daemon是服务端，负责创建、运行、监控容器，构建、存储镜像。在Linux系统中有这么几个常用的路径和文件： /var/run/docker.sock ：Docker守护进程默认监听一个Unix域套接字（Unix domain socket）来接受本地通信，这个套接字通常被称为Docker套接字。 /etc/docker/daemon.json ：这个文件包含Docker守护进程的配置选项，例如日志设置、存储驱动、网络配置等。如果该文件不存在，Docker将使用默认配置。 /var/lib/docker ：这是Docker用于存储镜像、容器、卷等数据的默认目录。 Docker daemon 默认只能响应来自本地 Host 的客户端请求，如果需要响应网络请求需要修改docker服务配置。 Docker镜像Docker镜像是一个轻量级、独立、可执行的软件包，可以包括代码、运行时、库、环境变量和配置文件。docker镜像是docker的基础，docker通过镜像生成容器，容器也可以打包成镜像，其具有以下特性： 不可变性：镜像的内容是不可变的，任何对镜像的修改都会生成一个新的镜像。这种不可变性确保了在不同环境中一致性的部署和运行。 轻量性：镜像采用分层存储的设计理念，由多个只读层组成，每个层都包含特定的文件或配置，每个只读层可以给多个镜像共享，从而节省存储空间和提高效率。 docker pull命令可以从Registry下载镜像。 docker run命令则是先下载镜像（如果本地没有），然后再启动容器。 RegistryRegistry是存放Docker镜像的仓库，Registry分私有和公有两种。 DockerHub（https://hub.docker.com/）是默认的Registry，由Docker 公司维护，上面有数以万计的镜像，用户可以自由下载和使用。 出于对速度或安全的考虑，用户也可以创建自己的私有Registry。 Docker镜像镜像的分层结构docker采用分层结构，通常来说最底层镜像能提供一个基本的操作系统环境，用户可以根据需要安装和配置软件，这样的镜像称作base 镜像。base 镜像从0开始构建，其他镜像以此为基础进行拓展。一般来说base 镜像是各种 Linux 发行版的 Docker 镜像，比如 Ubuntu、Debian、CentOS 等。 平时我们在虚拟机上安装Linux操作系统都是好几个G，为什么docker才200M左右呢？ docker使用的base镜像是经过精简的，只包括最基本的命令、工具和程序库。相比物理机安装的操作系统会小很多。另外base镜像只包括操作系统的rootfs部分，不包括bootfs和kermel，并且和Host共用kernel。 docker的每一层都代表着代码、运行时、库、环境变量和配置文件。下图为例，该新镜像在 Debian base 镜像上构建，添加了一层emacs 编辑器，再添加了一层apache2。新镜像是从 base 镜像一层一层叠加生成的。每安装一个软件，就在现有镜像的基础上增加一层。 当容器启动时，还会添加一个新的可写层被加载到镜像的顶部。 这一层通常被称作“容器层”，“容器层”之下的都叫“镜像层“。**所有对容器的改动，无论添加、删除，还是修改文件都只会发生在容器层中。**只有容器层是可写的，容器层下面的所有镜像层都是只读的。 只有当需要修改时才复制一份数据，这种特性被称作 Copy-on-Write。 分层结构的好处最主要的目的是共享资源，如果有多个镜像都从相同的 base 镜像构建而来，那么 Docker Host 只需在磁盘上保存一份 base 镜像；同时内存中也只需加载一份 base 镜像，就可以为所有容器服务了，而且镜像的每一层都可以被共享 。 使用docker history命令可以检查镜像的分层结构，例如： 构建镜像Docker 提供了两种构建镜像的方法： docker commit 命令与 Dockerfile 构建文件 docker commitdocker commit 命令是创建新镜像最直观的方法，每次使用一次该命令，则镜像多添加一层，其过程包含三个步骤： 运行容器 进入容器内部进行修改 使用docker commit命令将修改完的容器保存为新的镜像 Docker 并不建议用户通过这种方式构建镜像。原因如下 ： 手动创建镜像效率低下且可重复性弱； 镜像创建过程不透明，无法对镜像进行审计。 DockerfileDockerfile 是一个文本文件，记录了镜像构建的所有步骤。下面列出了 Dockerfile 中最常用的指令，完整列表和说明可参看官方文档 命令 解释 FROM 指定BASE镜像 MAINTAINER 设置镜像的作者，可以是任意字符串 COPY 将文件从buildcontext复制到镜像，COPY支持两种形式：COPY src dest 与COPY[“src”,”dest”]，注意：src只能指定buildcontext 中的文件或目录。 ADD 与COPY类似，从build context 复制文件到镜像。不同的是，如果src是归档文件（tar、zip、tgz、xz 等），文件会被自动解压到dest。 ENV 设置环境变量，环境变量可被后面的指令使用。例如：ENV MY_VERSION 1.3 RUN apt-get install -y mypackage=$MY_VERSION EXPOSE 指定容器中的进程会监听某个端口，Docker可以将该端口暴露出来 VOLUME 将文件或目录声明为volume WORKDIR 为后面的RUN、CMD、ENTRYPOINT、ADD或COPY指令设置镜像中的当前工作目录 RUN 在容器中运行指定的命令 CMD 容器启动时运行指定的命令 ENTRYPOINT 设置容器启动时运行的命令。 Dockerfile 的注释以”#” 开头RUN、CMD 和 ENTRYPOINT 这三个 Dockerfile 指令看上去很类似，很容易混淆，但是有些细微区别： RUN：执行命令并创建新的镜像层，RUN经常用于安装软件包。 CMD：设置容器启动后默认执行的命令及其参数，但 CMD 能够被 docker run 后面跟的命令行参数替换。 ENTRYPOINT：配置容器启动时运行的命令。 CMD单独使用时可以使用[命令] [参数] 的形式，当和ENTRYPOINT结合使用时可以作为参数输入，使参数的设定更加灵活。 例如： 123FROM ubuntuENTRYPOINT [&quot;echo&quot;, &quot;Hello&quot;]CMD [&quot;world&quot;] 在这个例子中，如果直接运行容器而不带任何命令行参数，它会输出Hello world。这是因为ENTRYPOINT指定了echo命令，而CMD提供了默认参数world。 如果在运行容器时指定了额外的参数，比如docker run &lt;image&gt; Docker!，那么CMD中的world会被忽略，输出将会是Hello Docker!。 Dockerfile支持Shell和Exec格式的命令 Shell格式： 1&lt;instruction&gt; &lt;command&gt; 例如： 123RUN apt-get install python3CMD echo &quot;Hello world&quot;NTRYPOINT echo &quot;Hello world&quot; 当指令执行时，shell 格式底层会调用/bin/sh-c [command]Exec格式： 1&lt;instruction&gt; [&quot;executable&quot;, &quot;paraml&quot;, &quot;param2&quot;, ...] 例如： 123RUN [&quot;apt-get&quot;, &quot;install&quot;, &quot;python3&quot;]CMD [&quot;/bin/echo&quot;, &quot;Hello world&quot; ]ENTRYPOINT [&quot;/bin/echo&quot;，&quot;Helloworld&quot;] **注意：**apt-get update 和 apt-get install 被放在一个 RUN 指令中执行，这样能够保证每次安装的是最新的包。如果 apt-get install 在单独的 RUN 中执行，则会使用 apt-get update 创建镜像层，而这一层可能是很久以前缓存的。 Docker容器容器的启动docker run是运行容器的命令，当启动时容器会执行指定的CMD或ENTRYPOINT指令，也可以手动指令运行的命令，但是当命令执行结束时容器就会退出。 例如运行docker run hello-world 容器的生命周期依赖于启动时执行的命令，只要该命令不结束，容器也就不会退出。 例如我们运行下面这一段不断循环的脚本 1docker run ubuntu /bin/bash -c &quot;while true ; do sleep 1; done&quot; 可以打开另一个终端查看容器的状态，发现容器始终在运行。为了避免程序在前台运行，可以添加参数-d让程序在后台运行，例如 1docker run -d ubuntu /bin/bash -c &quot;while true ; do sleep 1; done&quot; 进入容器内部按用途容器大致可分为两类：服务类容器和工具类的容器，大多数都是服务类的容器，需要常驻在后台对外提供服务。对于这种常驻在后台运行的容器，有时我们也需要进到容器里去做一些工作，比如查看日志、调试、启动其他进程等。 docker attach通过 docker attach命令可以 attach 到容器启动命令的终端 1docker attach [容器ID] 通过 Ctrl+p, 然后 Ctrl+q 组合键退出 attach 终端。 docker exec另一种方式是通过 docker exec 进入相同的容器 1docker exec -it [容器ID] bash 上述命令的含义是在容器内新开一个终端，并执行bash命令打开bash终端。需要注意的是，有些容器内没有bash，可以选择sh命令。 这两个方式有些不同，attach是接入到原来的终端当中，可以直接查看容器输出的内容。而exec是新开一个终端，可以执行Linux命令。建议如果想直接在终端中查看启动命令的输出，用 attach；其他情况一律使用 exec。 容器的启停docker命令指定容器有两种方式，第一种是使用容器ID，ID可以使用短ID，即前几位就行，第二种是指定容器名 例如: 123docker start aa9198422ccb # 使用完整的IDdocker start aa # 使用前几位ID，只需要能够和其他容器进行区分就足够docker start practical_chandrasekhar # 使用容器名指定 docker stop 通过 docker stop 可以停止运行的容器，docker stop 命令本质上是向该进程发送一个SIGTERM 信号。如果想快速停止容器，可使用 docker kill 命令，其作用是向容器进程发送SIGKILL 信号 docker start 对于处于停止状态的容器，可以通过docker start重新启动，docker start会保留容器的第一次启动时的所有参数。 docker restart docker restart 可以重启容器，其作用就是依次执行 docker stop 和 docker start。 容器可能会因某种错误而停止运行。对于服务类容器，我们通常希望在这种情况下容器能够自动重启。启动容器时设置–restart就可以达到这个效果，–restart=always 意味着无论容器因何种原因退出（包括正常退出），都立即重启；该参数的形式还可以是 –restart=on-fhilure:3, 意思是如果启动进程退出代码非 0, 则重启容器，最多重启 3 次。 1docker run -d -—restart=always httpd 容器的暂停与恢复docker pause 命令可以让容器暂停，docker unpause 可以使其恢复运行。 容器的删除docker rm 是删除容器，docker rmi 是删除镜像，删除之前需要先docker stop停止容器。 资源限制内存限额一个docker host上会运行若干容器，每个容器都需要CPU、内存和IO资源。对于KVM、VMware等虚拟化技术，用户可以控制分配多少CPU、内存资源给每个虚拟机。对于容器，Docker也提供了类似的机制避免某个容器因占用太多资源而影响其他容器乃至整个host的性能。 与操作系统类似，容器可使用的内存包括两部分：物理内存和 swap。 Docker 通过下面两组参数来控制容器内存的使用量。 -m 或 -memory：设置内存的使用限额，例如 100MB, 2GB -memory-swap：设置内存+swap 的使用限额。 如果在启动容器时只指定 -m 而不指定 -memory-swap, 那么 -memory-swap 默认为 -m的两倍 例如以下命令： 1docker run -m 200M —memory-swap=300M ubuntu 分配的内存超过限额，容器会退出。 CPU限额默认设置下，所有容器可以平等地使用hostCPU资源并且没有限制。Docker可以通过-c或–cpu-shares设置容器使用CPU的权重。如果不指定，默认值为1024。与内存限额不同，通过-设置的cpu share并不是CPU资源的绝对数量，而是一个相对的权重值。某个容器最终能分配到的CPU资源取决于它的cpushare占所有容器cpushare总和的比例。换句话说：通过cpu share可以设置容器使用CPU的优先级。 例如以下命令： 1docker run —name &quot;container_A&quot; -c 1024 ubuntu Block IO 带宽限额Block IO 是另一种可以限制容器使用的资源。Block 10 指的是磁盘的读写，docker 可通过设置权重、限制 bps 和 iops 的方式控制容器读写磁盘的带宽，下面分别讨论。 1.block IO权重 默认情况下，所有容器能平等地读写磁盘，可以通过设置 -blkio-weight 参数来改变容器block 10 的优先级。 --blkio-weight 与 --cpu-shares类似，设置的是相对权重值，默认为 500。在下面的例子中，containerA 读写磁盘的带宽是 containerB 的两倍。 12docker run -it ―name container_A ―blkio-weight 600 ubuntudocker run -it —name container_B ―blkio-weight 300 ubuntu 2. 限制 bps 和 iopsbps 是 byte per second, 每秒读写的数据量iops 是 io per second, 每秒 IO 的次数。可通过以下参数控制容器的 bps 和 iops： --device-read-bps:限制读某个设备的 bps。 --device-write-bps:限制写某个设备的 bps。 --device-read-iops: 限制读某个设备的 iops。 --device-write-iops: 限制写某个设备的 iops。 下面这个例子限制容器写 /dev/sda 的速率为 30 MB/s： 1docker run -it -一device-write-bps /dev/sda: 30MB ubuntu Docker网络None网络none 网络就是什么都没有的网络。挂在这个网络下的容器除了 lo, 没有其他任何网卡。容器创建时，可以通过 -network=none 指定使用 none 网络 1docker run -it --network=none busybox Host网络连接到 host 网络的容器共享 Docker host 的网络栈，容器的网络配置与 host 完全一样。 可以通过—network=host 指定使用 host 网络 1docker run -it --network=host busybox 直接使用 Docker host 的网络最大的好处就是性能，如果容器对网络传输效率有较高要求，则可以选择 host 网络。当然不便之处就是牺牲一些灵活性，比如要考虑端口冲突问题， Docker host 上已经使用的端口就不能再用了。 Docker host 的另一个用途是让容器可以直接配置 host 网路，比如某些跨 host 的网络解决 方案，其本身也是以容器方式运行的，这些方案需要对网络进行配置，比如管理 iptables。 Bridge网络Docker 安装时会创建一个命名为 docker0 的 Linux bridge。如果不指定-network, 创建的容器默认都会挂到 docker0 上。 默认的docker网关是172.17.0.1，容器创建时，docker 会自动从 172.17.0.0/16 中分配一个 IP, 这里 16 位的掩码保证有足够多的 IP 可以供容器使用。 User-defined网络除了 none、host、 bridge 这三个自动创建的网络，用户也可以根据业务需要创建 user-defined 网络。Docker 提供三种 user-defined 网络驱动：bridge、overlay 和 macvlano overlay 和 macvlan用于创建跨主机的网络 bridge网络： 类似上述docker0这个bridge，可以通过bridge 驱动创建新的网络 1docker network create --driver bridge my_net 通过brctl show命令和docker network inspect my_net命令可以查看新建网络的信息 也可以在创建bridge时使用--subnet和--gateway参数来指定网段，相应的也可以在容器运行时指定容器的静态IP。 docker network connect命令可以将两个bridge连通 Docker DNS Server通过IP访问容器虽然满足了通信的需求，但还是不够灵活。因为在部署应用之前可能无法确定IP，部署之后再指定要访问的IP会比较麻烦。对于这个问题，可以通过docker自带的DNS服务解决。 从Docker1.10版本开始，dockerdaemon实现了一个内嵌的DNS server，使容器可以直接通过“容器名”通信。方法很简单，只要在启动时用–name为容器命名就可以了。下面启动两个容器bbox1和bbox2： 12docker run -it —network=my_net2 --name=bboxl busyboxdocker run -it—network=my_net2 --name=bbox2 busybox 使用 docker DNS 有个限制：只能在 user-defined 网络中使用。也就是说，默认的 bridge网络是无法使用 DNS 的。 Docker存储Docker 为容器提供了两种存放数据的资源 由 storage driver 管理的镜像层和容器层 Data Volume storage driver前面讲到容器的分层结构特性：Copy-on-Write: 新数据会直接存放在最上面的容器层。 修改现有数据会先从镜像层将数据复制到容器层，修改后的数据直接保存在容器层中，镜像层保持不变。 如果多个层中有命名相同的文件，用户只能看到最上面那层中的文件。 分层结构使镜像和容器的创建、共享以及分发变得非常高效，而这些都要归功于 Docker storage driver。正是 storage driver 实现了多层数据的堆叠并为用户提供一个单一的合并之后的统一视图。 Docker 支持多种 storage driver, 有 AUFS、Device Mapper、Btrfc、OveHayFS、VFS 和ZFS。它们都能实现分层的架构，同时又有各自的特性。对于 Docker 用户来说，具体选择使用哪个 storage driver 是一个难题，因为： 没有哪个 driver 能够适应所有的场景。 driver 本身在快速发展和迭代。 所以优先使用 Linux 发行版默认的 storage driver。 对于某些容器，直接将数据放在由 storage driver 维护的层中是很好的选择，比如那些无状态的应用。无状态意味着容器没有需要持久化的数据，随时可以从镜像直接创建。 但对于另一类应用这种方式就不合适了，它们有持久化数据的需求，容器启动时需要加载已有的数据，容器销毁时希望保留产生的新数据，也就是说，这类容器是有状态的。 这就要用到 Docker 的另一种存储机制：Data Volume。 Data VolumeData Volume 本质上是 Docker Host 文件系统中的目录或文件，能够直接被 mount 到容器的文件系统中，具有以下优点： Data Volume 是目录或文件，而非没有格式化的磁盘 (块设备) 容器可以读写 volume 中的数据。 volume 数据可以被永久地保存，即使使用它的容器已经销毁。 volume实际上是 docker host 文件系统的一部分，所以 volume 的容量取决于文件系统当前未使用的空间，目前还没有方法设置 volume 的容量。 在具体的使用上，docker 提供了两种类型的 volume：bind mount 和 docker managed volume bind mountbind mount用于将主机文件系统中的目录或文件挂载到Docker容器中。这种挂载方式允许容器与主机之间共享文件和目录，使得容器中的应用程序可以访问主机上的文件系统。 在运行Docker容器时，可以通过-v或--volume选项来指定bind mount。语法通常是-v &lt;host_path&gt;:&lt;container_path&gt;，其中&lt;host_path&gt;是主机上的路径，&lt;container_path&gt;**是容器内的路径。Docker会将主机路径和容器路径之间建立一个映射关系，容器内对该路径的访问实际上是对主机文件系统中相应路径的访问。 bind mount 的使用直观高效，易于理解，但它也有不足的地方：bind mount 需要指定 host文件系统的特定路径，这就限制了容器的可移植性，当需要将容器迁移到其他 host, 而该 host没有要 mount 的数据或者数据不在相同的路径时，操作会失败 Docker managed volumesDocker managed volumes（Docker管理的卷）是一种Docker容器中用于存储数据的技术，与bind mount类似，但由Docker自动管理。相比于bind mount，Docker managed volumes提供了更多的便利和一些额外的功能，例如跨平台兼容性、易于备份和恢复、更好的性能等。 可以通过 docker inspect 查看 volume, 也可以用 docker volume 命令查看有哪些docker volume","link":"/2024/03/26/docker%E6%A0%B8%E5%BF%83%E7%9F%A5%E8%AF%86%E6%A6%82%E6%8B%AC/"},{"title":"gperftools快速上手","text":"最近在做后处理功能的开发，由于开发有计算效率上的要求，所以学习了一下怎么对程序性能进行分析。这里使用gperftools是因为它能统计部分代码的效率。相比与其他性能分析工具，gperftools有Profiling速度快，灵活性较高的优点。 主流的热点分析工具，分别是GNU gprof、Valgrind和Google perftools，三款工具的主要特点如下表： 工具 使用命令 是否需要重新编译 Profiling速度 是否支持多线程热点分析 是否支持链接库热点分析 GNU gprof ./test; gprof ./test ./gmon.out 是 慢 否 否 Valgrind Valgrind –tool=callgrind ./test 否 非常慢 是 是 Google perftools LD_PRELOAD=/usr/lib/libprofiler.so CPUPROFILE=./test.prof ./test 否 快 是 是 Ubuntu系统的安装12345678910111213# 克隆代码git clone https://github.com/gperftools/gperftools.git# 安装依赖库sudo apt-get install libunwind8-dev# 程序编译cd gperftools./autogen.sh./configuremake -j 8# 安装到系统文件夹sudo make install# 刷新动态库文件ldconfig 在.bashrc文件中添加环境变量 gperftools进行时间效率分析非侵入式gperftools允许不改变程序分析，用以下命令运行即可 1LD_PRELOAD=/usr/lib/libprofiler.so.0 CPUPROFILE=./main.prof ./main LD_PRELOAD：gperftools动态链接库的绝对路径，不同的版本变量名可能不同 CPUPROFILE：输出报告的文件名 侵入式如果只需要统计部分代码，例如想统计后处理相关代码的性能，可以通过函数来调用gperftools。 12345#include &lt;gperftools/profiler.h&gt; //引入相关头文件ProfilerStart(&quot;test.prof&quot;); //分析结束后会生成结果文件test.prof..... //待分析的代码ProfilerStop(); 编译和链接时需要加-lprofiler选项，运行该段代码会产生名为test.prof的报告 gperftools结果分析可以以文本形式展示性能报告： 1google-pprof --text [程序名] [报告文件名] gperftools支持动态链接库的分析，因此程序名也可以替换成动态链接库名。 1234567891011121314Total: 40 samples 6 15.0% 15.0% 6 15.0% __nss_database_lookup 6 15.0% 30.0% 6 15.0% psiginfo 5 12.5% 42.5% 7 17.5% std::__detail::_Executor::_M_dfs 3 7.5% 50.0% 20 50.0% Geometry::generatePlotKeys 2 5.0% 55.0% 5 12.5% Geometry::plotKeyToFSRIDs 2 5.0% 60.0% 37 92.5% PlotKeyExport::getValueByPlotKeys 2 5.0% 65.0% 2 5.0% __cxxabiv1::__si_class_type_info::__do_dyncast 2 5.0% 70.0% 4 10.0% __dynamic_cast 2 5.0% 75.0% 7 17.5% std::__detail::_Executor::_M_rep_once_more 2 5.0% 80.0% 2 5.0% strtoul 1 2.5% 82.5% 21 52.5% Geometry::getPlotKeys[abi:cxx11] 1 2.5% 85.0% 1 2.5% Solver::getFSRFissionRate 1 2.5% 87.5% 1 2.5% __libc_malloc Total: 40 samples 表示采集到40个样本，默认设置下gperftools采样时间为10 ms。可以通过环境变量CPUPROFILE_FREQUENCY设置采样频率，默认是100次采样。 结果说明，数据每一列意义: Number of profiling samples in this function 分析样本数量 Percentage of profiling samples in this function 分析样本百分比，也就是该函数在总时间的占比 Percentage of profiling samples in the functions printed so far 累计占比，该函数的时间占比加上之前所有函数的占比 Number of profiling samples in this function and its callees 分析样本数量 Percentage of profiling samples in this function and its callees 分析样本百分比（包含其他函数调用） Function name 函数名","link":"/2023/04/16/gperftools%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/"},{"title":"spdlog源码阅读(一)：简介","text":"spdlog是一个跨平台、快速和轻量的C++日志库，其完全header-only实现和基于C++11实现的特性使其可以很好的集成到任何项目中。项目地址：https://github.com/gabime/spdlog spdlog短小精悍，代码行数在2w左右，且代码风格优秀，符合现代C++编程规范，有许多值得学习的实践，遂开坑对该源码开始阅读和理解。 spdlog整体架构组成部分 Logger 类logger是spdlog日志库的核心类，提供日志输出的接口，具有以下功能： 支持trace，debug，info，warn，error和critical等级的日志输出接口，具有日志等级过滤的功能。 日志接口使用友好，提供了格式化字符串模板接口，使用fmt库作为底层驱动。 通过设置Sink对象来实现日志消息的单一输出或多个输出，每个输出可以单独设置日志过滤等级和日志格式化模板。 提供线程安全性，允许多个线程修改logger对象的日志过滤等级和日志刷新等级。 提供宽字符的支持。 Sink 类Sink包含了一系列输出类，来负责日志不同的输出形式。Sink是日志输出的抽象基类，只提供接口不提供实现。file_sink, console_sink等类通过继承拓展Sink类，负责实现日志的输出。 以下是 spdlog 主要实现的 sink 类型： Sink 类型 描述 头文件 stdout_sink_mt / stdout_sink_st 输出到标准输出的 sink spdlog/sinks/stdout_sinks.h stderr_sink_mt / stderr_sink_st 输出到标准错误的 sink spdlog/sinks/stdout_sinks.h basic_file_sink_mt / basic_file_sink_st 基本的文件输出 sink spdlog/sinks/basic_file_sink.h rotating_file_sink_mt / rotating_file_sink_st 循环文件 sink spdlog/sinks/rotating_file_sink.h daily_file_sink_mt / daily_file_sink_st 每日文件 sink spdlog/sinks/daily_file_sink.h null_sink_mt / null_sink_st 空 sink，不输出任何内容 spdlog/sinks/null_sink.h syslog_sink 系统日志 sink（仅 UNIX 系统） spdlog/sinks/syslog_sink.h android_sink Android 日志 sink spdlog/sinks/android_sink.h wincolor_sink_mt / wincolor_sink_st Windows 控制台彩色输出 sink spdlog/sinks/wincolor_sink.h ansicolor_sink_mt / ansicolor_sink_st ANSI 终端彩色输出 sink spdlog/sinks/ansicolor_sink.h ostream_sink_mt / ostream_sink_st 输出到 C++ ostream 的 sink spdlog/sinks/ostream_sink.h dist_sink_mt / dist_sink_st 分发 sink spdlog/sinks/dist_sink.h msvc_sink_mt / msvc_sink_st Visual Studio 输出窗口 sink spdlog/sinks/msvc_sink.h tcp_sink_mt / tcp_sink_st TCP 网络 sink spdlog/sinks/tcp_sink.h callback_sink_mt / callback_sink_st 回调函数 sink spdlog/sinks/callback_sink.h dup_filter_sink_mt / dup_filter_sink_st 重复消息过滤 sink spdlog/sinks/dup_filter_sink.h hourly_file_sink_mt / hourly_file_sink_st 每小时文件 sink spdlog/sinks/hourly_file_sink.h kafka_sink_mt / kafka_sink_st Kafka 消息队列 sink spdlog/sinks/kafka_sink.h mongo_sink_mt / mongo_sink_st MongoDB sink spdlog/sinks/mongo_sink.h qt_sinks_mt / qt_sinks_st Qt GUI 应用程序 sink spdlog/sinks/qt_sinks.h ringbuffer_sink_mt / ringbuffer_sink_st 环形缓冲区 sink spdlog/sinks/ringbuffer_sink.h systemd_sink_mt / systemd_sink_st Systemd Journal sink spdlog/sinks/systemd_sink.h win_eventlog_sink_mt / win_eventlog_sink_st Windows 事件日志 sink spdlog/sinks/win_eventlog_sink.h 注意： 后缀 “_mt” 表示多线程（thread-safe）版本，”_st” 表示单线程版本。 spdlog 还支持自定义 sink，允许用户根据需求实现自己的 sink。Sink类通过继承将接口和实现进行解耦，并实现了多种日志输出方式，具有较好的灵活性和拓展性。 Formatter 类日志的格式化器，可以格式化出不同类型的时间，支持文本的空白填充和对齐。此外，也支持自定义flag_formatter以实现自定义的格式化。 Registry 类全局单例,管理所有Logger实例，提供创建和检索Logger的接口。 异步支持spdlog实现了异步日志，通过异步日志类async_logger实现，允许日志记录操作在后台线程中进行，减少对主程序执行的影响。异步日志不直接输出，而是存在一个无锁环形队列circular_q中，通过实现一个多生产者-多消费者模式来实现日志的高效写入。 然而使用异步日志会引入一些复杂性，当队列满时，spdlog默认使用覆盖的策略，会导致一部分的异步日志的丢失。 相关阅读在此之前已有诸多优秀的spdlog库的源码解读，例如 spdlog库笔记汇总","link":"/2024/09/23/spdlog%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB-%E4%B8%80-%EF%BC%9A%E7%AE%80%E4%BB%8B/"},{"title":"spdlog源码阅读(三)：Register类的实现","text":"在 spdlog 日志库中，register 类是为了管理logger的生命周期并提供方便的全局访问。该类包括以下功能。 单例实现registry类的构造函数设置成private，并将拷贝构造函数和赋值运算符设置成delete，这是为了避免通过非期望的方式创建registry。registry只能通过instance方法对其实例化，该方法利用局部静态变量初始化的线程安全性来保证registry的初始化安全。 1234SPDLOG_INLINE registry &amp;registry::instance() { static registry s_instance; return s_instance;} 提供默认loggerRegister在构造时会创建一个默认的logger，并提供get_default_raw方法来获取默认的logger对象的裸指针，再通过函数的封装，提供了不需要额外初始化的日志接口。 此外，还可以通过set_default_logger方法来修改默认的logger对象，并使用智能指针保存该对象，避免内存泄漏。 如果不需要使用默认logger可以使用SPDLOG_DISABLE_DEFAULT_LOGGER取消相关实现。 123456789101112131415161718192021222324252627282930313233343536373839404142// registry构造函数SPDLOG_INLINE registry::registry() : formatter_(new pattern_formatter()) {#ifndef SPDLOG_DISABLE_DEFAULT_LOGGER // create default logger (ansicolor_stdout_sink_mt or wincolor_stdout_sink_mt in windows). #ifdef _WIN32 auto color_sink = std::make_shared&lt;sinks::wincolor_stdout_sink_mt&gt;(); #else auto color_sink = std::make_shared&lt;sinks::ansicolor_stdout_sink_mt&gt;(); #endif const char *default_logger_name = &quot;&quot;; default_logger_ = std::make_shared&lt;spdlog::logger&gt;(default_logger_name, std::move(color_sink)); loggers_[default_logger_name] = default_logger_;#endif // SPDLOG_DISABLE_DEFAULT_LOGGER}// 提供的不需要初始化的日志接口template &lt;typename... Args&gt;inline void log(level::level_enum lvl, format_string_t&lt;Args...&gt; fmt, Args &amp;&amp;...args) { default_logger_raw()-&gt;log(source_loc{}, lvl, fmt, std::forward&lt;Args&gt;(args)...);}template &lt;typename... Args&gt;inline void trace(format_string_t&lt;Args...&gt; fmt, Args &amp;&amp;...args) { default_logger_raw()-&gt;trace(fmt, std::forward&lt;Args&gt;(args)...);}template &lt;typename... Args&gt;inline void debug(format_string_t&lt;Args...&gt; fmt, Args &amp;&amp;...args) { default_logger_raw()-&gt;debug(fmt, std::forward&lt;Args&gt;(args)...);}// set_default_logger方法SPDLOG_INLINE void registry::set_default_logger(std::shared_ptr&lt;logger&gt; new_default_logger) { std::lock_guard&lt;std::mutex&gt; lock(logger_map_mutex_); if (new_default_logger != nullptr) { loggers_[new_default_logger-&gt;name()] = new_default_logger; } default_logger_ = std::move(new_default_logger);} logger的统一管理register提供了logger对象的管理方法，使用std::unordered_map来储存logger对象，并通过logger名称来对其索引。 通过工厂函数创建的logger对象会默认添加进管理，对于手动创建的logger对象可以使用register_logger_方法添加进管理。 register使用get方法来获取相应的logger对象，使用drop方法删除已管理的logger对象，还可以使用drop_all方法删除所有已管理的logger对象。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960// 工厂函数的create静态方法默认调用initialize_logger函数struct synchronous_factory { template &lt;typename Sink, typename... SinkArgs&gt; static std::shared_ptr&lt;spdlog::logger&gt; create(std::string logger_name, SinkArgs &amp;&amp;...args) { auto sink = std::make_shared&lt;Sink&gt;(std::forward&lt;SinkArgs&gt;(args)...); auto new_logger = std::make_shared&lt;spdlog::logger&gt;(std::move(logger_name), std::move(sink)); details::registry::instance().initialize_logger(new_logger); return new_logger; }};// initialize_logger函数内部调用了register_logger_，将logger对象添加进管理SPDLOG_INLINE void registry::initialize_logger(std::shared_ptr&lt;logger&gt; new_logger) { std::lock_guard&lt;std::mutex&gt; lock(logger_map_mutex_); new_logger-&gt;set_formatter(formatter_-&gt;clone()); if (err_handler_) { new_logger-&gt;set_error_handler(err_handler_); } // set new level according to previously configured level or default level auto it = log_levels_.find(new_logger-&gt;name()); auto new_level = it != log_levels_.end() ? it-&gt;second : global_log_level_; new_logger-&gt;set_level(new_level); new_logger-&gt;flush_on(flush_level_); if (backtrace_n_messages_ &gt; 0) { new_logger-&gt;enable_backtrace(backtrace_n_messages_); } // 可以通过修改automatic_registration_禁用自动添加管理的功能 if (automatic_registration_) { register_logger_(std::move(new_logger)); }}// 获取管理的logger对象SPDLOG_INLINE std::shared_ptr&lt;logger&gt; registry::get(const std::string &amp;logger_name) { std::lock_guard&lt;std::mutex&gt; lock(logger_map_mutex_); auto found = loggers_.find(logger_name); return found == loggers_.end() ? nullptr : found-&gt;second;}// 删除已管理的logger对象SPDLOG_INLINE void registry::drop(const std::string &amp;logger_name) { std::lock_guard&lt;std::mutex&gt; lock(logger_map_mutex_); auto is_default_logger = default_logger_ &amp;&amp; default_logger_-&gt;name() == logger_name; loggers_.erase(logger_name); if (is_default_logger) { default_logger_.reset(); }}// 删除所有已管理的logger对象SPDLOG_INLINE void registry::drop_all() { std::lock_guard&lt;std::mutex&gt; lock(logger_map_mutex_); loggers_.clear(); default_logger_.reset();} register实现了一套logger一样的接口，以便实现全局logger设置。实现方法类似，都是遍历所有logger再调用其方法。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556// Set global formatter. Each sink in each logger will get a clone of this objectSPDLOG_INLINE void registry::set_formatter(std::unique_ptr&lt;formatter&gt; formatter) { std::lock_guard&lt;std::mutex&gt; lock(logger_map_mutex_); formatter_ = std::move(formatter); for (auto &amp;l : loggers_) { l.second-&gt;set_formatter(formatter_-&gt;clone()); }}SPDLOG_INLINE void registry::enable_backtrace(size_t n_messages) { std::lock_guard&lt;std::mutex&gt; lock(logger_map_mutex_); backtrace_n_messages_ = n_messages; for (auto &amp;l : loggers_) { l.second-&gt;enable_backtrace(n_messages); }}SPDLOG_INLINE void registry::disable_backtrace() { std::lock_guard&lt;std::mutex&gt; lock(logger_map_mutex_); backtrace_n_messages_ = 0; for (auto &amp;l : loggers_) { l.second-&gt;disable_backtrace(); }}SPDLOG_INLINE void registry::set_level(level::level_enum log_level) { std::lock_guard&lt;std::mutex&gt; lock(logger_map_mutex_); for (auto &amp;l : loggers_) { l.second-&gt;set_level(log_level); } global_log_level_ = log_level;}SPDLOG_INLINE void registry::flush_on(level::level_enum log_level) { std::lock_guard&lt;std::mutex&gt; lock(logger_map_mutex_); for (auto &amp;l : loggers_) { l.second-&gt;flush_on(log_level); } flush_level_ = log_level;}SPDLOG_INLINE void registry::set_error_handler(err_handler handler) { std::lock_guard&lt;std::mutex&gt; lock(logger_map_mutex_); for (auto &amp;l : loggers_) { l.second-&gt;set_error_handler(handler); } err_handler_ = std::move(handler);}SPDLOG_INLINE void registry::flush_all() { std::lock_guard&lt;std::mutex&gt; lock(logger_map_mutex_); for (auto &amp;l : loggers_) { l.second-&gt;flush(); }} 除此之外，还实现了apply_all方法，可以通过传函数对象，实现多样化的管理需求。 1234567SPDLOG_INLINE void registry::apply_all( const std::function&lt;void(const std::shared_ptr&lt;logger&gt;)&gt; &amp;fun) { std::lock_guard&lt;std::mutex&gt; lock(logger_map_mutex_); for (auto &amp;l : loggers_) { fun(l.second); }} 线程安全register单例的实例化使用懒汉模式，并使用局部静态变量初始化来保证线程安全性。 1234SPDLOG_INLINE registry &amp;registry::instance() { static registry s_instance; return s_instance;} 对logger对象的操作之前使用RAII的锁来保证线程安全性 1std::lock_guard&lt;std::mutex&gt; lock(logger_map_mutex_); 性能优化频繁加锁会导致日志性能下降，因此register类除了default_logger方法还提供了get_default_raw方法，提供不加锁的获取默认logger指针的方法。由于不加锁，因此改方法非线程安全，使用时不能与set_default_logger方法同时使用。","link":"/2024/10/07/spdlog%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB-%E4%B8%89-%EF%BC%9ARegister%E7%B1%BB%E7%9A%84%E5%AE%9E%E7%8E%B0/"},{"title":"spdlog源码阅读(二)：Logger类的实现","text":"日志对象创建全局默认loggerspdlog库通过logger类提供日志接口，而logger的创建有多种方式。第一种方式是全局默认logger，例如，在官方example日志使用样例中提供的默认的日志调用： 12345678spdlog::info(&quot;Welcome to spdlog version {}.{}.{} !&quot;, SPDLOG_VER_MAJOR, SPDLOG_VER_MINOR, SPDLOG_VER_PATCH);spdlog::warn(&quot;Easy padding in numbers like {:08d}&quot;, 12);spdlog::critical(&quot;Support for int: {0:d}; hex: {0:x}; oct: {0:o}; bin: {0:b}&quot;, 42);spdlog::info(&quot;Support for floats {:03.2f}&quot;, 1.23456);spdlog::info(&quot;Positional args are {1} {0}..&quot;, &quot;too&quot;, &quot;supported&quot;);spdlog::info(&quot;{:&gt;8} aligned, {:&lt;8} aligned&quot;, &quot;right&quot;, &quot;left&quot;); 该方法调用的是默认创建的logger，由registry类创建和管理。registry是一个被设计成单例的类，在构造时自动创建一个输出到终端的logger，并设置成默认logger，以下是相关代码： 12345678910111213141516SPDLOG_INLINE registry::registry() : formatter_(new pattern_formatter()) {#ifndef SPDLOG_DISABLE_DEFAULT_LOGGER // create default logger (ansicolor_stdout_sink_mt or wincolor_stdout_sink_mt in windows). #ifdef _WIN32 auto color_sink = std::make_shared&lt;sinks::wincolor_stdout_sink_mt&gt;(); #else auto color_sink = std::make_shared&lt;sinks::ansicolor_stdout_sink_mt&gt;(); #endif const char *default_logger_name = &quot;&quot;; default_logger_ = std::make_shared&lt;spdlog::logger&gt;(default_logger_name, std::move(color_sink)); loggers_[default_logger_name] = default_logger_;#endif // SPDLOG_DISABLE_DEFAULT_LOGGER} 在使用全局函数接口时，其实就是先获取单例registry，获取单例registry的默认logger，再调用默认logger的相关方法，通过模板参数和完美转发将日志进行传递。 12345678SPDLOG_INLINE spdlog::logger *default_logger_raw() { return details::registry::instance().get_default_raw();}template &lt;typename... Args&gt;inline void info(format_string_t&lt;Args...&gt; fmt, Args &amp;&amp;...args) { default_logger_raw()-&gt;info(fmt, std::forward&lt;Args&gt;(args)...);} 工厂方法logger有时为了灵活性考虑，需要自己管理logger对象，此时可以使用工厂方法创建logger。在每个Sink实现的头文件中，都定义了与Sink有关的工厂方法。例如basic_file_sink就定义了相关的工厂方法。 1234567891011//// factory functions//template &lt;typename Factory = spdlog::synchronous_factory&gt;inline std::shared_ptr&lt;logger&gt; basic_logger_mt(const std::string &amp;logger_name, const filename_t &amp;filename, bool truncate = false, const file_event_handlers &amp;event_handlers = {}) { return Factory::template create&lt;sinks::basic_file_sink_mt&gt;(logger_name, filename, truncate, event_handlers);} 通过工厂方法可以便捷的创建logger对象，通过传入不同的工厂模板可以实现同步或异步logger对象的创建。该方法是一个嵌套模板， 第一层模板参数传入同步/异步工厂方法模板，第二层模板参数传入Sink。 使用方法如下： 12345// 同步loggerauto sync_file = spdlog::basic_logger_mt(&quot;file_logger&quot;, &quot;logs/basic-log.txt&quot;, true);// 异步loggerauto async_file = spdlog::basic_logger_mt&lt;spdlog::async_factory&gt;(&quot;async_file_logger&quot;, &quot;logs/async_log.txt&quot;); 工厂模板的create方法里调用了registry::initialize_logger。因此，通过工厂方法创建的每个同步logger都会被registry管理。 1234567template &lt;typename Sink, typename... SinkArgs&gt;static std::shared_ptr&lt;spdlog::logger&gt; create(std::string logger_name, SinkArgs &amp;&amp;...args) { auto sink = std::make_shared&lt;Sink&gt;(std::forward&lt;SinkArgs&gt;(args)...); auto new_logger = std::make_shared&lt;spdlog::logger&gt;(std::move(logger_name), std::move(sink)); details::registry::instance().initialize_logger(new_logger); return new_logger;} 被registry管理的logger可以通过日志名获取logger对象，日志名为logger对象的唯一标识符。 1auto logger = spdlog::get(&quot;console&quot;); 自定义logger也可以不使用工厂方法，自己手动定义一个logger对象。例如有时需要将logger指定多个输出Sink，可以通过以下形式： 1234567891011121314void multi_sink_example() { auto console_sink = std::make_shared&lt;spdlog::sinks::stdout_color_sink_mt&gt;(); console_sink-&gt;set_level(spdlog::level::warn); console_sink-&gt;set_pattern(&quot;[multi_sink_example] [%^%l%$] %v&quot;); auto file_sink = std::make_shared&lt;spdlog::sinks::basic_file_sink_mt&gt;(&quot;logs/multisink.txt&quot;, true); file_sink-&gt;set_level(spdlog::level::trace); spdlog::logger logger(&quot;multi_sink&quot;, {console_sink, file_sink}); logger.set_level(spdlog::level::debug); logger.warn(&quot;this should appear in both console and file&quot;); logger.info(&quot;this message should not appear in the console, only in the file&quot;);} 这种方法创建的logger对象不会被registry管理，如果需要加入管理可以手动执行 12345678auto console_sink = std::make_shared&lt;spdlog::sinks::stdout_color_sink_mt&gt;();console_sink-&gt;set_pattern(&quot;[%Y-%m-%d %H:%M:%S.%e] [%n] [%^%l%$] %v&quot;);auto my_logger = std::make_shared&lt;spdlog::logger&gt;(&quot;my_logger&quot;, console_sink);my_logger-&gt;set_level(spdlog::level::debug);// 将 logger 对象注册到 spdlog 的管理系统中spdlog::register_logger(my_logger); 日志接口logger类通过重载实现了丰富的接口，多数的接口都指向一个公共实现: 123456789101112131415161718192021// common implementation for after templated public api has been resolvedtemplate &lt;typename... Args&gt;void log_(source_loc loc, level::level_enum lvl, string_view_t fmt, Args &amp;&amp;...args) { bool log_enabled = should_log(lvl); bool traceback_enabled = tracer_.enabled(); if (!log_enabled &amp;&amp; !traceback_enabled) { return; } SPDLOG_TRY { memory_buf_t buf;#ifdef SPDLOG_USE_STD_FORMAT fmt_lib::vformat_to(std::back_inserter(buf), fmt, fmt_lib::make_format_args(args...));#else fmt::vformat_to(fmt::appender(buf), fmt, fmt::make_format_args(args...));#endif details::log_msg log_msg(loc, name_, lvl, string_view_t(buf.data(), buf.size())); log_it_(log_msg, log_enabled, traceback_enabled); } SPDLOG_LOGGER_CATCH(loc)} 传入的参数的含义分别为： source_loc，用来记录文件名、函数名和行号的结构体，用来保存__FILE__、__func__和__line__等宏信息； level::level_enum 日记的等级 string_view_t和args，日志内容及其参数，可以选择使用fmt的实现，若使用C++17及以上，可以选择std中的实现。 将传入的参数保存至log_msg结构体中，传递给log_it_方法。日志等级通过should_log函数进行过滤。除了日记记录level，还有flush_level_，当日志等级高于flush_level_时立即对日志内容刷新。 这两个变量都是用原子变量，保证多线程下的线程安全。 logger类也支持传递string类型的参数，例如 12345678910111213void log(log_clock::time_point log_time, source_loc loc, level::level_enum lvl, string_view_t msg) { bool log_enabled = should_log(lvl); bool traceback_enabled = tracer_.enabled(); if (!log_enabled &amp;&amp; !traceback_enabled) { return; } details::log_msg log_msg(log_time, loc, name_, lvl, msg); log_it_(log_msg, log_enabled, traceback_enabled);} string_view_t支持隐式转换，调用时可以直接传递std::string类型 日志的输出logger类不负责日志输出的具体实现，而是在**sink_it_**方法中调用Sink::log方法实现日志的输出 123456789101112SPDLOG_INLINE void logger::sink_it_(const details::log_msg &amp;msg) { for (auto &amp;sink : sinks_) { if (sink-&gt;should_log(msg.level)) { SPDLOG_TRY { sink-&gt;log(msg); } SPDLOG_LOGGER_CATCH(msg.source) } } if (should_flush_(msg)) { flush_(); }} 而Sink是一个抽象类，通过派生类的override来实现不同的日志输出功能。 backtracer调试功能spdlog 的 backtracer 功能是一个非常有用的调试工具，有时候输出的DEBUG信息过多会导致问题排查起来困难，而使用backtracer可以在问题出现时，打印最近的一些日志。这个功能特别适合于调试那些只有在特定条件下才会出现问题的场景 使用方法如下: 12345auto logger = spdlog::stdout_color_mt(&quot;console&quot;);logger-&gt;enable_backtrace(32); // 存储最近的32条消息...// 需要查看最近的日志logger-&gt;dump_backtrace(); 它的内部使用circular_q环形队列来保存日志，当达到最大容量时，新的消息会覆盖最旧的消息。由于是环形队列，避免了不必要的拷贝和移动开销，具有较高的性能。 性能优化logger实现了移动构造函数和swap函数，通过移动语义避免了对象的重复构造，具有较高的性能，。 1234567891011121314151617SPDLOG_INLINE void logger::swap(spdlog::logger &amp;other) SPDLOG_NOEXCEPT { name_.swap(other.name_); sinks_.swap(other.sinks_); // swap level_ auto other_level = other.level_.load(); auto my_level = level_.exchange(other_level); other.level_.store(my_level); // swap flush level_ other_level = other.flush_level_.load(); my_level = flush_level_.exchange(other_level); other.flush_level_.store(my_level); custom_err_handler_.swap(other.custom_err_handler_); std::swap(tracer_, other.tracer_);}","link":"/2024/09/28/spdlog%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB-%E4%BA%8C-%EF%BC%9ALogger%E7%B1%BB%E7%9A%84%E5%AE%9E%E7%8E%B0/"},{"title":"spdlog源码阅读(四)：Sink系列类的实现","text":"Sink是一系列类，功能为负责日志输出的具体实现，其通过继承的方式实现拓展。基类Sink的类定义如下： 12345678910111213141516class SPDLOG_API sink {public: virtual ~sink() = default; virtual void log(const details::log_msg &amp;msg) = 0; virtual void flush() = 0; virtual void set_pattern(const std::string &amp;pattern) = 0; virtual void set_formatter(std::unique_ptr&lt;spdlog::formatter&gt; sink_formatter) = 0; void set_level(level::level_enum log_level); level::level_enum level() const; bool should_log(level::level_enum msg_level) const;protected: // sink log level - default is all level_t level_{level::trace};}; Sink类的实现Sink类是一个纯虚类，无法被实例化。在类的声明前包含了SPDLOG_API宏，这是用于动态库符号导出的宏。 在win平台中，生成动态库时需要使用__declspec(dllexport)显式声明使得这些符号可以被其他程序使用，这是必须选项。在其他程序使用动态库时，使用__declspec(dllimport)声明导入了该符号，虽然这不是必须选项，但是有助于理解和编译器优化。 而在其他Linux平台中，编译动态库时默认导出所有符号，可以使用-fvisibility=hidden编译选项使默认符号不导。为了更详细的控制符号的导出，可以使用__attribute__((visibility(&quot;default&quot;)))来设置使符号导出，使用__attribute__ ((visibility(&quot;hidden&quot;)))设置使符号不导出。 它一共实现了4个纯虚函数，分别是： log:接收传递的日志信息，并输出到具体位置，子类通过重载这个函数来实现各种日志输出功能。 flush:日志刷新函数，可以调用该函数实现日志的刷新。 set_pattern:设置日志消息格式 set_formatter:设置日志消息格式化器 成员变量只有level_，它是std::atomic&lt;int&gt;类型，可以以比较低的开销实现线程安全性。 base_sink类的实现Sink类负责定义接口和基本的读写方法，而sink基础的功能在base_sink中实现 12345678910111213141516171819202122232425262728template &lt;typename Mutex&gt;class SPDLOG_API base_sink : public sink {public: ****base_sink(); explicit base_sink(std::unique_ptr&lt;spdlog::formatter&gt; formatter); ~base_sink() override = default; base_sink(const base_sink &amp;) = delete; base_sink(base_sink &amp;&amp;) = delete; base_sink &amp;operator=(const base_sink &amp;) = delete; base_sink &amp;operator=(base_sink &amp;&amp;) = delete; void log(const details::log_msg &amp;msg) final override; void flush() final override; void set_pattern(const std::string &amp;pattern) final override; void set_formatter(std::unique_ptr&lt;spdlog::formatter&gt; sink_formatter) final override;protected: // sink formatter std::unique_ptr&lt;spdlog::formatter&gt; formatter_; Mutex mutex_; virtual void sink_it_(const details::log_msg &amp;msg) = 0; virtual void flush_() = 0; virtual void set_pattern_(const std::string &amp;pattern); virtual void set_formatter_(std::unique_ptr&lt;spdlog::formatter&gt; sink_formatter);}; base_sink通过删除拷贝构造、移动构造、拷贝赋值和移动赋值来防止sink对象的复制和移动，以确保对象具有独占的所有权或避免资源管理问题。 base_sink类中对重载的函数使用了final和override关键字，用于显式声明函数是重载以及不能被再次重载。 base_sink 是一个模板类，模板参数为 Mutex，通过传递不同类型的 Mutex，可以实现不同的线程控制功能。传递 std::mutex 时，base_sink 具备线程安全性。如果需要更高的性能，可以传递 spdlog 定义的 null_mutex。null_mutex 实现了 lock 和 unlock 方法，但它们不执行任何实际操作，因此不会引入锁机制的开销，这个方法通过一套代码实现了线程安全和非线程安全的代码。 1234struct null_mutex { void lock() const {} void unlock() const {}}; 如果看base_sink 会发现该类只是实现了一个简单的封装，使用互斥锁来保证线程安全性，具体的实现由新定义的sink_it_、flush_、set_pattern_和set_formatter_方法实现。 basic_file_sink类的实现basic_file_sink才是sink的最完整的实现，其关键成员属性details::file_helper file_helper_ 负责文件的打开，写入和刷新 1234567891011template &lt;typename Mutex&gt;SPDLOG_INLINE void basic_file_sink&lt;Mutex&gt;::sink_it_(const details::log_msg &amp;msg) { memory_buf_t formatted; base_sink&lt;Mutex&gt;::formatter_-&gt;format(msg, formatted); file_helper_.write(formatted);}template &lt;typename Mutex&gt;SPDLOG_INLINE void basic_file_sink&lt;Mutex&gt;::flush_() { file_helper_.flush();} memory_buf_t是spdlog管理字符缓存的自定义类型，当使用std库时，其为std::string，如果使用fmt库，则使用的是fmt::basic_memory_buffer&lt;char, 250&gt;，fmt::basic_memory_buffer 通过预分配栈缓冲区和减少动态分配，能够在高效格式化操作中表现更佳，可以根据项目使用的日志长度，调整预分配的大小。 除了实现之外，还封装了使用接口，使用basic_file_sink_mt和basic_file_sink_st来区分多线程版和单线程版。 12345678910111213141516171819202122232425using basic_file_sink_mt = basic_file_sink&lt;std::mutex&gt;;using basic_file_sink_st = basic_file_sink&lt;details::null_mutex&gt;;} // namespace sinks//// factory functions//template &lt;typename Factory = spdlog::synchronous_factory&gt;inline std::shared_ptr&lt;logger&gt; basic_logger_mt(const std::string &amp;logger_name, const filename_t &amp;filename, bool truncate = false, const file_event_handlers &amp;event_handlers = {}) { return Factory::template create&lt;sinks::basic_file_sink_mt&gt;(logger_name, filename, truncate, event_handlers);}template &lt;typename Factory = spdlog::synchronous_factory&gt;inline std::shared_ptr&lt;logger&gt; basic_logger_st(const std::string &amp;logger_name, const filename_t &amp;filename, bool truncate = false, const file_event_handlers &amp;event_handlers = {}) { return Factory::template create&lt;sinks::basic_file_sink_st&gt;(logger_name, filename, truncate, event_handlers);} 通过工厂方法方便创建logger实例，而不需要单独创建logger对象和sink对象。","link":"/2024/10/14/spdlog%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB-%E5%9B%9B-%EF%BC%9ASink%E7%B3%BB%E5%88%97%E7%B1%BB%E7%9A%84%E5%AE%9E%E7%8E%B0/"},{"title":"windbg使用教程","text":"windbg是微软开发的用于在win平台调试程序的强大工具，支持内核态、用户态调试。可以调试程序、正在运行的进程和动态库，本教程主要介绍在用户态模式下调试应用程序。 相比VS调试程序，windbg开箱即用，不需要安装负责的编译环境，方便在生产环境调试。但是缺点是windbg上手难度大，对新手非常不友好。 安装微软应用商店建议直接从微软应用商店中安装，直接安装最新版，注意该版本不带有gflags等工具，需要安装相关工具需要从下载。 windows sdk可以从Windows SDK安装包中安装，选择只安装**Debugging Tools for Windows，**下载地址见：Windows SDK - Windows 应用开发 | Microsoft Developer 可以只安装**Debugging Tools for Windows，**其它的组件按需安装即可。 基本使用功能布局 与所有调试工具一样，windbg提供基本的调试功能，例如断点，步过、步入、步出。具有反汇编窗口、寄存器窗口、内存窗口、调用堆栈、局部变量窗口、线程/进程窗口和输出窗口。支持按钮交互控制和命令控制台。 基本命令命令可以参考微软官方命令手册：Using WinDbg and the debugger commands - Windows drivers | Microsoft Learn 以下是我收集和翻译的Cheat Sheet，用于速查命令。 运行程序加载PDB文件默认条件下会加载可执行文件路径下的pdb文件，使用lm命令可以判断是否加载。如果没有加载可以使用.sympath+命令手动加载符号文件目录 1.sympath+ C:\\Your\\PDB\\Directory 再强制重新加载符号 1.reload /f 加载源文件可以通过上方的打开源码按钮来加载源码，也可以使用.open命令打开源码文件。 1.open -a C:\\Path\\To\\file.cppp 如上图布局所示，基本的调试环境已经全部加载完成了。 其他wingdb功能非常强大，但是想要快速定位和解决内存的问题还是不足，需要借助gflags工具进行快速定位。以下为一些比较好的博客推荐： https://blog.hawkhai.com/blog/2020/12/26/memory-leak-gflags#%E5%AE%8C%E5%85%A8%E9%A1%B5%E5%A0%86","link":"/2025/05/29/windbg%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/"},{"title":"内存映射MMAP","text":"介绍mmap 是一种操作系统提供的系统调用，用于在进程的虚拟地址空间中创建内存映射区域，实现文件和内存之间的直接映射。 一般来说，修改一个文件的内容需要如下3个步骤： 把文件内容读入到内存中。 修改内存中的内容。 把内存的数据写入到文件中。如果使用代码来实现上面的过程，代码如下： 123read(fd, buf, 1024); // 读取文件的内容到buf... // 修改buf的内容write(fd, buf, 1024); // 把buf的内容写入到文件 从图中可以看出，页缓存(page cache) 是读写文件时的中间层，内核使用 页缓存 与文件的数据块关联起来。所以应用程序读写文件时，实际操作的是 页缓存。 从传统读写文件的过程中，我们可以发现有个地方可以优化：如果可以直接在用户空间读写 页缓存，那么就可以免去将 页缓存 的数据复制到用户空间缓冲区的过程。 那么，有没有这样的技术能实现上面所说的方式呢？答案是肯定的，就是 mmap。 使用 mmap 系统调用可以将用户空间的虚拟内存地址与文件进行映射（绑定），对映射后的虚拟内存地址进行读写操作就如同对文件进行读写操作一样。原理如图所示：前面我们介绍过，读写文件都需要经过 页缓存，所以 mmap 映射的正是文件的 页缓存，而非磁盘中的文件本身。由于 mmap 映射的是文件的 页缓存，所以就涉及到同步的问题，即 页缓存 会在什么时候把数据同步到磁盘。 Linux 内核并不会主动把 mmap 映射的 页缓存 同步到磁盘，而是需要用户主动触发。 同步 mmap 映射的内存到磁盘的 4 个时机： 调用 msync 函数主动进行数据同步（主动）。 调用 munmap 函数对文件进行解除映射关系时（主动）。 进程退出时（被动）。 系统关机时（被动）。 相关函数函数原型 1void *mmap(void *start, size_t length, int prot, int flags, int fd, off_t offset); 用于将文件或匿名内存映射到进程的虚拟地址空间中 返回说明 成功执行时，mmap()返回被映射区的指针。失败时，mmap()返回MAP_FAILED[其值为(void *)-1]， error被设为以下的某个值： 1234567891011 1 EACCES：访问出错 2 EAGAIN：文件已被锁定，或者太多的内存已被锁定 3 EBADF：fd不是有效的文件描述词 4 EINVAL：一个或者多个参数无效 5 ENFILE：已达到系统对打开文件的限制 6 ENODEV：指定文件所在的文件系统不支持内存映射 7 ENOMEM：内存不足，或者进程已超出最大内存映射数量 8 EPERM：权能不足，操作不允许 9 ETXTBSY：已写的方式打开文件，同时指定MAP_DENYWRITE标志10 SIGSEGV：试着向只读区写入11 SIGBUS：试着访问不属于进程的内存区 参数 start：映射区的开始地址 length：映射区的长度 prot：期望的内存保护标志，不能与文件的打开模式冲突。是以下的某个值，可以通过or运算合理地组合在一起 12341 PROT_EXEC ：页内容可以被执行2 PROT_READ ：页内容可以被读取3 PROT_WRITE ：页可以被写入4 PROT_NONE ：页不可访问 flags：指定映射对象的类型，映射选项和映射页是否可以共享。它的值可以是一个或者多个以下位的组合体 1234567891011121314 1 MAP_FIXED //使用指定的映射起始地址，如果由start和len参数指定的内存区重叠于现存的映射空间，重叠部分将会被丢弃。如果指定的起始地址不可用，操作将会失败。并且起始地址必须落在页的边界上。 2 MAP_SHARED //与其它所有映射这个对象的进程共享映射空间。对共享区的写入，相当于输出到文件。直到msync()或者munmap()被调用，文件实际上不会被更新。 3 MAP_PRIVATE //建立一个写入时拷贝的私有映射。内存区域的写入不会影响到原文件。这个标志和以上标志是互斥的，只能使用其中一个。 4 MAP_DENYWRITE //这个标志被忽略。 5 MAP_EXECUTABLE //同上 6 MAP_NORESERVE //不要为这个映射保留交换空间。当交换空间被保留，对映射区修改的可能会得到保证。当交换空间不被保留，同时内存不足，对映射区的修改会引起段违例信号。 7 MAP_LOCKED //锁定映射区的页面，从而防止页面被交换出内存。 8 MAP_GROWSDOWN //用于堆栈，告诉内核VM系统，映射区可以向下扩展。 9 MAP_ANONYMOUS //匿名映射，映射区不与任何文件关联。10 MAP_ANON //MAP_ANONYMOUS的别称，不再被使用。11 MAP_FILE //兼容标志，被忽略。12 MAP_32BIT //将映射区放在进程地址空间的低2GB，MAP_FIXED指定时会被忽略。当前这个标志只在x86-64平台上得到支持。13 MAP_POPULATE //为文件映射通过预读的方式准备好页表。随后对映射区的访问不会被页违例阻塞。14 MAP_NONBLOCK //仅和MAP_POPULATE一起使用时才有意义。不执行预读，只为已存在于内存中的页面建立页表入口。 fd：有效的文件描述词。如果MAP_ANONYMOUS被设定，为了兼容问题，其值应为-1 offset：被映射对象内容的起点 相关函数 1int munmap( void * addr, size_t len ) 成功执行时，munmap()返回0。失败时，munmap返回-1，error返回标志和mmap一致； 该调用在进程地址空间中解除一个映射关系，addr是调用mmap()时返回的地址，len是映射区的大小； 当映射关系解除后，对原来映射地址的访问将导致段错误发生。 1int msync( void *addr, size_t len, int flags ) 一般说来，进程在映射空间的对共享内容的改变并不直接写回到磁盘文件中，往往在调用munmap()后才执行该操作。 可以通过调用msync()实现磁盘上文件内容与共享内存区的内容一致。 优缺点优点1、对文件的读取操作跨过了页缓存，减少了数据的拷贝次数，用内存读写取代I/O读写，提高了文件读取效率。 2、实现了用户空间和内核空间的高效交互方式。两空间的各自修改操作可以直接反映在映射的区域内，从而被对方空间及时捕捉。 3、提供进程间共享内存及相互通信的方式。不管是父子进程还是无亲缘关系的进程，都可以将自身用户空间映射到同一个文件或匿名映射到同一片区域。从而通过各自对映射区域的改动，达到进程间通信和进程间共享的目的。 4、可用于实现高效的大规模数据传输。内存空间不足，是制约大数据操作的一个方面，解决方案往往是借助硬盘空间协助操作，补充内存的不足。但是进一步会造成大量的文件I/O操作，极大影响效率。这个问题可以通过mmap映射很好的解决。换句话说，但凡是需要用磁盘空间代替内存的时候，mmap都可以发挥其功效。 缺点 由于 mmap 使用时必须实现指定好内存映射的大小，因此 mmap 并不适合变长文件； 如果更新文件的操作很多，mmap 避免两态拷贝的优势就被摊还，最终还是落在了大量的脏页回写及由此引发的随机 I/O 上，所以在随机写很多的情况下，mmap 方式在效率上不一定会比带缓冲区的一般写快； 读/写小文件（例如 16K 以下的文件），mmap 与通过 read 系统调用相比有着更高的开销与延迟；同时 mmap 的刷盘由系统全权控制，但是在小数据量的情况下由应用本身手动控制更好； mmap 受限于操作系统内存大小：例如在 32-bits 的操作系统上，虚拟内存总大小也就 2GB，但由于 mmap 必须要在内存中找到一块连续的地址块，此时你就无法对 4GB 大小的文件完全进行 mmap，在这种情况下你必须分多块分别进行 mmap，但是此时地址内存地址已经不再连续，使用 mmap 的意义大打折扣，而且引入了额外的复杂性； 使用场景 多个线程以只读的方式同时访问一个文件，这是因为 mmap 机制下多线程共享了同一物理内存空间，因此节约了内存。案例：多个进程可能依赖于同一个动态链接库，利用 mmap 可以实现内存仅仅加载一份动态链接库，多个进程共享此动态链接库。 mmap 非常适合用于进程间通信，这是因为对同一文件对应的 mmap 分配的物理内存天然多线程共享，并可以依赖于操作系统的同步原语； mmap 虽然比 sendfile 等机制多了一次 CPU 全程参与的内存拷贝，但是用户空间与内核空间并不需要数据拷贝，因此在正确使用情况下并不比 sendfile 效率差； 相关阅读一文读懂 mmap 原理 认真分析mmap：是什么 为什么 怎么用 10分钟了解什么是内存映射MMAP！","link":"/2024/04/23/%E5%86%85%E5%AD%98%E6%98%A0%E5%B0%84MMAP/"},{"title":"多线程内存模型(1)：指令重排序","text":"内存模型是多线程编程中非常复杂的概念，在了解这些内容之前需要了解一下前置知识 指令重排序首先也是最复杂的部分：代码重排序。编译器和 CPU 能够重新排列程序指令，这些操作之间是相互独立的，编译器可以重新排列指令，然后 CPU 可以再次重新排列指令。 编译器重排序编译器可能会改变源代码中指令的顺序，以提高代码的执行效率。例如优化寄存器的使用次数，优化内存布局和实现指令并行。 一般来说，只有没有关系的两条指令才有可能被重排，例如这段代码： 12int x = 1;double y = 3.14; 这种情况先初始化x还是先初始化y对程序逻辑没有影响。重排序是为了代码有更好的效率，例如这段代码： 12345678910111213141516171819//优化前int x = 1;int y = 2;int a1 = x * 1;int b1 = y * 1;int a2 = x * 2;int b2 = y * 2;int a3 = x * 3;int b3 = y * 3;//优化后int x = 1;int y = 2;int a1 = x * 1;int a2 = x * 2;int a3 = x * 3;int b1 = y * 1;int b2 = y * 2;int b3 = y * 3; 交替的读x、y，会导致寄存器频繁的交替存储x和y，最糟的情况下寄存器要存储3次x和3次y。如果能让x的一系列操作一块做完，y的一块做完，理想情况下寄存器只需要存储1次x和1次y。 CPU乱序执行指令重排序是处理器层面做的优化。处理器在执行时往往会因为一些限制而等待，如访存的地址在cache中未命中，这时就需要到内存甚至外存去取，然而内存和外区的读取速度比CPU执行速度慢得多。 早期处理器是顺序执行(in-order execution)的，在内存、外存读取数据这段时间，处理器就一直处于等待状态。现在处理器一般都是乱序执行(out-of-order execution)，处理器会在等待数据的时候去执行其他已准备好的操作，不会让处理器一直等待。 满足乱序执行的条件： 该缓存的操作数缓存好 有空闲的执行单元 对于下面这段汇编代码，操作1如果发生cache miss，则需要等待读取内存外存。看看有没有能优先执行的指令，操作2依赖于操作1，不能被优先执行，操作3不依赖1和2，所以能优先执行操作3。 所以实际执行顺序是3&gt;1&gt;2 123LDR R1, [R0];//操作1ADD R2, R1, R1;//操作2ADD R3, R4, R4;//操作3 缓存一致性重排序这是指令重排序最难理解的部分，是由缓存不一致导致的重排序，我们先来看一段代码： 12345678910111213141516171819202122232425262728#include &quot;bits/stdc++.h&quot;using namespace std;void test() { int y = 0; int x = 0; auto thread1 = [&amp;]() { x = 1; y = 1; }; auto thread2 = [&amp;]() { while (y != 1); assert(x == 1); }; thread t1(thread1); thread t2(thread2); t1.join(); t2.join();}int main() { for (int i = 1; i &lt;= 100000; i++) { test(); } return 0; 注：这段代码在现代编译器和现代操作系统的优化下已经不再会抛出异常了。 这段代码是有可能抛出x≠1的异常的，对于thread1来说，是先执行x=1再执行y=1，但是对于thread2来说，有可能是先执行y=1再执行x=1，即两个线程看这一段代码的执行顺序可能不一样。这种差异是由缓存不一致导致的，CPU的缓存架构如下。 每个核都有自己专属的L1和L2缓存，而所有核共享L3缓存。变量赋值的移动顺序一般是：内存→L3缓存→L2缓存→L1缓存→寄存器。赋值操作后，变量值需要通过缓存一致性协议传播到L3缓存，再由L3缓存同步到其他核。在变量赋值后到更新到L3缓存之前，该变量的赋值对其他核是不可见的。 假设在thread1中，核先执行x=1，再执行y=1。但是，如果y的赋值先被刷新到L3缓存，而x的赋值后被刷新，那么对其他核来说，顺序会变成先看到y=1，再看到x=1。这是变量的更新顺序在多个缓存层之间传递时，引入的重排序。 多线程视角下的指令重排as-if-serial规则无论编译器和CPU对指令如何重排，都不会影响单线程下的运行结果，这也被称为as-if-serial规则。as-if-serial规则保证了程序在单线程执行的正确性，但在保证多线程执行的正确性上却无能为力。例如这段代码： 123456789101112131415161718192021222324252627282930// demo.cpp#include &quot;bits/stdc++.h&quot;using namespace std;int x = 0;int y = 0;void test() { auto thread1 = [&amp;]() { x = y + 1; y = 1; }; auto thread2 = [&amp;]() { while (y != 1); assert(x == 1); }; thread t1(thread1); thread t2(thread2); t1.join(); t2.join();}int main() { test(); return 0;} 编译时开启O2优化 1g++ demo.cpp -o demo -lpthread -O2 由于编译器的指令重排，导致y=1的赋值指令在x=y+1赋值指令之前，这段线程t1的运行没有影响，但是却影响了线程t2的执行结果。 happens-before规则happens-before是并发编程中的一个概念，用于描述多线程运行时两个操作之间的顺序关系。如果一个操作A happens-before另一个操作B，则必须保证执行语义与A在B之前执行的语义一致。 多线程编程没有像单线程as-if-serial规则这样强有力的规则来保证执行的正确性，但C++也 提供了一系列的happens-before规则来保证在多线程环境运行下的顺序。 程序顺序规则（Program Order Rule）： 单个线程内的每个操作都 happens-before 该线程中随后进行的任何操作，即as-if-serial规则。 锁定规则（Locking Rule）： 解锁一个互斥锁 happens-before 该互斥锁的任何后续加锁。 条件变量规则（Condition Variable Rule）： 通知（notify）某个条件变量 happens-before 任意一个随后对该条件变量的等待（wait）成功返回。 原子操作规则（Atomic Operation Rule）： 一个原子操作上的释放（release）操作 happens-before 另一个线程中该原子操作上的获取（acquire）操作。 线程启动和结束规则（Thread Start and Join Rule）： 一个线程的启动（std::thread 构造函数） happens-before 该线程中执行的任何操作。 一个线程的结束（std::thread 的 join 或 detach） happens-before join 返回或者 detach 完成。 内存一致性操作使用使用内存一致性协议MESI来保证各个核内部缓存数据的一致性，但是完全的确保顺序一致性需要很大的代价，不仅限制编译器的优化，也限制了CPU的执行效率。为了更好地挖掘硬件的并行能力，现代的CPU多半都是介于两者之间，即所谓的宽松的内存一致性模型（Relaxed Memory Consistency Models）。 由于内存一致性不能保证，也导致了多线程编程时的资源竞争，如读脏数据、更新丢失和指令重排。 参考文档https://www.cnblogs.com/zhongqifeng/p/14889070.html https://mp.weixin.qq.com/s/Unh56s2FI5eMaeDjrGcGrw https://www.0xffffff.org/2017/02/21/40-atomic-variable-mutex-and-memory-barrier/","link":"/2024/07/28/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B-1-%EF%BC%9A%E6%8C%87%E4%BB%A4%E9%87%8D%E6%8E%92%E5%BA%8F/"},{"title":"多线程内存模型(2)：内存屏障","text":"重排序总的来说有四种类型 重排序类型Load-Load 重排序交换两个读取指令的顺序 123456// 原始顺序int a = *p;int b = *q;// 重新排序int b = *q;int a = *p; Store-Store重排序交换两个存储指令的顺序 123456// 原始顺序*p = a;*q = b;// 重新排序*q = b;*p = a; Load-Store重排序交换读取和存储指令的顺序 123456// 原始顺序int a = *p;*q = b;// 重新排序*q = b;int a = *p; Store-Load重排序交换存储指令和读取指令的顺序 123456// 原始顺序*p = a;int b = *q;// 重新排序int b = *q;*p = a; 屏障CPU和编译器都预留了一些方法给我们阻止重排序，这些方法统称为屏障(Barrier)。根据之前提到的编译器重排和CPU重排，有编译器屏障和CPU屏障。 以这段代码为例，开启O2优化后b的赋值在a的赋值之前，这是编译器导致的重排序。 编译器屏障编译器屏障用于阻止编译器重新排序特定的指令，GCC 提供了 asm 内联汇编语法来实现，即asm volatile(&quot;&quot; ::: &quot;memory&quot;)。 插入编译器屏障之后，编译器不会重新排序屏障之前和之后的指令。 内存屏障即使编译器层面不会对代码进行重排，但在CPU层面还是可能会对代码进行重排，因此需要使用更底层的屏障。内存屏障，也叫运行时内存屏障(Runtime Memory Barrier) 编译器内置GCC 提供了内置函数来实现这些屏障，__sync_synchronize 。这是一个全局内存屏障，确保在屏障之前的所有内存操作在屏障之后的内存操作之前完成。 当编译器识别到内存屏障时，默认不会对这部分的指令进行重排序。 CPU指令注意到调用__sync_synchronize函数后，汇编代码对应的位置会增加一条mfence指令，这是 x86 和 x86_64 架构中的一条内存屏障指令，用于强制对所有读写内存操作进行序列化。 内存屏障一共有三种：分为写屏障（Store Barrier）、读屏障（Load Barrier）和全屏障（Full Barrier），在 x86平台分别对应着sfence、lfence和mfence。 mfence：全屏障确保在屏障之前的所有读和写操作在屏障之后的读和写操作之前完成 lfence：读屏障确保在屏障之前的所有读操作在屏障之后的读操作之前完成 sfence：写屏障确保在屏障之前的所有写操作在屏障之后的写操作之前完成 使用内联汇编来插入这些屏障指令的示例： 12345678#define MFENCE() asm volatile(&quot;mfence&quot; ::: &quot;memory&quot;)int a, b;void foo() { a = b + 1; MFENCE(); b = 0;} 读屏障和写屏障的与第一部分提到的四种重排序有关，该部分与平台强相关，详细内容可以查阅官方手册Intel® 64 and IA-32 Architectures Software Developer’s Manual 参考文章https://blog.csdn.net/wxj1992/article/details/103649056","link":"/2024/08/08/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B-2-%EF%BC%9A%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C/"},{"title":"多线程内存模型(3)：锁，原子变量","text":"锁锁是多线程编程中最常用的同步机制，用于保护共享资源，防止多个线程同时访问或修改，从而避免数据不一致或竞态条件的发生。以下代码是互斥锁的使用，利用RAII来完成自动锁的自动析构。 123456789int counter = 0;std::mutex mtx;void increment(int times) { for (int i = 0; i &lt; times; i++) { std::lock_guard&lt;std::mutex&gt; lock(mtx); ++counter; }} increment函数是使用互斥锁保护共享资源的函数，可以在多线程调用时保证线程安全性。锁有两种状态，一种是没有被其他线程获取，此时可以马上获取锁的所有权。另一种是已被其他线程获取，此时当前线程获取就会进入阻塞，由用户态进入内核态，等待满足条件时再次唤醒。 但在increment函数中，++counter操作开销要比用户态和内核态之间上下文切换带来的开销要小得多。为了优化性能，需要使用开销更小的同步方式。 原子变量原子操作是一种不可分割的操作，即操作要么完全执行，要么完全不执行，中间不会被中断或看到不完整的状态。在多线程编程中，原子操作可以在不使用锁的情况下保证线程安全，防止数据竞争。而具有原子操作方法的变量叫做原子变量。 原子操作并非不使用锁，只是在更底层使用Lock#指令锁，可以以一个更低开销的方式来实现同步，原子操作不需要进入内核态，没有上下文切换，因此有更高的性能。但也因此原子操作并不支持太复杂的操作。 原子变量支持的操作加载和存储操作 load()：从原子变量中读取值。 store(value)：将值存储到原子变量中。 在实际使用中，可以直接赋值和取值，编译器会帮我们调用该方法，而不需要刻意调用load和store。 交换操作 exchange(value)：将新值存储到原子变量中，并返回旧值。 比较并交换 compare_exchange_strong(expected, desired)：如果原子变量的当前值等于 expected，则将其设置为 desired，否则不做任何操作。返回是否成功执行替换。 compare_exchange_weak(expected, desired)：与 compare_exchange_strong 类似，但可能会在并发情况下产生伪失败（即使条件满足，也可能失败），适用于循环重试的情况。 算术操作 fetch_add(value)：将 value 加到原子变量的当前值上，并返回旧值。 fetch_sub(value)：将 value 从原子变量的当前值中减去，并返回旧值。 位操作 fetch_and(value)：对原子变量的当前值与 value 进行按位与操作，并返回旧值。 fetch_or(value)：对原子变量的当前值与 value 进行按位或操作，并返回旧值。 fetch_xor(value)：对原子变量的当前值与 value 进行按位异或操作，并返回旧值。 增减操作 ++、--：原子变量的递增和递减操作。返回新值或旧值，取决于操作是前缀还是后缀形式。 内存序控制原子变量除了提供原子操作之外，也提供了多种内存序选项，可以用来控制原子变量前后包括非原子变量的内存顺序。atomic头文件提供了6中内存序，用来进行不同的内存序控制。 memory_order_relaxed不对操作的顺序或可见性施加任何约束。只保证原子操作本身的原子性，而不保证与其他原子操作或非原子操作的顺序。这种用法适用于不依赖操作顺序的场景，通常用于计数器、统计数据等场景。 12345std::atomic&lt;int&gt; counter(0);void increment() { counter.fetch_add(1, std::memory_order_relaxed);} 在这个例子中，允许多个线程同时调用increment，只需要确保计数器的递增是原子的，而不关心累加操作的顺序。 memory_order_acquire保证当前原子操作之前的所有读写操作都能被原子操作之后的操作可见。它是通过保证所有原子操作之后的读写不能重排到原子操作之前来保证可见性的。 memory_order_release保证当前原子操作之前的所有读写操作都能被原子操作之后的操作可见。但它是通过保证所有原子操作之前的操作不能重排到原子操作之后来保证可见性的。 这两者内存序经常同时使用，例如这段代码 123456789101112131415std::atomic&lt;int*&gt; ptr(nullptr);int data;void producer() { data = 42; ptr.store(&amp;data, std::memory_order_release);}void consumer() { int* p; while (!(p = ptr.load(std::memory_order_acquire))) ; assert(*p == 42);} memory_order_consume这个与memory_order_acquire功能类似，也是保证原子操作之后的读写不能重排到原子操作之前来保证可见性的，与memory_order_acquire的区别是只保证有依赖关系的读写操作不重排到原子操作之前。但实际上很多编译器都没有正确地实现memory_order_consume，导致等同于memory_order_acquire memory_order_acq_rel结合了memory_order_acquire和memory_order_release的特性。既保证了获取操作的可见性，又保证了释放操作的顺序性。常用于读-改-写的场景，如比较并交换（CAS）操作中，既需要获取又需要释放，例如这个简单的无锁栈。 123456789std::atomic&lt;Node*&gt; head(nullptr);void push(Node* new_node) { Node* old_head = head.load(std::memory_order_relaxed); do { new_node-&gt;next = old_head; } while (!head.compare_exchange_weak(old_head, new_node, std::memory_order_acq_rel));} memory_order_seq_cst全序一致性，是最强的内存序保证。所有线程中的所有原子操作都按顺序执行，避免了所有的重排。它是默认的内存序类型，例如这个多线程生产者-消费者模型。 1234567891011121314std::atomic&lt;int&gt; data(0);std::atomic&lt;bool&gt; flag(false);void producer() { data.store(42, std::memory_order_seq_cst); flag.store(true, std::memory_order_seq_cst);}void consumer() { while (!flag.load(std::memory_order_seq_cst)) ; // busy-wait assert(data.load(std::memory_order_seq_cst) == 42); // 必然成立}","link":"/2024/09/20/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B-3-%EF%BC%9A%E9%94%81%EF%BC%8C%E5%8E%9F%E5%AD%90%E5%8F%98%E9%87%8F/"},{"title":"抓包工具的使用","text":"HTTP抓包工具有老牌的Fiddler和Charles，但这些工具仅限于HTTP抓包，想要抓取传输层的tcp包则需要用到更加强大的wireshark和tcpdump。 wireshark和tcpdump都可以捕获通过网卡的所有网络通信的数据包，可以完整查看网络中的每层、每个协议、每个数据包的详细组成信息。但是缺点是信息太多，需要过滤和处理。 WireShark基本过滤规则IP 地址过滤 显示特定 IP 地址的流量： 1ip.addr == 192.168.1.100 这会显示源或目标 IP 地址为 192.168.1.100 的所有数据包。 显示某个 IP 地址之间的通信： 1ip.addr == 192.168.1.100 &amp;&amp; ip.addr == 8.8.8.8 这会显示源地址为 192.168.1.100 且目标地址为 8.8.8.8 之间的所有数据包。 协议过滤 显示特定协议的数据包： 1tcp 这会显示所有 TCP 数据包。 显示特定端口的流量： 1tcp.port == 80 这会显示目标或源端口为 80 的所有 TCP 数据包。 显示所有 ARP 数据包： 1arp 应用层协议过滤 显示 HTTP 请求和响应： 1http 这会显示所有 HTTP 请求和响应数据包。 显示 DNS 查询和响应： 1dns 这会显示所有 DNS 查询和响应数据包。 数据包方向过滤 显示进入或离开特定 IP 地址的流量： 1ip.src == 192.168.1.100 这会显示源地址为 192.168.1.100 的所有数据包。 显示进入或离开特定网络接口的流量： 1eth.addr == 00:11:22:33:44:55 这会显示以太网地址为 00:11:22:33:44:55 的所有数据包。 逻辑运算符 与运算符 (&amp;&amp;)： 1ip.addr == 192.168.1.100 &amp;&amp; tcp.port == 80 显示源或目标 IP 地址为 192.168.1.100 且目标或源端口为 80 的所有 TCP 数据包。 或运算符 (||)： 1ip.addr == 192.168.1.100 || ip.addr == 8.8.8.8 显示源地址为 192.168.1.100 或目标地址为 8.8.8.8 的所有数据包。 非运算符 (!)： 1!tcp.port == 80 显示所有不是目标或源端口为 80 的 TCP 数据包。 其它过滤条件 过滤特定数据包大小： 1frame.len &gt; 1000 显示大小大于 1000 字节的所有数据包。 根据协议层次过滤： 1tcp.flags.syn == 1 &amp;&amp; tcp.flags.ack == 0 显示 SYN 标志为 1 而 ACK 标志为 0 的所有 TCP 数据包（TCP 握手过程中的第一个数据包）。 根据时间戳过滤： 1frame.time &gt; &quot;2024-06-01 12:00:00&quot; 显示时间戳晚于 2024-06-01 12:00:00 的所有数据包。 tcpdump用法1tcpdump [options] [filter_expression] [options]：可选的命令行选项，用于配置 tcpdump 的捕获行为，如捕获的接口、是否显示数据包内容等。 [filter_expression]：过滤表达式，用于指定要捕获的数据包的类型或条件。 tcpdump基本过滤规则IP 地址过滤 显示特定 IP 地址的流量： 1host 192.168.1.100 这会显示源或目标 IP 地址为 192.168.1.100 的所有数据包。 显示特定 IP 地址之间的通信： 1host 192.168.1.100 and host 8.8.8.8 这会显示源地址为 192.168.1.100 且目标地址为 8.8.8.8 之间的所有数据包。 协议过滤 显示特定协议的数据包： 1tcp 这会显示所有 TCP 数据包。 显示特定端口的流量： 1port 80 这会显示目标或源端口为 80 的所有数据包。 显示所有 ARP 数据包： 1arp 应用层协议过滤 显示 HTTP 请求和响应： 1port 80 这会显示所有 HTTP 请求和响应数据包。 显示 DNS 查询和响应： 1port 53 这会显示所有 DNS 查询和响应数据包。 数据包方向过滤 显示进入或离开特定 IP 地址的流量： 1src host 192.168.1.100 这会显示源地址为 192.168.1.100 的所有数据包。 显示进入或离开特定网络接口的流量： 1ether host 00:11:22:33:44:55 这会显示以太网地址为 00:11:22:33:44:55 的所有数据包。 逻辑运算符 与运算符 (and)： 1src host 192.168.1.100 and port 80 显示源地址为 192.168.1.100 且目标或源端口为 80 的所有数据包。 或运算符 (or)： 1src host 192.168.1.100 or dst host 8.8.8.8 显示源地址为 192.168.1.100 或目标地址为 8.8.8.8 的所有数据包。 非运算符 (not)： 1not port 22 显示所有不是目标或源端口为 22 的数据包。 其它过滤条件 过滤特定数据包大小： 1greater 1000 显示大小大于 1000 字节的所有数据包。 根据协议层次过滤： 1tcp[13] &amp; 2 != 0 显示所有 SYN 标志为 1 而 ACK 标志为 0 的 TCP 数据包（即 TCP 握手过程中的第一个数据包）。 根据时间戳过滤： 1after &quot;2024-06-01 12:00:00&quot; 显示时间戳晚于 2024-06-01 12:00:00 的所有数据包。 tcpdump 还支持各种选项来更精确地控制捕获行为，例如指定捕获的网络接口、输出到文件等。以下是一些常用的选项： 指定捕获接口： 1tcpdump -i eth0 将捕获结果输出到文件： 1tcpdump -w capture.pcap 从文件中读取捕获结果：","link":"/2024/06/13/%E6%8A%93%E5%8C%85%E5%B7%A5%E5%85%B7%E7%9A%84%E4%BD%BF%E7%94%A8/"},{"title":"模型训练推理优化实践(一):训练优化","text":"NVIDIA提供了一些适用于CUDA层面的Profiling工具，其中最重要的是Nsight产品族的性能分析工具Nsight Systems、Nsight Compute和Nsight Graphics。 这里两个工具使用上互补，Nsight Systems更侧重整个系统性能分析，监视了CPU、GPU、内存和网络等资源的情况，可以识别系统整体的瓶颈。除了CUDA之外，也支持OpenGL、DirectX、Vulkan、CPU 线程等分析。 Nsight Graphics更适用于内核级微观分析，优化算子的计算效率。 例如，使用Nsight Systems和Nsight Compute对AI应用实现性能分析与优化的流程为： 先利用Nsight Systems观察到某个CUDA Kernel具体运行时间的功能，分析一下程序。 如果发现某个Kernel运行时间过长，可以使用Nsight Compute对这个CUDA Kernel做进一步的性能分析并进行优化。 CUDA Kernel如果优化完成，可以再次使用Nsight Systems对程序做Profiling，如此反复，直到整个程序的性能优化达到预期结果。 环境准备该实践需要安装以下环境： pytorch(GPU版本):用于下载、加载和训练和推理模型 nvtx:在程序中插入标记和区间，更清晰地可视化代码执行过程，便于性能分析与调优。 torch-tensorrt: 推理优化库 训练优化实践创建示例模型当搭建完一个深度学习网络，您可以使用NVIDIA Nsight Systems工具进行基准性能分析，观察哪些地方可以做优化。本文以TensorBoard-plugin tutorial中的示例模型为例，演示如何利用NVIDIA Nsight Systems工具寻找模型优化的机会。操作步骤如下所示。 创建一个如下的main.py文件 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667import nvtx # 引入nvtx包，便于在nsight system中观察各个函数的逻辑关系。import torchimport torch.nnimport torch.optimimport torch.profilerimport torch.utils.dataimport torchvision.datasetsimport torchvision.modelsimport torchvision.transforms as Ttransform = T.Compose([ T.Resize(224), T.ToTensor(), T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True)device = torch.device(&quot;cuda:0&quot;)model = torchvision.models.resnet18(weights='IMAGENET1K_V1').cuda(device)criterion = torch.nn.CrossEntropyLoss().cuda(device)optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)model.train()def train(data, batch_idx): # 数据传输 nvtx.push_range(&quot;copy data &quot; + str(batch_idx), color=&quot;rapids&quot;) inputs, labels = data[0].to(device=device), data[1].to(device=device) nvtx.pop_range() # 前向传播 nvtx.push_range(&quot;forward &quot; + str(batch_idx), color=&quot;yellow&quot;) outputs = model(inputs) loss = criterion(outputs, labels) nvtx.pop_range() # 后向传播 nvtx.push_range(&quot;backward &quot; + str(batch_idx), color=&quot;green&quot;) optimizer.zero_grad() loss.backward() optimizer.step() nvtx.pop_range()# 由于enumerate(train_loader)无法通过插入nvtx统计数据加载时间，将for循环代码替换为如下等价代码。dl = iter(train_loader)batch_idx = 0while True: try: # 统计最后3个batch总共持续的时间。 if batch_idx == 5: tet = nvtx.start_range(message=&quot;Total Elapsed Time(3 batchs)&quot;, color=&quot;orange&quot;) # 只观察前面8个batch，在这8个batch中前面5个用于wait和warmup，目标观察后面3个 if batch_idx &gt;= 8: nvtx.end_range(tet) break # 数据加载。 nvtx.push_range(&quot;__next__ &quot; + str(batch_idx), color=&quot;orange&quot;) batch_data = next(dl) nvtx.pop_range() # batch处理，包括数据传输和GPU计算 nvtx.push_range(&quot;batch &quot; + str(batch_idx), color=&quot;cyan&quot;) train(batch_data, batch_idx) nvtx.pop_range() batch_idx += 1 except StopIteration: nvtx.pop_range() break 执行以下命令，会在当前目录下生成名为baseline.nsys-rep的文件。 123456789nsys profile \\ -w true \\ --cuda-memory-usage=true \\ --python-backtrace=cuda \\ -s cpu \\ -f true \\ -x true \\ -o baseline \\ python ./main.py 预期输出： 12345Files already downloaded and verifiedGenerating '/tmp/nsys-report-6673.qdstrm'[1/1] [========================100%] baseline.nsys-repGenerated: /root/baseline.nsys-rep 将baseline.nsys-rep文件导入Nsight System UI中，即可对模型进行分析。如下为初次打开的效果图：本文仅参考最后3个Batch（前3个Batch可能会受到初始化和预热效应的影响，性能评估不准确）。如下所示，放大最后3个Batch的位置。图中有2个NVTX记录Batch时间，一个是在CUDA Stream（Default Stream）中（图中标号为1），一个是在Python线程中（图中标号为2），两者统计的Batch时间（包括copy data、forward、backward）有很大差别。因此如果调用CUDA API并在GPU上运行核函数，此时以在CUDA Stream中的NVTX为准（也就是标号1的数据），这是因为Batch传输和GPU计算对于CPU来说是异步的，Python线程中统计的可能不太准确。 Batch数据加载和Batch计算（包括将Batch传输到GPU）是重叠的，从上图中可以看到，当进行Batch 6的加载操作时，GPU端仍然在计算Batch 5，所以在后续计算3个Batch的总持续时间时，重叠部分不计算时间。 对Baseline各个阶段的持续时间统计如下： 各阶段持续时间 耗时（单位：ms） 平均数据加载时间（图中标记：next） (37.276 + 35.794 + 35.790) / 3 = 36.287 平均数据传输时间（图中折叠未显示出） (4.39 + 4.363 + 4.317) / 3 = 4.357 平均Batch处理时间（包含数据传输、forward、backward） (38.738 + 37.78 + 37.754) / 3 = 38.091 3个Batch总的持续时间（如下图所示，从第5个Batch数据加载到第7个Batch计算完成） 176.878 ms 平均每秒处理样本数（单位：samples/s） 32(batch size) * 3 / (176.878 / 1000) = 542.746 步骤二：优化和分析模型模型优化流程对于一个单机的深度学习训练任务，主要分为如下几个阶段： 数据加载（Data Loading）：通常情况下，把数据从Disk（或者其他网络存储系统）加载到主机内存，并对数据做预处理操作（例如，去除噪声值），笼统地称为数据加载阶段。 数据传输（Data Transmission）：将数据从主机内存传输到GPU内存。 训练（Training）：GPU计算单元（CUDA Core、Tensor Core）利用这些数据做训练操作。 以下将对每部分做一些案例介绍。 优化方向1：缩短数据加载（Data Loading）时间对于一个训练任务而言，缩短数据加载时间对整个训练任务有很大的帮助，如果数据加载时间大于GPU训练的时间，就有可能造成GPU空闲（等待数据加载）。 如下图所示，在Baseline（不包含任何优化措施）中，Batch与Batch计算之间存在很大的空隙，引起这些空隙的根因在于Batch数据加载时间比较长，GPU需要长时间等待数据加载完成才能处理这个Batch的数据，所以数据加载成为整个训练任务的瓶颈。 PyTorch的DataLoader支持多个Worker（Multi-process）同时工作，加载某一个Mini Batch的数据。修改main.py文件中的train_loader参数，尝试设置8个Worker加载数据。 1train_loader = torch.utils.data.DataLoader(train_set,num_workers=8, batch_size=32, shuffle=True) 重新运行，可以看到Batch与Batch之间已经没有空隙，同时数据加载时间大大缩小，三个Batch加载平均消耗时间为：(2.879 ms + 104.995 us + 180.066 us) / 3 = 1.055 ms。同时，每秒处理样本数（samples/s）为：32 * 3 /（120.328 / 1000）= 797.819（注意数据加载时间已经隐藏在GPU计算中，所以忽略），性能相比Baseline提升（797.819 - 542.746）/ 542.746 * 100% = 47.00%。 优化方向2：缩短数据传输（Data Transmission）时间在设置8个Worker的基础上，可以继续寻找示例模型训练中可优化的点。在上述的分析中，可以看到数据传输平均时间为4.357 ms，尝试开启Pin Memory来缩短数据传输时间。 在PyTorch中，支持将加载的数据直接存放在Pin Memory中。如下所示，修改main.py文件中的train_loader参数，开启Pin Memory。 1train_loader = torch.utils.data.DataLoader(train_set,num_workers=8, batch_size=32,pin_memory=True, shuffle=True) 重新运行代码，可以看到数据传输的平均时间为：（1.956 + 1.979 + 1.989）/ 3 = 1.975 ms，相比Baseline时间缩短4.357 ms - 1.975 ms = 2.382 ms。总的持续时间缩短为99.535 ms，平均每秒处理样本数（samples/s）为： 32 * 3 /(99.535 / 1000) = 964.485，性能提升（964.485 - 797.819）/ 797.819 * 100% = 20.89% 优化方向3：数据加载和数据计算完全重叠在缩短数据传输时间的基础上，继续寻找优化的机会。分析开启Pin Memory的Timeline发现，虽然Batch加载和Batch计算（包括Batch传输）有重叠效果，但是Batch加载却只能重叠一个Batch计算，如下图，Batch5的加载与Batch4的计算重叠，Batch6的加载与Batch5的计算重叠，Batch7的加载与Batch6的计算重叠。并没有出现例如加载Batch6、Batch7与Batch5计算重叠的情况。同时，在Timeline中发现，在数据加载操作的后面，都会出现一次cudaStreamSynchronize，强制CPU与GPU做一次同步操作，然而每次计算Batch时并不需要这个同步操作。 这个同步操作是由如下的这行代码引入的： 1inputs, labels = data[0].to(device=device), data[1].to(device=device) to函数默认行为是：每次将数据从Host端传输到GPU端后，会执行cudaStreamSynchronize进行同步。然而，to函数亦支持非阻塞模式（异步操作），通过添加参数non_blocking=True来实现： 1inputs, labels = data[0].to(device=device,non_blocking=True), data[1].to(device=device,non_blocking=True) 采用非阻塞模式后（异步操作），数据传输至GPU的操作被安排至CUDA流队列末尾而不会阻碍CPU，即CPU可继续执行后续任务，无需等待数据传输完成。 修改代码后，重新运行，结果显示如下。 从上面的图中可以看出： GPU真正在计算Batch3时，CPU端Batch5、Batch6、Batch7数据加载已经完成（也就是CPU早早完成自己的任务），真正做到Batch加载与Batch计算完全重叠。 Batch5、Batch6、Batch7的加载已经完全隐藏在了Batch2、Batch3、Batch4的计算中，它们的加载时间可以忽略不计。 每秒样本处理数（samples/s）为：32 * 3 / (94.164 / 1000) = 1019.498。相比上一步的优化2，性能提升（1019.498 - 964.485）/ 964.485 * 100% = 5.7%。 优化方向4：自动混合精度前面已经优化了数据加载、数据传输。本次将聚焦寻找一些降低GPU计算Batch时间的方法。 PyTorch支持在训练的时候开启混合精度计算（ Automatic Mixed Precision (AMP)），在AMP模式下，GPU上部分Tensor自动转换为低精度的16位浮点数，并在GPU张量核心上运行，以此降低显存使用量和缩短计算时间。 修改下面的代码开启AMP模式。在生产环境中，AMP的完整实现可能需要梯度缩放，下方代码演示中没有包括这一点，请参考相关文档正确使用AMP。 123456789# train stepdef train(data): ...... # 省略其他代码 # 开启amp with torch.autocast(device_type='cuda', dtype=torch.float16): outputs = model(inputs) loss = criterion(outputs, labels) ....... # 省略其他代码 开启AMP的结果如下。Batch计算时间缩短为58.938 ms，平均每秒处理的样本数为：32 * 3 / (58.938 /1000) = 1628.83，性能提升（1628.83 - 1019.498）/ 1019.498 * 100% = 59.77%。 进入一个Batch的forward和Backward，观察其Kernel函数的组成，发现开启AMP之前，操作的数据类型基本都是float32，并且将Kernel函数执行时间按降序排列，执行时间靠前的如下所示，从300μs到1ms不等。 开启AMP以后，大多数操作的数据类型都是float16，并且执行时间靠前的Kernel基本都在100μs到300μs之间。 优化方向5：增大Batch Size增大Batch Size也能够提升每秒处理样本数，但是增大Batch Size需要考虑显存的使用情况（显存是否够用）和大Batch Size对Loss值的影响。 修改如下代码，尝试将Batch Size从32调整至512。 1train_loader = torch.utils.data.DataLoader(train_set,num_workers=8, batch_size=512,pin_memory=True, shuffle=True) 运行代码，结果如下。总的持续时间为：697.666 ms，平均每秒处理样本数（samples/s）为：512 * 3 /（697.666 / 1000）= 2201.627。性能提升（2201.627 - 1628.83）/ 1628.83 * 100% = 35.17%。 优化方向6：模型编译默认情况下，PyTorch采用的是即时编译，您可以借助PyTorch的编译API将模型编译成图模式（Graph Mode）。 修改如下代码： 12model = torchvision.models.resnet18(weights='IMAGENET1K_V1').cuda(device)model = torch.compile(model) 运行代码，结果显示如下。总的持续时间为：567.971 ms，平均每秒处理的样本数为：512 * 3 /（567.971 / 1000）= 2704.36，性能提升（2704.36 - 2201.627）/ 2201.627 * 100% = 22.83%。 优化方向7：Batch传输与Batch计算重叠由于Batch传输和Batch计算是串行执行的，也就是Batch传输完成，才能执行Batch计算。而Batch传输时，GPU是处于空闲状态的，然后当Batch Size变大时，Batch传输时间相比Batch计算是不可忽略的。 按照一般的思维，要计算Batch，只有当Batch传输到GPU后，才能开始计算，如果传输没有完成就开始计算，结果就不是正确的。如果以流水线思维思考，假设Batch计算的时间比Batch传输的时间长，那么如果GPU在计算第一个Batch的同时，第二个Batch也开始传输，等GPU计算第二个Batch的同时，第三个Batch传输也在进行，那么就将Batch传输的时间隐藏在Batch的计算中了。 在单个Stream中无法完成上述的重叠操作，不过PyTorch允许创建多个Stream，除了默认的Stream外，可以额外创建一个Stream。完整代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384import nvtx # 引入nvtx包import torchimport torch.nnimport torch.optimimport torch.profilerimport torch.utils.dataimport torchvision.datasetsimport torchvision.modelsimport torchvision.transforms as Ttransform = T.Compose([ T.Resize(224), T.ToTensor(), T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)train_loader = torch.utils.data.DataLoader(train_set,num_workers=8, batch_size=512,pin_memory=True, shuffle=True)device = torch.device(&quot;cuda:0&quot;)model = torchvision.models.resnet18(weights='IMAGENET1K_V1').cuda(device)model = torch.compile(model)criterion = torch.nn.CrossEntropyLoss().cuda(device)optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)def train(model, device, train_loader, optimizer,criterion): model.train() dl = iter(train_loader) transfered_data = [] # 创建一个新的stream s = torch.cuda.Stream() def prepare_batch(batch_idx): nvtx.push_range(&quot;__next__ &quot; + str(batch_idx),color=&quot;orange&quot;) (inputs, labels) = next(dl) # 传输数据在新的stream中进行 nvtx.pop_range() nvtx.push_range(&quot;cpy &quot; + str(batch_idx),color=&quot;rapids&quot;) with torch.cuda.stream(s): inputs, labels = inputs.to(device=device,non_blocking=True), labels.to(device=device,non_blocking=True) nvtx.pop_range() return (inputs, labels) def batch_compute(batch_idx,data): nvtx.push_range(&quot;batch &quot; + str(batch_idx),color=&quot;cyan&quot;) nvtx.push_range(&quot;forward &quot; + str(batch_idx),color=&quot;yellow&quot;) with torch.autocast(device_type='cuda', dtype=torch.float16): outputs = model(data[0]) loss = criterion(outputs, data[1]) nvtx.pop_range() nvtx.push_range(&quot;backward &quot; + str(batch_idx),color=&quot;green&quot;) optimizer.zero_grad() loss.backward() optimizer.step() nvtx.pop_range() torch.cuda.current_stream().wait_stream(s) nvtx.pop_range() batch_idx = 0 tet = None while True: try: if batch_idx == 6: tet = nvtx.start_range(message=&quot;Total Elapsed Time(3 batchs)&quot;, color=&quot;orange&quot;) if batch_idx &gt;= 8: break data = prepare_batch(batch_idx) transfered_data.append(data) # 当batch_idx为0时，不执行计算操作 # 每一个循环都需要让默认的stream等待新创建的stream传输数据完成，确保下一轮 # Batch计算所需数据能够准备完成。 if batch_idx &gt; 0: batch_compute(batch_idx-1,transfered_data[batch_idx - 1]) else: torch.cuda.current_stream().wait_stream(s) batch_idx += 1 except StopIteration: nvtx.pop_range() break batch_compute(batch_idx-1,transfered_data[batch_idx - 1]) nvtx.end_range(tet)train(model, device, train_loader, optimizer,criterion) 运行代码，结果展示如下。图中展示了Batch2到Batch7的传输操作隐藏在了Batch1到Batch4的计算中（Batch0和Batch1的传输未展示，页面有限）。同时可以确认的是，每个Batch在计算之前，其数据都已经传输完成。例如，Batch4计算时，Batch4的传输已经隐藏在Batch2的计算中。因此，可以确保计算结果的正确性。 总的持续时间为484.016 ms，平均每秒处理样本数为：512 * 3 / (484.016 / 1000) = 3173.449，性能提升（3173.449 - 2704.36）/ 2704.36 * 100% = 17.35%。 需要注意的是，虽然将数据传输隐藏在数据计算中，但是会额外增加GPU内存的使用，以上面为例，当计算Batch5时，所有的Batch都驻留在了GPU内存中。 总结对各个优化项性能提升做一个总结。 阶段 平均每秒处理样本数（samples/s） 性能相比前一个优化项提升百分比 未优化：Baseline 542.746 - 优化1：Data Loader worker设置为8 797.819 47.00% 优化2：开启Pin Memory 964.485 20.89% 优化3：数据加载与Batch计算完全重叠 1019.498 5.7% 优化4：自动混合精度 1628.83 59.77% 优化5：增大Batch Size 2201.627 35.17% 优化6：模型编译 2704.36 22.83% 优化7：Batch传输与Batch计算重叠 3173.449 17.35%","link":"/2025/06/15/%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96%E5%AE%9E%E8%B7%B5/"},{"title":"C++模板学习笔记（一）","text":"记录一下学习C++模板时的知识点 两阶段模板编译检查模板的检查分成两阶段，在定义时和在实例化时进行检查。在模板定义时检查： 语法检查，比如分号。 使用了未知的类型或函数，且与模板参数无关。 在模板实例化阶段，会将类型带入模板再次进行检查，比如以下代码： 12345678template&lt;typename T&gt;void foo(T t){ undeclared(); // 如果 undeclared()未定义，第一阶段就会报错，因为与模板参数无关 undeclared(t); //如果 undeclared(t)未定义，第二阶段会报错，因为与模板参数有关 static_assert(sizeof(int) &gt; 10,&quot;int too small&quot;); // 与模板参数无关，总是报错 static_assert(sizeof(T) &gt; 10, &quot;T too small&quot;); //与模板参数有关，只会在第二阶段报错} 有些错误只会在模板实例化时出现，因此如果模板只是定义了，但是没有实例化过，这个错误可能一直存在但是不会被发现。 模板的定义模板通常在声明时定义，但也支持声明与定义分离，例如在同一个头文件中 12345678910// MyClass.hpptemplate &lt;typename T&gt;class MyClass {public: void memberFunc();};// 定义必须写在同一个头文件内！template &lt;typename T&gt;void MyClass&lt;T&gt;::memberFunc() { /* ... */ } 处于编译效率考虑，也可以将定义放在其他头文件中，有些项目将包含有模板定义的文件添加在_impl.h后缀，供需要实例化的编译单元包含。 1234567// MyClass.cpptemplate &lt;typename T&gt;void MyClass&lt;T&gt;::memberFunc() { /* ... */ }// 显式实例化所需类型template class MyClass&lt;int&gt;; // 实例化int版本template class MyClass&lt;double&gt;; // 实例化double版本 将模板定义移到单独头文件的核心价值是 通过显式实例化控制代码生成，从而优化编译速度和封装性，但会牺牲模板的灵活性（用户无法随意指定新类型）。 模板的默认参数一个有意思的地方，即使后面的模板参数没有指定默认指，依然可以让前面的模板参数有默认值 12345template&lt;typename RT = long, typename T1, typename T2&gt;RT max (T1 a, T2 b){ return b &lt; a ? a : b;} 模板特化什么是模板特化为特定类型的模板提供一个“特殊”版本，作为模板定义的一个补充。模板的特化可以分成全特化和偏特化，全特化即完全指定所有模板参数，偏特化则为指定部分模板参数。 1234567891011// 定义一个模板函数template&lt;typename T&gt;bool equal(T a, T b) { return a == b;}// 定义类型为double时的行为template &lt;&gt;bool equal(double a, double b) { return abs(a-b) &lt; 1e-5;} 模板函数实际上模板函数不存在模板偏特化，类似模板偏特化的功能是通过函数重载实现的。原因是函数重载可以实现模板特化的功能，就不再需要引入更加复杂的模板偏特化功能了。以下是利用函数重载实现模板偏特化的例子 123456789101112131415161718template &lt;typename T, typename U&gt;void foo(T a, U b) { std::cout &lt;&lt; &quot;Generic: T=&quot; &lt;&lt; typeid(T).name() &lt;&lt; &quot;, U=&quot; &lt;&lt; typeid(U).name() &lt;&lt; std::endl;}// 通过重载模拟&quot;部分特化&quot;template &lt;typename U&gt;void foo(int a, U b) { // 第一个参数固定为 int std::cout &lt;&lt; &quot;Overload (T=int): U=&quot; &lt;&lt; typeid(U).name() &lt;&lt; std::endl;}int main() { foo(1, 2); // 调用重载版本 foo&lt;int, int&gt;(int, int) foo(1, &quot;hello&quot;); // 调用重载版本 foo&lt;int, const char*&gt;(int, const char*) foo(3.14, 'a'); // 调用主模板 foo&lt;double, char&gt;(double, char) return 0;} 模板类模板的成员函数特化有多种方式。可以对整个模板类进行特化，特化时需要特化所有的成员函数，如果在特化时没有定义该成员函数，那么在后续使用时也不能使用该成员函数。 12345678910111213141516171819202122232425#include &quot;bits/stdc++.h&quot;using namespace std;template &lt;typename T&gt;class MyClass {public: void func1() { cout &lt;&lt; &quot;Generic func1\\n&quot;; } void func2() { cout &lt;&lt; &quot;Generic func2\\n&quot;; }};template &lt;&gt;class MyClass&lt;int&gt; { public: void func1() { cout &lt;&lt; &quot;Specialized func1 for int\\n&quot;; } // void func2() { cout &lt;&lt; &quot;Specialized func2 for int\\n&quot;; }};int main() { MyClass&lt;int&gt; a; a.func1(); // Output: Specialized func1 for int a.func2(); // Error! func2 is not specialized for int return 0;} 上面这个例子特化了一个int类型版本的MyClass，在特化时没有特化func2函数，因此在a调用func2时会编译错误。特化后的模板类不会继承通用实现版本的成员函数。 除了对整个模板类进行特化，还允许对模板类的单个成员函数进行特化，这样就能保持特化时继承通用版本的成员函数。 12345678910111213141516171819202122232425262728293031#include &lt;iostream&gt;#include &lt;typeinfo&gt;template &lt;typename T&gt;class Printer {public: void printType() { std::cout &lt;&lt; &quot;Generic type: &quot; &lt;&lt; typeid(T).name() &lt;&lt; &quot;\\n&quot;; } // 声明特化版本的成员函数 void printSpecial();};template &lt;&gt;void Printer&lt;int&gt;::printSpecial() { std::cout &lt;&lt; &quot;Specialized for int!\\n&quot;;}// 其他类型仍然使用通用版本（未特化时可能未定义，需谨慎）int main() { Printer&lt;double&gt; p1; p1.printType(); // 输出: Generic type: d (double) // p1.printSpecial(); // 未定义，编译错误（未特化 double） Printer&lt;int&gt; p2; p2.printType(); // 输出: Generic type: i (int) p2.printSpecial(); // 输出: Specialized for int! return 0;} 此时成员函数就与普通函数一致，遵循通用的规则，例如只能全特化而不支持偏特化。 模板别名模板别名可以便于我们使用，有这么几种常用用法 typedef 关键字定义: typedef Stack&lt;int&gt; IntStack using 关键字定义(C++11):using IntStack = Stack&lt;int&gt; 也可以alias封装出一个新模板，例如： 12345678template&lt;typename T&gt;using DequeStack = Stack&lt;T, std::deque&lt;T&gt;&gt;;// 链式封装template&lt;typename T&gt;using EntityWithLogAndTimer = Logger&lt;Timer&lt;T&gt;&gt;;using MyBetterEntity = EntityWithLogAndTimer&lt;BaseEntity&gt;;","link":"/2025/07/14/%E6%A8%A1%E6%9D%BF%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/"},{"title":"C++模板学习笔记（二）","text":"记录一下学习C++模板时的知识点 模板参数省略调用模板函数时可以省略模板参数，因为很容易从实参中推导出类型 1234567template&lt;typename T&gt;void print(T val) { std::cout &lt;&lt; val &lt;&lt; std::endl;}print(42); // T 被推导为 intprint(&quot;hello&quot;); // T 被推导为 const char* 类模板参数通常不可以省略，但是在C++17及以上时具有类模板参数推导的机制，可以省略。 1234567template&lt;typename T&gt;class Wrapper {public: Wrapper(T val) { ... }};Wrapper w(42); // ✅ 从构造函数推导出 T = int（C++17） 对于C++11等不支持类模板参数推导的情况，可以使用模板函数对模板类的构造进行封装，也能实现类似的效果 123456789101112template&lt;typename T&gt;class Wrapper {public: Wrapper(T val) { ... }};template&lt;typename T&gt;Wrapper&lt;T&gt; make_wrapper(T val) { return Wrapper&lt;T&gt;(val);}auto w = make_wrapper(42); // ✅ 自动推导 Wrapper&lt;int&gt; 模板实例化的规则先看下这段代码问题在哪里 123456789101112131415#include &quot;bits/stdc++.h&quot;using namespace std;template&lt;typename T, typename... Args&gt;void print(T firstArg, Args... args) { cout &lt;&lt; firstArg &lt;&lt; '\\n'; if (sizeof...(args) &gt; 0) { print(args...); }}int main() { print(123, &quot;hello&quot;, &quot;world&quot;);} 原因是因为if的判断是在运行时决定的，而模板的实例化是在编译时决定的，编译时无法知道运行时的状态。于是编译器看到print(args…)时必须确保它在任何情况下都合法，因此print函数需要补充一个无参数的重载版本。 可变参数模板中…的用法基本使用12template&lt;typename... Args&gt; // Args 是模板参数包（Template Parameter Pack）void func(Args... args); // args 是函数参数包（Function Parameter Pack） 参数包解包递归展开12345678// 递归终止条件void print() {}template&lt;typename T, typename... Args&gt;void print(T first, Args... rest) { std::cout &lt;&lt; first &lt;&lt; &quot; &quot;; print(rest...); // 递归调用，展开 rest} 折叠表达式1234template&lt;typename... Args&gt;auto sum(Args... args) { return (args + ...); // 折叠表达式：args[0] + args[1] + ...} 二元运算符支持所有运算符 完美转发完美转发的目的是保持参数的左/右值属性 1234template&lt;typename... Args&gt;void wrapper(Args&amp;&amp;... args) { target_func(std::forward&lt;Args&gt;(args)...); // 展开为 std::forward&lt;T1&gt;(x1), std::forward&lt;T2&gt;(x2), ...} 参数翻倍1234template&lt;typename... Args&gt;void printDoubled(Args&amp;... args) { print((args + args)...); // 关键点：参数包展开} 参数加11234template&lt;typename... Args&gt;void addOne(Args&amp;... args) { print((args + 1)...);} 变参下标1234template&lt;typename C, typename... Idx&gt;void printElems(C&amp; coll, Idx... idx) { print(coll[idx]...);} sizeof…运算符用于获取参数包大小，是一个编译器常量 123456789template&lt;typename... Args&gt;void func(Args... args) { constexpr size_t count = sizeof...(Args); // 类型参数包的大小 constexpr size_t count2 = sizeof...(args); // 函数参数包的大小}// 当调用std::vector&lt;std::string&gt; coll = {&quot;good&quot;, &quot;times&quot;, &quot;say&quot;, &quot;bye&quot;};// printElems(coll,2,0,3);// 时，相当于调用了// print (coll[2], coll[0], coll[3]); 模板技巧使用this→对于类模板，如果它的基类也是依赖于模板参数的，那么对它而言即使 x 是继承而来的，使用 this-&gt;x 和 x 也不一定是等效的。比如 12345678910111213template&lt;typename T&gt;class Base { public: void bar();};template&lt;typename T&gt;class Derived : Base&lt;T&gt; { public: void foo() { bar(); // calls external bar() or error }}; Derived 中的 bar()永远不会被解析成 Base 中的 bar()。因此这样做要么会遇到错误，要么就是调用了其它地方的 bar()，比如可能是定义在其它地方的 global 的 bar()","link":"/2025/07/16/%E6%A8%A1%E6%9D%BF%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89/"},{"title":"Python项目import管理","text":"介绍了Python模块导入的查找顺序和项目中import的最佳实践 import导入顺序讲到import管理首先需要连接import查询的路径及其顺序，当执行 import module 或 from package import module 时，Python 会按以下顺序查找模块： 1.检查sys.modules，先检查模块是否已经被导入，如果已经被导入就会忽略。 2.检查内置模块(Built-in Moudules) 3.sys.path列表包含的路径，按照以下顺序进行查找 当前脚本所在目录 环境变量PYTHONPATH中的路径 Python标准库目录 Python第三方库目录 项目import管理import有绝对导入和相对导入两种写法，优先推荐使用绝对导入 1from mypackage.module_a import func 这种写法清晰明了，跨目录导入不会出错，对重构和测试非常优化。 还有一种相对导入的方法，不推荐使用 12from .module_b import func # 当前包from ..subpackage.module_c import func # 上级包 它的缺点是依赖运行上下文，不可以在其他目录中直接运行。","link":"/2025/07/18/Python%E9%A1%B9%E7%9B%AEimport%E7%AE%A1%E7%90%86/"}],"tags":[{"name":"并发编程","slug":"并发编程","link":"/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"跨平台开发","slug":"跨平台开发","link":"/tags/%E8%B7%A8%E5%B9%B3%E5%8F%B0%E5%BC%80%E5%8F%91/"},{"name":"CMake","slug":"CMake","link":"/tags/CMake/"},{"name":"开发工具","slug":"开发工具","link":"/tags/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/"},{"name":"并行计算","slug":"并行计算","link":"/tags/%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97/"},{"name":"效率工具","slug":"效率工具","link":"/tags/%E6%95%88%E7%8E%87%E5%B7%A5%E5%85%B7/"},{"name":"Qt","slug":"Qt","link":"/tags/Qt/"},{"name":"机器学习","slug":"机器学习","link":"/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"网络编程","slug":"网络编程","link":"/tags/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"},{"name":"C++","slug":"C","link":"/tags/C/"},{"name":"Docker","slug":"Docker","link":"/tags/Docker/"},{"name":"性能优化","slug":"性能优化","link":"/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"},{"name":"源码阅读","slug":"源码阅读","link":"/tags/%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/"},{"name":"操作系统, 内存","slug":"操作系统-内存","link":"/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E5%86%85%E5%AD%98/"},{"name":"内存模型","slug":"内存模型","link":"/tags/%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/"},{"name":"网络, 抓包","slug":"网络-抓包","link":"/tags/%E7%BD%91%E7%BB%9C-%E6%8A%93%E5%8C%85/"},{"name":"Python","slug":"Python","link":"/tags/Python/"}],"categories":[],"pages":[{"title":"","text":"2024-10-13 开通ChangeLog页面","link":"/changelog/index.html"}]}